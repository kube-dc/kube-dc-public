{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What Is Kube-DC?","text":"<p>Kube-DC is an advanced, enterprise-grade platform that transforms Kubernetes into a comprehensive Data Center solution supporting both virtual machines and containerized workloads. It provides organizations with a unified management interface for all their infrastructure needs, from multi-tenancy and virtualization to networking and billing.</p>"},{"location":"#overview","title":"Overview","text":"<p>Kube-DC bridges the gap between traditional virtualization and modern container orchestration, allowing teams to run both legacy workloads and cloud-native applications on the same platform. By leveraging Kubernetes as the foundation, Kube-DC inherits its robust ecosystem while extending functionality to support enterprise requirements.</p> <p></p>"},{"location":"#key-features-at-a-glance","title":"Key Features at a Glance","text":"<p>Kube-DC offers a comprehensive set of features designed for modern data center operations:</p> <ul> <li>Multi-Tenancy - Host multiple organizations with isolated environments and custom SSO integration</li> <li>Unified Workload Management - Run both VMs and containers on the same platform</li> <li>Advanced Networking - VPC per project, VLAN support, and software-defined networking</li> <li>Enterprise Virtualization - KubeVirt integration with GPU passthrough and live migration</li> <li>Infrastructure as Code - Kubernetes-native APIs with support for Terraform, Ansible, and more</li> <li>Integrated Billing - Track and allocate costs for all resources</li> <li>Managed Services Platform - Deploy databases, storage, and AI/ML infrastructure</li> </ul> <p>For detailed information about each feature, including capabilities and use cases, visit the Core Features page.</p>"},{"location":"#why-choose-kube-dc","title":"Why Choose Kube-DC?","text":""},{"location":"#for-enterprise-it","title":"For Enterprise IT","text":"<ul> <li>Run legacy VMs alongside modern containers</li> <li>Implement chargeback models for departmental resource usage</li> <li>Provide self-service infrastructure while maintaining governance</li> <li>Reduce operational costs by consolidating virtualization and container platforms</li> </ul>"},{"location":"#for-service-providers","title":"For Service Providers","text":"<ul> <li>Offer multi-tenant infrastructure with complete isolation</li> <li>Provide value-added services beyond basic IaaS</li> <li>Implement flexible billing based on actual resource usage</li> <li>Support diverse customer workloads on a single platform</li> </ul>"},{"location":"#for-devops-teams","title":"For DevOps Teams","text":"<ul> <li>Unify VM and container management workflows</li> <li>Implement infrastructure as code for all resources</li> <li>Integrate with existing CI/CD pipelines</li> <li>Enable developer self-service while maintaining control</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to explore Kube-DC? Check out our Quick Start guides to begin your journey.</p> <p>For a deeper understanding of the underlying architecture and concepts, visit the Architecture &amp; Concepts section.</p>"},{"location":"#community-and-support","title":"Community and Support","text":"<p>Kube-DC is built with a focus on community collaboration. Visit our Community &amp; Support page to learn how to get involved, report issues, or seek assistance.</p>"},{"location":"core-features/","title":"Core Features","text":"<p>Kube-DC extends Kubernetes with a robust set of features designed for enterprise data center operations. This page provides detailed technical specifications and use cases for each of Kube-DC's core capabilities.</p> <p>Looking for a high-level overview? Visit our introduction page.</p>"},{"location":"core-features/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Organization Management</li> <li>Namespace as a Service</li> <li>Network Management</li> <li>Virtualization</li> <li>Infrastructure as Code</li> <li>Integrated Flexible Billing</li> <li>Management Services</li> </ul>"},{"location":"core-features/#organization-management","title":"Organization Management","text":"<p>Foundation for Multi-Tenancy</p> <p>Organization Management provides the foundation for Kube-DC's multi-tenant capabilities, enabling complete isolation between different users and groups.</p> <p>Kube-DC's multi-tenant architecture allows service providers to host multiple organizations with complete isolation and customization.</p> <p>Capabilities:</p> <ul> <li>Multi-Organization Support: Host multiple organizations on a single Kube-DC installation with complete logical separation</li> <li>Custom SSO Integration: Each organization can configure its own identity provider:<ul> <li>Google Workspace / Gmail</li> <li>Microsoft Active Directory / Azure AD</li> <li>GitHub</li> <li>GitLab</li> <li>LDAP</li> <li>SAML 2.0 providers</li> <li>OpenID Connect providers</li> </ul> </li> <li>Hierarchical Group Management: Create and manage groups within organizations with inheritance of permissions</li> <li>Flexible RBAC: Assign fine-grained permissions to groups for specific projects or resources</li> <li>Organizational Quotas: Set resource limits at the organization level to ensure fair resource allocation</li> </ul> <p>Real-World Applications</p> <ul> <li>Managed Service Providers: Host multiple client organizations with separate authentication systems</li> <li>Enterprise IT: Separate departments with different authentication requirements</li> <li>Educational Institutions: Provide isolated environments for different departments or research groups</li> </ul>"},{"location":"core-features/#namespace-as-a-service","title":"Namespace as a Service","text":"<p>Projects and Workloads</p> <p>Namespaces in Kube-DC function as projects, providing isolated environments for deploying and managing diverse workloads.</p> <p>Every project in Kube-DC is allocated its own Kubernetes namespace with extended capabilities for running both containers and virtual machines.</p> <p>Capabilities:</p> <ul> <li>Unified Management: Deploy and manage both VMs and containers from a single interface</li> <li>Project Isolation: Complete network and resource isolation between projects</li> <li>Resource Quotas: Set limits on CPU, memory, storage, and other resources per project</li> <li>Integrated Dashboard: View and manage all workloads through a unified web interface</li> <li>Custom Templates: Create and use templates for quick deployment of common workloads</li> </ul> <p>Real-World Applications</p> <ul> <li>Application Modernization: Run legacy VMs alongside containerized microservices</li> <li>Development Environments: Provide isolated environments for development, testing, and staging</li> <li>Mixed Workloads: Support teams that require both traditional and cloud-native infrastructure</li> </ul>"},{"location":"core-features/#network-management","title":"Network Management","text":"<p>Advanced Connectivity</p> <p>Kube-DC's network capabilities enable sophisticated connectivity options while maintaining isolation between projects.</p> <p>Kube-DC provides advanced networking capabilities that bridge traditional data center networking with cloud-native concepts.</p> <p>Capabilities:</p> <ul> <li>Dedicated VPC per Project: Each project gets its own virtual network environment</li> <li>VLAN Integration: Connect to physical network infrastructure using VLANs</li> <li>Software-Defined Networking: Create overlay networks with software-defined control</li> <li>Network Peering: Connect project networks with each other or with external networks</li> <li>NAT and Internet Gateway: Control outbound and inbound internet access per project</li> <li>External IP Assignment: Assign public IPs directly to VMs or Kubernetes services</li> <li>Load Balancer Integration: Create and manage load balancers for services and VMs</li> <li>Network Policies: Define granular rules for network traffic filtering</li> <li>DNS Management: Automatic DNS for services and VMs with custom domain support</li> </ul> <p>Real-World Applications</p> <ul> <li>Hybrid Cloud Deployments: Extend on-premises networks to containerized workloads</li> <li>Multi-Tier Applications: Create complex network topologies for enterprise applications</li> <li>Secure Isolation: Create zero-trust network environments with fine-grained control</li> </ul>"},{"location":"core-features/#virtualization","title":"Virtualization","text":"<p>KubeVirt Integration</p> <p>Built on KubeVirt, Kube-DC provides enterprise-grade virtualization capabilities fully integrated with Kubernetes.</p> <p>Built on KubeVirt, Kube-DC provides enterprise-grade virtualization capabilities integrated with Kubernetes.</p> <p>Capabilities:</p> <ul> <li>Hardware Vendor Support: Compatible with major hardware vendors' servers and components</li> <li>GPU Passthrough: Support for Nvidia GPU passthrough to virtual machines</li> <li>ARM Support: Run VMs on ARM-based infrastructure</li> <li>Web Console: Access VM consoles directly through the web UI</li> <li>SSH Integration: SSH access management with key authentication</li> <li>Live Migration: Move running VMs between nodes without downtime</li> <li>Snapshots: Create point-in-time snapshots of VM volumes</li> <li>VM Templates: Create and use templates for rapid VM provisioning</li> <li>Custom Boot Options: Configure boot order, firmware settings, and UEFI support</li> <li>VM Import/Export: Import existing VMs from other platforms</li> </ul> <p>Real-World Applications</p> <ul> <li>Legacy Application Support: Run applications that require traditional VMs</li> <li>Windows Workloads: Host Windows servers alongside Linux containers</li> <li>GPU-Accelerated Computing: Provide GPU resources for AI/ML or rendering workloads</li> <li>Specialized Operating Systems: Run operating systems not supported in containers</li> </ul>"},{"location":"core-features/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>API-Driven Architecture</p> <p>Kube-DC's API-driven approach enables automation and integration with popular infrastructure tools.</p> <p>Kube-DC leverages and extends the Kubernetes API to enable comprehensive infrastructure automation.</p> <p>Capabilities:</p> <ul> <li>Native Kubernetes API: Manage all Kube-DC resources using standard Kubernetes tools</li> <li>Custom Resource Definitions (CRDs): Extended Kubernetes objects for managing organizations, projects, VMs, and more</li> <li>GitOps Compatible: Deploy and manage infrastructure using GitOps workflows</li> <li>Terraform Provider: Official Terraform provider for Kube-DC resources</li> <li>Ansible Integration: Ansible modules for managing Kube-DC resources</li> <li>Crossplane Support: Use Crossplane to provision and manage Kube-DC resources</li> <li>Pulumi Provider: Programmatically manage Kube-DC using multiple languages</li> </ul> <p>Real-World Applications</p> <ul> <li>Automated Infrastructure: Create fully automated infrastructure provisioning workflows</li> <li>Self-Service Portals: Build custom self-service interfaces using the Kube-DC API</li> <li>CI/CD Integration: Include infrastructure provisioning in CI/CD pipelines</li> <li>Multi-Cloud Management: Manage Kube-DC resources alongside other cloud resources</li> </ul>"},{"location":"core-features/#integrated-flexible-billing","title":"Integrated Flexible Billing","text":"<p>Cost Management</p> <p>Track, allocate, and manage costs across all resources with Kube-DC's comprehensive billing capabilities.</p> <p>Kube-DC includes comprehensive resource tracking and billing capabilities suitable for both service providers and internal IT organizations.</p> <p>Capabilities:</p> <ul> <li>Resource Metering: Track usage of CPU, memory, storage, GPU, and network resources</li> <li>Custom Pricing Models: Define pricing tiers for different resource types and customers</li> <li>Project-Based Billing: Track and bill resource usage at the project level</li> <li>Cost Allocation: Assign costs to organizational units, projects, or individual resources</li> <li>Quota Enforcement: Automatically enforce resource limits based on billing status</li> <li>Usage Reporting: Generate detailed usage reports for analysis and billing</li> <li>Billing API: Integrate with external billing systems through a comprehensive API</li> <li>Chargeback Models: Support for various internal chargeback models for enterprise use</li> </ul> <p>Real-World Applications</p> <ul> <li>Managed Service Providers: Bill customers for exact resource usage</li> <li>Enterprise IT: Implement internal chargeback or showback for departmental resource usage</li> <li>Resource Optimization: Identify resource usage patterns and optimize costs</li> </ul>"},{"location":"core-features/#management-services","title":"Management Services","text":"<p>Value-Added Services</p> <p>Extend Kube-DC's capabilities by offering managed services on top of the core platform.</p> <p>Kube-DC provides a platform for delivering managed services on top of its infrastructure.</p> <p>Capabilities:</p> <ul> <li>Database as a Service: Deploy and manage databases with automated operations</li> <li>PostgreSQL</li> <li>MySQL/MariaDB</li> <li>Microsoft SQL Server</li> <li>And more</li> <li>Object Storage: S3-compatible storage with multi-tenancy support</li> <li>NoSQL Databases: Managed NoSQL database offerings</li> <li>Redis</li> <li>MongoDB</li> <li>Elasticsearch/OpenSearch</li> <li>AI/ML Platform: Infrastructure for deploying and serving AI/ML models</li> <li>LLM serving</li> <li>Model training infrastructure</li> <li>GPU resource allocation</li> <li>Backup Services: Automated backup solutions for VMs and containers</li> <li>Monitoring as a Service: Multi-tenant monitoring solutions</li> <li>Service Catalog: Self-service provisioning of common services</li> </ul> <p>Real-World Applications</p> <ul> <li>Internal Platform Team: Provide managed services to development teams</li> <li>Managed Service Providers: Offer value-added services beyond basic infrastructure</li> <li>AI/ML Operations: Provide specialized infrastructure for data science teams</li> </ul>"},{"location":"quick-start/","title":"Quick start","text":"<ol> <li>Configure network. Ubuntu 24 netplan example (all nodes): </li> </ol> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s31f6:\n      addresses:\n        - 22.22.22.2/24\n      routes:\n        - to: 0.0.0.0/0\n          via: 22.22.22.1\n          on-link: true\n          metric: 100\n      routing-policy:\n        - from: 22.22.22.1\n          table: 100\n      nameservers:\n        addresses:\n          - 8.8.8.8\n          - 8.8.4.4\n  vlans:\n    enp0s31f6.4012:\n      id: 4012\n      link: enp0s31f6\n      mtu: 1460\n      addresses:\n        - 192.168.100.2/22\n</code></pre> <ol> <li>Update, upgrade, install soft:</li> </ol> <pre><code>sudo apt -y update\nsudo apt -y upgrade\nsudo apt -y install unzip iptables\n</code></pre> <ol> <li>Disable IPv6 and increase inotify limits. Add to <code>/etc/sysctl.conf</code> (all nodes, optional)</li> </ol> <pre><code>net.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1\nfs.inotify.max_user_watches=1524288\nfs.inotify.max_user_instances=4024\n</code></pre> <p>and run </p> <pre><code>sudo sysctl -p\n</code></pre> <ol> <li>Disable <code>resolved</code>: </li> </ol> <pre><code>systemctl stop systemd-resolved\nsystemctl disable systemd-resolved\nrm /etc/resolv.conf\necho \"nameserver 8.8.8.8\" &gt; /etc/resolv.conf\necho \"nameserver 8.8.4.4\" &gt;&gt; /etc/resolv.conf\n</code></pre> <ol> <li>Edit <code>/etc/hosts</code> and remove all ipv6:</li> </ol> <pre><code>127.0.0.1 localhost.localdomain localhost\n22.22.22.3 kube-dc-master-1\n</code></pre> <ol> <li>Clone git repo (initial master node): </li> </ol> <pre><code>git clone https://github.com/shalb/kube-dc.git\ncd kube-dc\n</code></pre> <ol> <li>Check passwordless connection to all other nodes.</li> </ol> <pre><code>ssh root@22.22.22.3\n</code></pre> <ol> <li>Install <code>cluster.dev</code>. https://docs.cluster.dev/installation-upgrade/</li> </ol> <pre><code>curl -fsSL https://raw.githubusercontent.com/shalb/cluster.dev/master/scripts/get_cdev.sh | sh\n</code></pre> <ol> <li>Configure and install rke2 cluster initial node.    8.1 Install <code>kubectl</code> <pre><code>\n</code></pre></li> </ol> <p>8.2 Create rke2 config file <code>/etc/rancher/rke2/config.yaml</code>: <pre><code># run from root or sudo -s\nmkdir -p /etc/rancher/rke2/\n\ncat &lt;&lt;EOF &gt; /etc/rancher/rke2/config.yaml\nnode-name: kube-dc-master-1\ndisable-cloud-controller: true\ndisable: rke2-ingress-nginx\ncni: none\ncluster-cidr: \"10.100.0.0/16\"\nservice-cidr: \"10.101.0.0/16\"\ncluster-dns: \"10.101.0.11\"\nnode-label:\n  - kube-dc-manager=true\n  - kube-ovn/role=master\nkube-apiserver-arg: \n  - authentication-config=/etc/rancher/auth-conf.yaml\ndebug: true\nnode-external-ip: 138.201.253.201\ntls-san:\n  - kube-api.dev.kube-dc.com\n  - 138.201.253.201\nadvertise-address: 138.201.253.201\nnode-ip: 192.168.100.2\nEOF\n</code></pre></p> <p>8.2 Create kubernetes auth file: <pre><code># run from root or sudo -s\ncat &lt;&lt;EOF &gt; /etc/rancher/auth-conf.yaml\napiVersion: apiserver.config.k8s.io/v1beta1\nkind: AuthenticationConfiguration\njwt: []\nEOF\nchmod 666 /etc/rancher/auth-conf.yaml\n</code></pre>   8.3 Install rke2: </p> <pre><code># run from root or sudo -s\nexport INSTALL_RKE2_VERSION=\"v1.32.1+rke2r1\" # https://docs.rke2.io/release-notes/v1.32.X (required kubernetes v1.31 or later)\nexport INSTALL_RKE2_TYPE=\"server\"\n\ncurl -sfL https://get.rke2.io | sh -\n\nsystemctl enable rke2-server.service\nsystemctl start rke2-server.service\n\njournalctl -u rke2-server -f\n</code></pre> <p>8.4 Get kubeconfig and check cluster access <pre><code># run from your user\nsudo cp /etc/rancher/rke2/rke2.yaml ~/.kube/config\nsudo chown \"$(whoami):$(whoami)\" ~/.kube/config\n\nkubectl get node\n# kube-dc-master-1   NotReady   control-plane,etcd,master   10m   v1.32.1+rke2r1\n# NotReady node it's ok\n</code></pre></p> <ol> <li>Configure and join master node.   9.1 Get join token (on init master node): <pre><code>sudo cat /var/lib/rancher/rke2/server/node-token\n</code></pre>   9.2 Create rke2 config file <code>/etc/rancher/rke2/config.yaml</code>: <pre><code># run from root or sudo -s\nmkdir -p /etc/rancher/rke2/\n\ncat &lt;&lt;EOF &gt; /etc/rancher/rke2/config.yaml\ntoken: &lt;TOKEN&gt;\nserver: https://138.201.253.201:9345\nnode-name: kube-dc-master-2\ndisable-cloud-controller: true\ndisable: rke2-ingress-nginx\ncluster-cidr: \"10.100.0.0/16\"\nservice-cidr: \"10.101.0.0/16\"\ncluster-dns: \"10.101.0.11\"\nnode-label:\n  - kube-ovn/role=master\ndebug: true\nnode-external-ip: 88.99.29.250\ntls-san:\n  - kube-api.dev.kube-dc.com\n  - 88.99.29.250\nadvertise-address: 88.99.29.250\nnode-ip: 192.168.100.3\nEOF\n</code></pre></li> </ol> <p>8.3 Install rke2: </p> <pre><code># run from root or sudo -s\nexport INSTALL_RKE2_VERSION=\"v1.32.1+rke2r1\" # https://docs.rke2.io/release-notes/v1.32.X (required kubernetes v1.31 or later)\nexport INSTALL_RKE2_TYPE=\"server\"\n\ncurl -sfL https://get.rke2.io | sh -\n\nsystemctl enable rke2-server.service\nsystemctl start rke2-server.service\n\njournalctl -u rke2-server -f\n</code></pre> <ol> <li>Configure and join worker node.   9.1 Get join token (on init master node): <pre><code>sudo cat /var/lib/rancher/rke2/server/node-token\n</code></pre>   9.2 Create rke2 config file: <pre><code># run from root or sudo -s\nmkdir -p /etc/rancher/rke2/\n\ncat &lt;&lt;EOF &gt; /etc/rancher/rke2/config.yaml\ntoken: &lt;TOKEN&gt;\nserver: https://192.168.100.2:9345\nnode-name: kube-dc-worker-1\nnode-ip: 192.168.100.3\nEOF\n</code></pre></li> </ol> <p>8.3 Install rke2: </p> <pre><code># run from root or sudo -s\nexport INSTALL_RKE2_VERSION=\"v1.32.1+rke2r1\" # https://docs.rke2.io/release-notes/v1.32.X (required kubernetes v1.31 or later)\nexport INSTALL_RKE2_TYPE=\"agent\"\n\ncurl -sfL https://get.rke2.io | sh -\n\nsystemctl enable rke2-agent.service\nsystemctl start rke2-agent.service\n\njournalctl -u rke2-agent -f\n</code></pre> <ol> <li>Install kube-dc stack</li> </ol> <p>In installer folder <code>inatsller/kube-dc/</code>, edit stack.yaml like this:</p> <p><pre><code>name: cluster\ntemplate: \"./templates/kube-dc/\"\nkind: Stack\nbackend: default\nvariables:\n  debug: \"true\"\n  kubeconfig: /home/arti/.kube/config\n\n  monitoring:\n    prom_storage: 20Gi\n    retention_size: 17GiB\n    retention: 365d\n\n  cluster_config:\n    pod_cidr: \"10.100.0.0/16\"\n    svc_cidr: \"10.101.0.0/16\"\n    join_cidr: \"100.64.0.0/16\"\n    cluster_dns: \"10.101.0.11\"\n    default_external_network:\n      nodes_list: # list of nodes, where 4011 vlan is accessible\n        - kube-dc-master-1\n        - kube-dc-worker-1\n      name: external4011\n      vlan_id: \"4011\"\n      interface: \"enp0s31f6\"\n      cidr: \"167.235.85.112/29\"\n      gateway: 167.235.85.113\n      mtu: \"1400\"\n\n  node_external_ip: 138.201.253.201 # wildcard *.dev.kube-dc.com shoud be faced on this ip\n\n  email: \"noreply@shalb.com\"\n  domain: \"dev.kube-dc.com\"\n  install_terraform: true\n\n  create_default:\n    organization:\n      name: shalb\n      description: \"My test org my-org 1\"\n      email: \"arti@shalb.com\"\n    project:\n      name: demo\n      cidr_block: \"10.1.0.0/16\"\n\n\n  versions:\n    kube_dc: \"v0.1.20\" # release version\n    rke2: \"v1.32.1+rke2r1\"\n</code></pre> install: </p> <pre><code>cdev apply\n</code></pre>"},{"location":"quickstart-hetzner/","title":"Master-Worker Setup on Hetzner Dedicated Servers","text":"<p>This guide provides step-by-step instructions for deploying a Kube-DC cluster with a master and worker node setup on Hetzner Dedicated Servers. This deployment leverages Hetzner's vSwitch and additional subnets to provide enterprise-grade networking capabilities for floating IPs and load balancers.</p>"},{"location":"quickstart-hetzner/#prerequisites","title":"Prerequisites","text":"<ol> <li>At least two Hetzner Dedicated Servers</li> <li>Access to Hetzner Robot interface</li> <li>A Hetzner vSwitch configured for your servers (see Hetzner vSwitch documentation)</li> <li>An additional subnet allocated through Hetzner Robot for external IPs and load balancers</li> <li>Wildcard domain ex: *.dev.kube-dc.com shoud be set to main public ip of master node.</li> </ol>"},{"location":"quickstart-hetzner/#server-configuration","title":"Server Configuration","text":""},{"location":"quickstart-hetzner/#1-prepare-servers","title":"1. Prepare Servers","text":"<p>Ensure your Hetzner Dedicated Servers meet these minimum requirements: - Master Node: 4+ CPU cores, 16+ GB RAM - Worker Node: 4+ CPU cores, 16+ GB RAM</p> <p>Install Ubuntu 24.04 LTS on all servers through the Hetzner Robot interface.</p>"},{"location":"quickstart-hetzner/#2-configure-vswitch","title":"2. Configure vSwitch","text":"<p>In the Hetzner Robot interface:</p> <ol> <li>Create a vSwitch if you don't have one already</li> <li>Add your servers to the vSwitch</li> <li>Request an additional subnet to be used for external IPs (Floating IPs)</li> <li>Assign the subnet to your vSwitch</li> </ol> <p>You will get two vlan ids, one for the local network(in example 4012) and one for the external subnet with public ips(in example 4011).</p>"},{"location":"quickstart-hetzner/#network-configuration","title":"Network Configuration","text":""},{"location":"quickstart-hetzner/#1-configure-network-interfaces","title":"1. Configure Network Interfaces","text":"<p>SSH into each server and configure the networking using Netplan. Edit <code>/etc/netplan/60-kube-dc.yaml</code>:</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s31f6:  # Primary network interface name (check your actual interface name)\n      addresses:\n        - 22.22.22.2/24  # Primary IP address and subnet mask (main IP provided by Herzner)\n      routes:\n        - to: 0.0.0.0/0  # Default route for all traffic\n          via: 22.22.22.1  # Gateway IP address (Also provided by Hernzer)\n          on-link: true  # Indicates the gateway is directly reachable\n          metric: 100  # Route priority (lower = higher priority)\n      routing-policy:\n        - from: 22.22.22.2  # Source-based routing for traffic from gateway\n          table: 100  # Custom routing table ID\n      nameservers:\n        addresses:\n          - 8.8.8.8  # Primary DNS server (Google)\n          - 8.8.4.4  # Secondary DNS server (Google)\n  vlans:\n    enp0s31f6.4012:  # VLAN interface name (format: interface.vlan_id)\n      id: 4012  # VLAN ID (must match your Hetzner vSwitch ID)\n      link: enp0s31f6  # Parent interface for VLAN \n      mtu: 1460  # Maximum Transmission Unit size\n      addresses:\n        - 192.168.100.2/22  # Master node IP on private network\n        # Use 192.168.100.3/22 for worker node in its config\n</code></pre> <p>Apply the configuration:</p> <pre><code>sudo netplan apply\n</code></pre>"},{"location":"quickstart-hetzner/#2-system-optimization","title":"2. System Optimization","text":"<p>On all nodes, update, upgrade, and install required software:</p> <pre><code>sudo apt -y update\nsudo apt -y upgrade\nsudo apt -y install unzip iptables\n</code></pre> <p>Optimize system settings by adding to <code>/etc/sysctl.conf</code>:</p> <pre><code># Disable IPv6\nnet.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1\n\n# Increase inotify limits\nfs.inotify.max_user_watches=1524288\nfs.inotify.max_user_instances=4024\n\n# Network optimization for Kubernetes\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\n</code></pre> <p>Apply the changes:</p> <pre><code>sudo sysctl -p\n</code></pre> <p>Disable systemd-resolved to prevent DNS conflicts:</p> <pre><code>sudo systemctl stop systemd-resolved\nsudo systemctl disable systemd-resolved\nsudo rm /etc/resolv.conf\necho \"nameserver 8.8.8.8\" | sudo tee /etc/resolv.conf\necho \"nameserver 8.8.4.4\" | sudo tee -a /etc/resolv.conf\n</code></pre> <p>Update the hosts file on each server with the private IPs:</p> <pre><code># On Master Node\necho \"192.168.100.2 kube-dc-master-1\" | sudo tee -a /etc/hosts\n# On Worker Node\necho \"192.168.100.3 kube-dc-worker-1\" | sudo tee -a /etc/hosts\n</code></pre>"},{"location":"quickstart-hetzner/#kubernetes-installation","title":"Kubernetes Installation","text":""},{"location":"quickstart-hetzner/#1-install-clusterdev","title":"1. Install Cluster.dev","text":"<p>On the master node, install Cluster.dev:</p> <pre><code>curl -fsSL https://raw.githubusercontent.com/shalb/cluster.dev/master/scripts/get_cdev.sh | sh\n</code></pre>"},{"location":"quickstart-hetzner/#2-clone-the-kube-dc-repository","title":"2. Clone the Kube-DC Repository","text":"<pre><code>git clone https://github.com/shalb/kube-dc.git\ncd kube-dc\n</code></pre>"},{"location":"quickstart-hetzner/#3-configure-and-install-rke2-on-master-node","title":"3. Configure and Install RKE2 on Master Node","text":"<p>Install kubectl:</p> <pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin/\n</code></pre> <p>Create RKE2 configuration (replace the external IP with your server's public IP):</p> <pre><code>sudo mkdir -p /etc/rancher/rke2/\n\ncat &lt;&lt;EOF | sudo tee /etc/rancher/rke2/config.yaml\nnode-name: kube-dc-master-1\ndisable-cloud-controller: true\ndisable: rke2-ingress-nginx\ncni: none\ncluster-cidr: \"10.100.0.0/16\"\nservice-cidr: \"10.101.0.0/16\"\ncluster-dns: \"10.101.0.11\"\nnode-label:\n  - kube-dc-manager=true\n  - kube-ovn/role=master\nkube-apiserver-arg: \n  - authentication-config=/etc/rancher/auth-conf.yaml\ndebug: true\nnode-external-ip: YOUR_MASTER_PUBLIC_IP # Main IP provided by Hetzner for server\ntls-san:\n  - kube-api.yourdomain.com\n  - YOUR_MASTER_PUBLIC_IP\nadvertise-address: YOUR_MASTER_PUBLIC_IP\nnode-ip: 192.168.100.2\nEOF\n\ncat &lt;&lt;EOF | sudo tee /etc/rancher/auth-conf.yaml\napiVersion: apiserver.config.k8s.io/v1beta1\nkind: AuthenticationConfiguration\njwt: []\nEOF\nsudo chmod 666 /etc/rancher/auth-conf.yaml\n</code></pre> <p>Install RKE2 server:</p> <pre><code>export INSTALL_RKE2_VERSION=\"v1.32.1+rke2r1\"\nexport INSTALL_RKE2_TYPE=\"server\"\ncurl -sfL https://get.rke2.io | sh -\nsudo systemctl enable rke2-server.service\nsudo systemctl start rke2-server.service\n</code></pre> <p>Check the installation progress:</p> <pre><code>sudo journalctl -u rke2-server -f\n</code></pre> <p>Configure kubectl:</p> <pre><code>mkdir -p ~/.kube\nsudo cp /etc/rancher/rke2/rke2.yaml ~/.kube/config\nsudo chown $(id -u):$(id -g) ~/.kube/config\nchmod 600 ~/.kube/config\n</code></pre> <p>Verify the cluster status:</p> <pre><code>kubectl get nodes\n</code></pre>"},{"location":"quickstart-hetzner/#4-join-worker-node-to-the-cluster","title":"4. Join Worker Node to the Cluster","text":"<p>Get the join token from the master node:</p> <pre><code>sudo cat /var/lib/rancher/rke2/server/node-token\n</code></pre> <p>On the worker node, create the RKE2 configuration (replace TOKEN with the token from the master node):</p> <pre><code>sudo mkdir -p /etc/rancher/rke2/\n\ncat &lt;&lt;EOF | sudo tee /etc/rancher/rke2/config.yaml\ntoken: &lt;TOKEN&gt;\nserver: https://192.168.100.2:9345 # Master node local IP\nnode-name: kube-dc-worker-1\nnode-ip: 192.168.100.3\nEOF\n</code></pre> <p>Install RKE2 agent:</p> <pre><code>export INSTALL_RKE2_VERSION=\"v1.32.1+rke2r1\"\nexport INSTALL_RKE2_TYPE=\"agent\"\ncurl -sfL https://get.rke2.io | sh -\nsudo systemctl enable rke2-agent.service\nsudo systemctl start rke2-agent.service\n</code></pre> <p>Monitor the agent service:</p> <pre><code>sudo journalctl -u rke2-agent -f\n</code></pre> <p>Verify on the master node that the worker joined successfully:</p> <pre><code>kubectl get nodes\n</code></pre>"},{"location":"quickstart-hetzner/#install-kube-dc-components","title":"Install Kube-DC Components","text":""},{"location":"quickstart-hetzner/#1-create-clusterdev-project-configuration","title":"1. Create Cluster.dev Project Configuration","text":"<p>On the master node, create a project configuration file:</p> <pre><code>mkdir -p ~/kube-dc-hetzner\ncat &lt;&lt;EOF &gt; ~/kube-dc-hetzner/project.yaml\nkind: Project\nname: kube-dc-hetzner\nvariables:\n  kubeconfig: ~/.kube/config\n  debug: true\nEOF\n</code></pre>"},{"location":"quickstart-hetzner/#2-create-clusterdev-stack-configuration","title":"2. Create Cluster.dev Stack Configuration","text":"<p>Create the stack configuration file:</p> <pre><code>cat &lt;&lt;EOF &gt; ~/kube-dc-hetzner/stack.yaml\nname: cluster\ntemplate: \"./templates/kube-dc/\"\nkind: Stack\nbackend: default\nvariables:\n  debug: \"true\"\n  kubeconfig: /home/arti/.kube/config\n\n  monitoring:\n    prom_storage: 20Gi\n    retention_size: 17GiB\n    retention: 365d\n\n  cluster_config:\n    pod_cidr: \"10.100.0.0/16\"\n    svc_cidr: \"10.101.0.0/16\"\n    join_cidr: \"100.64.0.0/16\"\n    cluster_dns: \"10.101.0.11\"\n    default_external_network:\n      nodes_list: # list of nodes, where 4011 vlan (external network) is accessible\n        - kube-dc-master-1\n        - kube-dc-worker-1\n      name: external4011\n      vlan_id: \"4011\"\n      interface: \"enp0s31f6\"\n      cidr: \"167.235.85.112/29\" # External subnet provided by Hetzner\n      gateway: 167.235.85.113 # Gateway for external subnet\n      mtu: \"1400\"\n\n  node_external_ip: 22.22.22.2 # wildcard *.dev.kube-dc.com shoud be faced on this ip\n\n  email: \"noreply@shalb.com\"\n  domain: \"dev.kube-dc.com\"\n  install_terraform: true\n\n  create_default:\n    organization:\n      name: shalb\n      description: \"My test org my-org 1\"\n      email: \"arti@shalb.com\"\n    project:\n      name: demo\n      cidr_block: \"10.1.0.0/16\"\n\n  versions:\n    kube_dc: \"v0.1.20\" # release version\n    rke2: \"v1.32.1+rke2r1\"\nEOF\n</code></pre>"},{"location":"quickstart-hetzner/#3-deploy-kube-dc","title":"3. Deploy Kube-DC","text":"<p>Run Cluster.dev to deploy Kube-DC components:</p> <pre><code>cd ~/kube-dc-hetzner\ncdev apply\n</code></pre> <p>This process will take 15-20 minutes to complete. You can monitor the deployment progress in the terminal output.</p>"},{"location":"quickstart-hetzner/#post-installation-steps","title":"Post-Installation Steps","text":""},{"location":"quickstart-hetzner/#1-access-kube-dc-ui","title":"1. Access Kube-DC UI","text":"<p>After the installation completes, the Kube-DC UI should be accessible at <code>https://kube-api.yourdomain.com</code> (if you've configured DNS) or directly via the master node's public IP.</p>"},{"location":"quickstart-hetzner/#2-set-up-initial-organization","title":"2. Set Up Initial Organization","text":"<p>Follow the on-screen instructions to create your first organization and projects.</p>"},{"location":"quickstart-hetzner/#3-configure-floating-ips-and-load-balancers","title":"3. Configure Floating IPs and Load Balancers","text":"<p>Kube-DC automatically configures the Hetzner additional subnet to provide floating IPs for your workloads. This is a wrapper on top of Kube-OVN that enables:</p> <ul> <li>Floating IP allocation: Dynamically assign public IPs to VMs and services</li> <li>Load balancer with external IPs: Distribute traffic to services with public visibility</li> <li>Default gateway per project: Isolate network traffic between projects</li> </ul> <p>These IPs can be assigned to services using the <code>LoadBalancer</code> type or directly to VMs.</p>"},{"location":"quickstart-hetzner/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues during the installation:</p> <ol> <li> <p>Check the RKE2 server/agent logs:    <pre><code>sudo journalctl -u rke2-server -f  # On master\nsudo journalctl -u rke2-agent -f   # On worker\n</code></pre></p> </li> <li> <p>Check the Kube-OVN logs:    <pre><code>kubectl logs -n kube-system -l app=kube-ovn-controller\n</code></pre></p> </li> <li> <p>Verify network connectivity between nodes on the private network:    <pre><code>ping 192.168.100.2  # From worker node\nping 192.168.100.3  # From master node\n</code></pre></p> </li> </ol> <p>For additional help, consult the Kube-DC community support resources.</p>"},{"location":"quickstart-overview/","title":"Kube-DC Installation Overview","text":"<p>This document provides a technical overview of the Kube-DC installation process, with detailed explanations of key configuration files and their parameters.</p>"},{"location":"quickstart-overview/#installation-methods","title":"Installation Methods","text":"<p>Kube-DC can be installed in several ways:</p> <ul> <li>Master-Worker deployment: Recommended starting point for new deployments</li> <li>Multi-node HA cluster: For production environments</li> <li>On top of existing Kubernetes: For extending an existing cluster</li> </ul>"},{"location":"quickstart-overview/#prerequisites","title":"Prerequisites","text":"<p>Before installing Kube-DC, ensure your system meets the following requirements:</p> <ul> <li>Hardware: Minimum 4 CPU cores, 8GB RAM per node</li> <li>Operating System: Ubuntu 20.04 LTS or newer (24.04 LTS recommended)</li> <li>Network: Dedicated network interface for VM traffic with VLAN support</li> <li>Storage: Local or network storage with support for dynamic provisioning</li> <li>Kubernetes: Version 1.31+ if installing on existing cluster</li> </ul>"},{"location":"quickstart-overview/#network-configuration","title":"Network Configuration","text":"<p>Kube-DC requires proper network configuration for optimal performance. The key requirement is that your external network must be routed through a VLAN to enable advanced networking features.</p>"},{"location":"quickstart-overview/#external-network-requirements","title":"External Network Requirements","text":"<p>Kube-DC networking is built on top of Kube-OVN and requires the following network configuration:</p> <ul> <li>VLAN-capable network interface: A dedicated network interface with VLAN support</li> <li>External subnet with routing: An external subnet that's properly routed to your infrastructure</li> <li>Static IP configuration: Static IP addressing (no DHCP) to ensure network stability</li> </ul> <p>This configuration allows Kube-DC to implement:</p> <ul> <li>Floating IP allocation: Dynamically assign public IPs to workloads</li> <li>Load balancer with external IPs: Distribute traffic to services with public visibility</li> <li>Default gateway per project: Isolate network traffic between projects</li> </ul> <p>All of these features work as a wrapper on top of Kube-OVN, providing enterprise-grade networking capabilities for your infrastructure.</p>"},{"location":"quickstart-overview/#example-network-configuration","title":"Example Network Configuration","text":"<p>Below is an example Netplan configuration with detailed comments for a VLAN-enabled network:</p> <pre><code>network:\n  version: 2  # Netplan version\n  renderer: networkd  # Network renderer to use\n  ethernets:\n    eth0:  # Primary network interface name (check your actual interface name)\n      addresses:\n        - 192.168.1.2/24  # Primary IP address and subnet mask\n      routes:\n        - to: 0.0.0.0/0  # Default route for all traffic\n          via: 192.168.1.1  # Gateway IP address\n          on-link: true  # Indicates the gateway is directly reachable\n          metric: 100  # Route priority (lower = higher priority)\n      nameservers:\n        addresses:\n          - 8.8.8.8  # Primary DNS server (Google)\n          - 8.8.4.4  # Secondary DNS server (Google)\n  vlans:\n    eth0.100:  # VLAN interface (format: interface.vlan_id)\n      id: 100  # VLAN ID\n      link: eth0  # Parent interface for VLAN \n      mtu: 1500  # Recommended MTU for your network\n      addresses:\n        - 10.100.0.2/24  # Private IP on the VLAN network\n</code></pre> <p>Important</p> <p>Do not use DHCP for the VLAN interface as it would break the initial Kube-OVN setup. Always use static IP configuration.</p>"},{"location":"quickstart-overview/#networking-components","title":"Networking Components","text":"<p>The Kube-DC network setup consists of several key components that work together:</p> <ol> <li>Kube-OVN: Core CNI providing overlay and underlay networking</li> <li>Multus CNI: Enables multiple network interfaces for pods</li> <li>VLAN Integration: Connects Kubernetes networking to physical infrastructure</li> </ol>"},{"location":"quickstart-overview/#external-network-configuration","title":"External Network Configuration","text":"<p>Kube-OVN is configured with the following settings to enable external connectivity through VLAN routing:</p> <pre><code># Subnet configuration for external connectivity\napiVersion: kubeovn.io/v1\nkind: Subnet\nmetadata:\n  name: external-network  # Network name\n  labels:\n    network.kube-dc.com/allow-projects: \"all\"  # Allow all projects to use this network\nspec:\n  protocol: IPv4  # IP protocol version\n  cidrBlock: 203.0.113.0/24  # Your allocated external subnet\n  gateway: 203.0.113.1  # Gateway IP (first IP in your external subnet)\n  vlan: vlan100  # VLAN ID reference matching your network configuration\n  mtu: 1500  # MTU size optimized for your network\n</code></pre> <pre><code># VLAN configuration\napiVersion: kubeovn.io/v1\nkind: Vlan\nmetadata:\n  name: vlan4012  # VLAN name reference\nspec:\n  id: 4012  # VLAN ID matching your Hetzner vSwitch ID\n  provider: external-network  # Provider name\n</code></pre>"},{"location":"quickstart-overview/#system-optimization","title":"System Optimization","text":"<p>For optimal performance, several system settings should be configured:</p>"},{"location":"quickstart-overview/#system-control-parameters","title":"System Control Parameters","text":"<p>Add the following to <code>/etc/sysctl.conf</code>:</p> <pre><code># Disable IPv6 to prevent issues with dual-stack networks\nnet.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1\n\n# Increase inotify limits for Kubernetes workloads\nfs.inotify.max_user_watches=1524288  # Number of watches per user\nfs.inotify.max_user_instances=4024   # Number of watch instances per user\n</code></pre>"},{"location":"quickstart-overview/#dns-configuration","title":"DNS Configuration","text":"<p>Disable <code>systemd-resolved</code> to prevent conflicts with container DNS:</p> <pre><code>systemctl stop systemd-resolved\nsystemctl disable systemd-resolved\nrm /etc/resolv.conf\necho \"nameserver 8.8.8.8\" &gt; /etc/resolv.conf\necho \"nameserver 8.8.4.4\" &gt;&gt; /etc/resolv.conf\n</code></pre>"},{"location":"quickstart-overview/#rke2-configuration","title":"RKE2 Configuration","text":"<p>RKE2 (Rancher Kubernetes Engine 2) is the preferred Kubernetes distribution for Kube-DC. The configuration differs depending on the node role:</p>"},{"location":"quickstart-overview/#initial-master-node-configuration","title":"Initial Master Node Configuration","text":"<p>Create <code>/etc/rancher/rke2/config.yaml</code> with the following parameters:</p> <pre><code>node-name: kube-dc-master-1  # Unique node name\ndisable-cloud-controller: true  # Disable default cloud controller as Kube-DC uses its own\ndisable: rke2-ingress-nginx  # Disable default ingress as Kube-DC provides its own\ncni: none  # Disable default CNI as Kube-DC uses Kube-OVN\ncluster-cidr: \"10.100.0.0/16\"  # Pod network CIDR range\nservice-cidr: \"10.101.0.0/16\"  # Service network CIDR range\ncluster-dns: \"10.101.0.11\"  # Cluster DNS service IP\nnode-label:  # Node labels used by components to identify master nodes\n  - kube-dc-manager=true  # Identifies this node for management components\n  - kube-ovn/role=master  # Identifies this node for Kube-OVN control plane\nkube-apiserver-arg:  # Additional API server arguments\n  - authentication-config=/etc/rancher/auth-conf.yaml  # Path to auth config for custom authentication\ndebug: true  # Enable debug logging\nnode-external-ip: 138.201.253.201  # External IP for this node\ntls-san:  # Subject Alternative Names for TLS certificates\n  - kube-api.dev.kube-dc.com  # DNS name for API server\n  - 138.201.253.201  # IP address for API server\nadvertise-address: 138.201.253.201  # IP address to advertise for API server\nnode-ip: 192.168.100.2  # Internal cluster IP address\n</code></pre>"},{"location":"quickstart-overview/#authentication-configuration","title":"Authentication Configuration","text":"<p>Create <code>/etc/rancher/auth-conf.yaml</code> to configure Kubernetes API authentication:</p> <pre><code>apiVersion: apiserver.config.k8s.io/v1beta1\nkind: AuthenticationConfiguration\njwt: []  # Empty JWT configuration allows for extending authentication later\n</code></pre>"},{"location":"quickstart-overview/#clusterdev-installation","title":"Cluster.dev Installation","text":"<p>Kube-DC uses Cluster.dev as the deployment tool for installing and managing components. Install it with:</p> <pre><code>curl -fsSL https://raw.githubusercontent.com/shalb/cluster.dev/master/scripts/get_cdev.sh | sh\n</code></pre>"},{"location":"quickstart-overview/#core-components","title":"Core Components","text":"<p>The Kube-DC installer deploys the following core components:</p> <ol> <li>Kube-OVN: Advanced networking solution that provides overlay and underlay networking</li> <li>Multus CNI: CNI that enables attaching multiple network interfaces to pods</li> <li>KubeVirt: Virtualization layer for running VMs on Kubernetes</li> <li>Keycloak: Identity and access management solution</li> <li>Cert-Manager: Certificate management for TLS</li> <li>Ingress-NGINX: Ingress controller for external access</li> <li>Prometheus &amp; Loki: Monitoring and logging stack</li> <li>Kube-DC Core: The core management components for Kube-DC</li> </ol>"},{"location":"quickstart-overview/#installation-process-overview","title":"Installation Process Overview","text":"<p>The installation process follows these high-level steps:</p> <ol> <li>System Preparation: Configure network, optimize system settings, and install prerequisites</li> <li>Kubernetes Installation: Install RKE2 on master and worker nodes</li> <li>Kube-DC Installation: Use cluster.dev to deploy Kube-DC components</li> <li>Post-Installation Setup: Configure authentication, networking, and initial organization</li> </ol> <p>For detailed step-by-step instructions, refer to: - Master-Worker Setup (Dedicated Servers) - Minimal HA Setup (Bare Metal) - Installing on Existing K8s</p>"},{"location":"quickstart-overview/#version-compatibility","title":"Version Compatibility","text":"<p>The main components of Kube-DC have the following version compatibility:</p> Component Minimum Version Recommended Version Kubernetes 1.31.0 1.32.1 KubeVirt 1.2.0 1.3.0 Kube-OVN 1.12.0 1.13.2 Keycloak 24.0.0 24.3.0"}]}