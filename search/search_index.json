{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"What Is Kube-DC?","text":"<p>Kube-DC is an advanced, enterprise-grade platform that transforms Kubernetes into a comprehensive Data Center solution supporting both virtual machines and containerized workloads. It provides organizations with a unified management interface for all their infrastructure needs, from multi-tenancy and virtualization to networking and billing.</p>"},{"location":"#overview","title":"Overview","text":"<p>Kube-DC bridges the gap between traditional virtualization and modern container orchestration, allowing teams to run both legacy workloads and cloud-native applications on the same platform. By leveraging Kubernetes as the foundation, Kube-DC inherits its robust ecosystem while extending functionality to support enterprise requirements.</p> <p></p>"},{"location":"#key-features-at-a-glance","title":"Key Features at a Glance","text":"<p>Kube-DC offers a comprehensive set of features designed for modern data center operations:</p> <ul> <li>Multi-Tenancy - Host multiple organizations with isolated environments and custom SSO integration</li> <li>Unified Workload Management - Run both VMs and containers on the same platform</li> <li>Advanced Networking - VPC per project, VLAN support, and software-defined networking</li> <li>Enterprise Virtualization - KubeVirt integration with GPU passthrough and live migration</li> <li>Infrastructure as Code - Kubernetes-native APIs with support for Terraform, Ansible, and more</li> <li>Integrated Billing - Track and allocate costs for all resources</li> <li>Managed Services Platform - Deploy databases, storage, and AI/ML infrastructure</li> </ul> <p>For detailed information about each feature, including capabilities and use cases, visit the Core Features page.</p>"},{"location":"#why-choose-kube-dc","title":"Why Choose Kube-DC?","text":""},{"location":"#for-enterprise-it","title":"For Enterprise IT","text":"<ul> <li>Run legacy VMs alongside modern containers</li> <li>Implement chargeback models for departmental resource usage</li> <li>Provide self-service infrastructure while maintaining governance</li> <li>Reduce operational costs by consolidating virtualization and container platforms</li> </ul>"},{"location":"#for-service-providers","title":"For Service Providers","text":"<ul> <li>Offer multi-tenant infrastructure with complete isolation</li> <li>Provide value-added services beyond basic IaaS</li> <li>Implement flexible billing based on actual resource usage</li> <li>Support diverse customer workloads on a single platform</li> </ul>"},{"location":"#for-devops-teams","title":"For DevOps Teams","text":"<ul> <li>Unify VM and container management workflows</li> <li>Implement infrastructure as code for all resources</li> <li>Integrate with existing CI/CD pipelines</li> <li>Enable developer self-service while maintaining control</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to explore Kube-DC? Check out our Quick Start guides to begin your journey.</p> <p>For a deeper understanding of the underlying architecture and concepts, visit the Architecture &amp; Concepts section.</p>"},{"location":"#community-and-support","title":"Community and Support","text":"<p>Kube-DC is built with a focus on community collaboration. Visit our Community &amp; Support page to learn how to get involved, report issues, or seek assistance.</p>"},{"location":"CODEBASE_CONTEXT/","title":"Codebase Context for Kube-DC","text":"<p>This document summarizes the codebase structure of the Kube-DC project for future reference. It serves as a single source of truth to avoid repeating exploratory analysis.</p>"},{"location":"CODEBASE_CONTEXT/#top-level-organization","title":"Top-level Organization","text":"<pre><code>.github/             # GitHub workflows and issue templates\n.vscode/             # Editor settings\napi/                 # Kubernetes CRD API definitions for kube-dc.com\ncharts/              # Helm charts for deploying Kube-DC\ncmd/                 # Controller manager entry point (main.go)\ndocs/                # User-facing documentation and architecture guides\nexamples/            # Sample manifests and usage scenarios\nhack/                # Development and automation scripts\ninternal/            # Core libraries, controllers, and utilities\ninstaller/           # Installation manifests and scripts\nservices/            # Auxiliary Kubernetes services (DB, storage, etc.)\nui/                  # Web UI (frontend and backend)\n\nDockerfile           # Container image for controller manager\nDockerfile_manager   # Alternate Dockerfile for the manager image\n.dockerignore        # Files to ignore in Docker builds\n.gitignore           # Git ignore rules\n.golangci.yml        # GolangCI-Lint configuration\nMakefile             # Build and automation targets\nPROJECT              # Project metadata\nREADME.md            # Project overview and key features\ngo.mod, go.sum       # Go module definitions\npackage-lock.json    # Node/NPM dependency lock file for UI backend\nmkdocs.yml           # MkDocs configuration for documentation site\n</code></pre>"},{"location":"CODEBASE_CONTEXT/#detailed-directory-breakdown","title":"Detailed Directory Breakdown","text":""},{"location":"CODEBASE_CONTEXT/#cmd","title":"cmd/","text":"<p>Contains the <code>main.go</code> entry point for the Kube-DC controller manager that initializes and runs Kubernetes controllers.</p>"},{"location":"CODEBASE_CONTEXT/#internal","title":"internal/","text":"<p>Modular Go packages implementing business logic and controller patterns: - service_lb/: Load balancer and external IP management - organization/: Organization CRD and Keycloak integration - eip/, fip/: External/ floating IP resource controllers - project/, organizationgroup/: CRD controllers for multi-tenancy - client/, objmgr/, controller/, utils/: Core abstractions for resource management</p>"},{"location":"CODEBASE_CONTEXT/#ui-web-ui","title":"ui/ (Web UI)","text":"<p>The <code>ui</code> directory contains the Kube\u2011DC user interface, split into two subprojects:</p>"},{"location":"CODEBASE_CONTEXT/#frontend","title":"frontend/","text":"<p>React/TypeScript single\u2011page application scaffolded from PatternFly Seed: - Entry: <code>src/index.tsx</code> and <code>src/app/</code> for layout, routing, and components - Build: Webpack configs (<code>webpack.common.js</code>, <code>webpack.dev.js</code>, <code>webpack.prod.js</code>) and scripts in <code>package.json</code> - Assets &amp; manifests: <code>kubernetes/</code> holds deployment, service, and ingress YAML for UI - Dev tools: Jest tests, Storybook (<code>stories/</code>), ESLint/Prettier, bundle analyzer, and Surge deployment (<code>dr-surge.js</code>)</p> <p><pre><code>ui/frontend/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 index.tsx\n\u2502   \u2514\u2500\u2500 app/\n\u251c\u2500\u2500 kubernetes/\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 webpack.common.js\n\u2514\u2500\u2500 README.md\n</code></pre> \u3010F:ui/frontend/README.md\u2020L1-L6\u3011\u3010F:ui/frontend/package.json\u2020L9-L16\u3011\u3010F:ui/frontend/webpack.common.js\u2020L1-L7\u3011</p>"},{"location":"CODEBASE_CONTEXT/#backend","title":"backend/","text":"<p>Node.js/Express API server that provides UI endpoints and in\u2011cluster proxies: - Server: <code>app.js</code> sets up routes, CORS, body parsing, and WebSocket proxy for VNC - Controllers: <code>controllers/</code> contains modules for cloud-shell, VMs, volumes, network, projects, metrics, system functions, etc. - Proxy: HTTP and WebSocket proxy middleware to route VNC and other traffic via Kubernetes services - Kubernetes manifests: <code>kubernetes/</code> and <code>kubernetes_service/</code> directories for deployment YAML</p> <p><pre><code>ui/backend/\n\u251c\u2500\u2500 app.js\n\u251c\u2500\u2500 controllers/\n\u2502   \u251c\u2500\u2500 cloudShellModule.js\n\u2502   \u2514\u2500\u2500 volumeModule.js\n\u251c\u2500\u2500 kubernetes/\n\u251c\u2500\u2500 package.json\n\u2514\u2500\u2500 README.md\n</code></pre> \u3010F:ui/backend/app.js\u2020L1-L20\u3011\u3010F:ui/backend/controllers/cloudShellModule.js\u2020L1-L10\u3011</p>"},{"location":"CODEBASE_CONTEXT/#hack","title":"hack/","text":"<p>Utility scripts for: - cluster setup and bootstrap - UI code updates and build automation - integration tests and version management</p>"},{"location":"CODEBASE_CONTEXT/#charts","title":"charts/","text":"<p>Helm chart definitions to deploy Kube-DC components onto a Kubernetes cluster.</p>"},{"location":"CODEBASE_CONTEXT/#docs","title":"docs/","text":"<p>Markdown files for: - Tutorials (quickstart, kubeconfig, IP &amp; LB, VMs, user groups) - Architecture (networking, virtualization, multi-tenancy, overview) - Community and support guidelines</p>"},{"location":"CODEBASE_CONTEXT/#examples","title":"examples/","text":"<p>Sample manifests demonstrating cluster API integration, VM workloads, and organization/user configurations.</p>"},{"location":"CODEBASE_CONTEXT/#installer","title":"installer/","text":"<p>Installation scripts and YAML manifests for bootstrapping the control plane and CRDs.</p>"},{"location":"CODEBASE_CONTEXT/#services","title":"services/","text":"<p>Predefined Kubernetes objects for ancillary services such as database and storage provisioning.</p>"},{"location":"CODEBASE_CONTEXT/#go-controller-manager-architecture","title":"Go Controller Manager Architecture","text":""},{"location":"CODEBASE_CONTEXT/#cmdmaingo","title":"cmd/main.go","text":"<ul> <li>Registers schemes for Kubernetes core, kube-dc CRDs, OVN, and CNI types.</li> <li>Parses flags (metrics address, leader election, Keycloak debug, HTTP/2, config secret).</li> <li>Initializes controller-runtime Manager with metrics server, health/readiness probes, and webhook server.</li> <li>Sets global configuration (ConfigSecretName, KubeDcNamespace).</li> <li>Registers Reconcilers: OrganizationReconciler, ProjectReconciler, OrganizationGroupReconciler, EIpReconciler, FIpReconciler, ServiceReconciler.</li> </ul> <p><pre><code>// Add CRD schemes and plugins; initialize Manager and register controllers\nutilruntime.Must(clientgoscheme.AddToScheme(scheme))\nutilruntime.Must(kubedccomv1.AddToScheme(scheme))\n// ...\nmgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{...})\n// ...\n(&amp;controller.OrganizationReconciler{Client: mgr.GetClient(), Scheme: mgr.GetScheme(), Debug: debug}).SetupWithManager(mgr)\n(&amp;controller.ProjectReconciler{Client: mgr.GetClient(), Scheme: mgr.GetScheme(), Debug: debug}).SetupWithManager(mgr)\n// ...\n(&amp;corecontroller.ServiceReconciler{Client: mgr.GetClient(), Scheme: mgr.GetScheme()}).SetupWithManager(mgr)\n</code></pre> \u3010F:cmd/main.go\u2020L54-L60\u3011\u3010F:cmd/main.go\u2020L169-L212\u3011</p>"},{"location":"CODEBASE_CONTEXT/#crd-types-and-schemas-apikube-dccomv1","title":"CRD Types and Schemas (api/kube-dc.com/v1)","text":"<ul> <li>Defines custom resources: Organization, Project, OrganizationGroup, EIp, FIp.</li> <li><code>*_types.go</code> files describe Spec and Status fields; <code>*_extend.go</code> adds loader and helper methods.</li> </ul> <p><pre><code>api/kube-dc.com/v1/\n\u251c\u2500\u2500 organization_types.go\n\u251c\u2500\u2500 project_types.go\n\u251c\u2500\u2500 organizationgroup_types.go\n\u251c\u2500\u2500 eip_types.go\n\u251c\u2500\u2500 fip_types.go\n\u251c\u2500\u2500 organization_extend.go\n\u2514\u2500\u2500 project_extend.go\n</code></pre> \u3010F:api/kube-dc.com/v1/organization_types.go\u2020L1-L80\u3011\u3010F:api/kube-dc.com/v1/project_types.go\u2020L1-L80\u3011</p>"},{"location":"CODEBASE_CONTEXT/#controllers-internalcontroller","title":"Controllers (internal/controller)","text":"<ul> <li>OrganizationReconciler: Manages Organization CR, delegates to internal/organization for Keycloak realm, auth config, roles, and secrets.</li> <li>ProjectReconciler: Manages Project CR, orchestrates namespace, VPC, subnet, SNAT, EIP, keypairs, roles, and DNS via internal/project.</li> <li>OrganizationGroupReconciler: Syncs OrganizationGroup CR, handling Keycloak groups and Kubernetes rolebindings.</li> <li>EIpReconciler / FIpReconciler: Reconcile external/Floating IP CRs.</li> <li>ServiceReconciler: Reconciles <code>ServiceTypeLoadBalancer</code> Services and their Endpoints; loads Project context; manages external IPs via <code>NewSvcLbEIpRes</code> and OVN-based load balancers via <code>NewLoadBalancerRes</code> in <code>service_controller.go</code>.   \u3010F:internal/controller/core/service_controller.go\u2020L52-L83\u3011\u3010F:internal/controller/core/service_controller.go\u2020L116-L140\u3011</li> </ul> <p><pre><code>internal/controller/\n\u251c\u2500\u2500 kube-dc.com/\n\u2502   \u251c\u2500\u2500 organization_controller.go\n\u2502   \u251c\u2500\u2500 project_controller.go\n\u2502   \u251c\u2500\u2500 organizatongroup_controller.go\n\u2502   \u251c\u2500\u2500 eip_controller.go\n\u2502   \u2514\u2500\u2500 fip_controller.go\n\u2514\u2500\u2500 core/\n    \u2514\u2500\u2500 service_controller.go\n</code></pre> \u3010F:internal/controller/kube-dc.com/organization_controller.go\u2020L1-L30\u3011\u3010F:internal/controller/core/service_controller.go\u2020L1-L20\u3011</p>"},{"location":"CODEBASE_CONTEXT/#business-logic-internal-packages","title":"Business Logic (internal packages)","text":"<ul> <li>internal/organization: Orchestrates Organization CR synchronization by invoking resource controllers:</li> <li><code>organization.go</code>: Sync/Delete pipeline calling NewKeycloakRealm, NewKubeAuthConfig, NewRealmRole, NewRealmAccessSeret to manage Keycloak realms, Kubernetes auth secrets, realm roles, and access secrets.     \u3010F:internal/organization/organization.go\u2020L12-L58\u3011\u3010F:internal/organization/organization.go\u2020L61-L102\u3011</li> <li>internal/project: Orchestrates Project CR lifecycle, provisioning namespaces, networking, and identities:</li> <li><code>project.go</code>: Sync/Delete pipeline calling NewProjectNamespace, NewProjectVpc, NewProjectEip, NewProjectSubnet, NewProjectNad, NewProjectSnat, NewProjectKeyPairSeret, NewProjectAuthKeySecret, NewProjectKeycloakRole, NewProjectRole, NewProjectRoleBinding, NewProjectVpcDns.     \u3010F:internal/project/project.go\u2020L13-L58\u3011\u3010F:internal/project/project.go\u2020L59-L137\u3011</li> <li>internal/organizationgroup: Manages Keycloak group and Kubernetes bindings per project.</li> <li>internal/service_lb: Implements Service LoadBalancer logic using OVN and EIp CRD:</li> <li><code>service_lb.go</code>: Defines <code>LBResource</code> which configures OVN logical router/switch load balancers (VIPs\u2192backends) via <code>NewLoadBalancerRes</code>, with <code>Sync</code>/<code>Delete</code> methods to mutate OVN NB DB.</li> <li><code>eip_res.go</code>: Defines <code>NewSvcLbEIpRes</code> to reconcile external IP addresses (EIp CRD) for services, based on annotations or project gateway, with functions to Get/Create/Delete and update status.   \u3010F:internal/service_lb/service_lb.go\u2020L30-L41\u3011\u3010F:internal/service_lb/eip_res.go\u2020L18-L27\u3011</li> <li>internal/objmgr: Generic resource manager abstractions for creating/updating Kubernetes objects.</li> <li>internal/utils: Common utilities (random names, JSON copy, resource processor).</li> </ul>"},{"location":"CODEBASE_CONTEXT/#external-integrations","title":"External Integrations","text":"<ul> <li>Keycloak via gocloak for identity management.</li> <li>OVN via kube-ovn client for software\u2011defined networking.</li> <li>NetworkAttachmentDefinitions via CNI client for custom network attachments.</li> </ul>"},{"location":"CODEBASE_CONTEXT/#metrics-healthchecks-leader-election","title":"Metrics, Healthchecks &amp; Leader Election","text":"<ul> <li>Exposes secure metrics endpoint with authentication filters.</li> <li>Readiness and liveness probes via <code>/healthz</code> and <code>/readyz</code>.</li> <li>Optional leader election for HA controller managers.</li> </ul>"},{"location":"CODEBASE_CONTEXT/#installation-via-clusterdev-infrastructure-as-code","title":"Installation via cluster.dev Infrastructure as Code","text":"<p>Kube-DC leverages the cluster.dev IaC framework (v0.9.7) to provision and deploy its control plane and dependencies.</p> <p>Under <code>installer/kube-dc</code>: - stack.yaml: Defines a <code>Stack</code> using the <code>templates/kube-dc/</code> StackTemplate to orchestrate installation units.   <pre><code>name: cluster\ntemplate: \"./templates/kube-dc/\"\nkind: Stack\n</code></pre>   \u3010F:installer/kube-dc/stack.yaml\u2020L1-L4\u3011\u3010F:go.mod\u2020L16\u3011 - project.yaml: Defines a <code>Project</code> for cluster.dev, setting owner organization and project defaults.   <pre><code>name: dev\nkind: Project\n</code></pre>   \u3010F:installer/kube-dc/project.yaml\u2020L1-L3\u3011 - templates/kube-dc/template.yaml: StackTemplate with sequential units: Terraform install, password generators, CRDs, Helm charts (kube-ovn, multus-cni, kubevirt, Keycloak, cert-manager, ingress-nginx, monitoring stack, kube-dc core), and custom shell hooks.   \u3010F:installer/kube-dc/templates/kube-dc/template.yaml\u2020L17-L23\u3011</p> <p>The installer docs demonstrate bootstrapping cluster.dev CLI and deploying the stack: - Bootstrapping cluster.dev: <code>curl -fsSL https://raw.githubusercontent.com/shalb/cluster.dev/master/scripts/get_cdev.sh | sh</code>   \u3010F:docs/quickstart-hetzner.md\u2020L175-L176\u3011 - High-level install step: \u201cKube-DC Installation: Use cluster.dev to deploy Kube-DC components\u201d   \u3010F:docs/quickstart-overview.md\u2020L104-L105\u3011</p>"},{"location":"CODEBASE_CONTEXT/#cicd-testing","title":"CI/CD &amp; Testing","text":""},{"location":"CODEBASE_CONTEXT/#github-actions-workflows","title":"GitHub Actions workflows","text":"<ul> <li>release.yaml: on tag pushes, builds and pushes Helm charts via <code>hack/build.sh</code> inside Alpine/helm container.   \u3010F:.github/workflows/release.yaml\u2020L1-L20\u3011</li> <li>sync_to_public_repo.yaml: on <code>main</code> changes to charts/examples/docs/installer/hack, syncs to the public kube-dc-public repo.   \u3010F:.github/workflows/sync_to_public_repo.yaml\u2020L1-L55\u3011</li> </ul>"},{"location":"CODEBASE_CONTEXT/#local-ci-via-makefile-go-code","title":"Local CI via Makefile (Go code)","text":"<ul> <li><code>make test</code>: run unit tests with envtest and coverage.</li> <li><code>make test-e2e</code>: run end-to-end tests via Kind.</li> <li><code>make lint</code>, <code>make fmt</code>, <code>make vet</code>: lint, format, and vet Go code.</li> <li><code>make build</code>: compile the controller manager binary.   \u3010F:Makefile\u2020L14-L23\u3011\u3010F:Makefile\u2020L27-L38\u3011\u3010F:Makefile\u2020L95-L114\u3011</li> </ul>"},{"location":"CODEBASE_CONTEXT/#frontend-ci-reacttypescript","title":"Frontend CI (React/TypeScript)","text":"<ul> <li><code>npm run ci-checks</code>: type-check, ESLint lint, and Jest coverage tests.</li> <li>Additional scripts: <code>start:dev</code>, <code>build</code>, <code>test</code>, <code>storybook</code>, <code>bundle-profile:analyze</code>.   \u3010F:ui/frontend/package.json\u2020L21-L26\u3011</li> </ul>"},{"location":"CODEBASE_CONTEXT/#backend-ci-nodejsexpress","title":"Backend CI (Node.js/Express)","text":"<ul> <li><code>npm run lint</code>: run ESLint for backend controllers.   \u3010F:ui/backend/package.json\u2020L28-L33\u3011</li> </ul>"},{"location":"CODEBASE_CONTEXT/#usage","title":"Usage","text":"<p>Refer to this file for project structure insights to avoid redundant codebase exploration.</p>"},{"location":"architecture-multi-tenancy/","title":"Multi-Tenancy &amp; RBAC","text":"<p>Kube-DC implements a comprehensive multi-tenant architecture that leverages Kubernetes namespaces and Keycloak for identity and access management. This document explains how organizations, projects, and groups in Kube-DC are mapped to Kubernetes and Keycloak objects.</p>"},{"location":"architecture-multi-tenancy/#core-components-and-mapping-structure","title":"Core Components and Mapping Structure","text":"<p>The following diagram illustrates the mapping between Kube-DC structures and the underlying Kubernetes and Keycloak components:</p> <pre><code>graph TD\n    User[User 1] --&gt;|Authenticates| KC[Keycloak Realm]\n    User --&gt;|Obtains Group and Role| KCG[Keycloak Group]\n    User --&gt;|Obtains Group and Role| KCR[Keycloak Role]\n\n    ORG[Organization] --&gt;|Maps to| ORGNS[Organization Namespace]\n\n    ORGNS --&gt;|Contains| ORGGRP[Organization Group]\n\n    PROJ[Project A] --&gt;|Maps to| PNS[Project A NS]\n    PROJ2[Project B] --&gt;|Maps to| PNS2[Project B NS]\n\n    ORGGRP --&gt;|Maps to| K8GRPCRD[Group CRD]\n    ORGGRP --&gt;|Maps to| KCGRP[Keycloak Group]\n\n    KCGRP --&gt;|Maps to| K8SROLE[K8s RoleBinding]\n    KCR --&gt;|Maps to| K8SROLE\n\n    K8GRPCRD --&gt;|Defines permissions for| PNS\n    K8GRPCRD --&gt;|Defines permissions for| PNS2\n\n    KK[Keycloak Client Role] --&gt;|KK to K8s Role Mapping| K8R[K8s Role]</code></pre>"},{"location":"architecture-multi-tenancy/#organization-structure","title":"Organization Structure","text":""},{"location":"architecture-multi-tenancy/#organization","title":"Organization","text":"<p>An Organization is the top-level entity in Kube-DC that represents a company, department, or team.</p> <p>Example Organization YAML:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: Organization\nmetadata:\n  name: shalb\n  namespace: shalb\nspec: \n  description: \"Shalb organization\"\n  email: \"arti@shalb.com\"\n</code></pre> <p>Mapping:</p> <ul> <li>Each Organization maps to a dedicated Kubernetes namespace with the same name</li> <li>A corresponding Keycloak Client is created for the organization</li> <li>The Organization serves as a logical grouping for Projects and OrganizationGroups</li> </ul>"},{"location":"architecture-multi-tenancy/#project","title":"Project","text":"<p>A Project represents a logical grouping of resources within an Organization. Projects help segregate workloads and manage access control.</p> <p>Example Project YAML:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: Project\nmetadata:\n  name: demo\n  namespace: shalb\nspec:\n  cidrBlock: \"10.0.10.0/24\"\n</code></pre> <p>Mapping:</p> <ul> <li>Each Project maps to a dedicated Kubernetes namespace in the format: <code>{organization}-{project}</code> (e.g., <code>shalb-demo</code>)</li> <li>Projects receive their own network CIDR block for resource isolation</li> <li>Kubernetes namespaces provide the boundary for resource quotas and access control</li> </ul>"},{"location":"architecture-multi-tenancy/#organizationgroup","title":"OrganizationGroup","text":"<p>An OrganizationGroup maps users to roles within specific projects, defining what actions they can perform.</p> <p>Example OrganizationGroup YAML:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: OrganizationGroup\nmetadata:\n  name: \"app-manager\"\n  namespace: shalb\nspec:\n  permissions:\n  - project: \"demo\"\n    roles:\n    - admin\n  - project: \"prod\"\n    roles:\n    - resource-manager\n</code></pre> <p>Mapping:</p> <ul> <li>OrganizationGroups are implemented as Kubernetes Custom Resource Definitions (CRDs)</li> <li>Each OrganizationGroup maps to a Keycloak Group</li> <li>The permissions defined in OrganizationGroups determine the Kubernetes RoleBindings that grant access to resources</li> <li>Different roles can be assigned for different projects</li> </ul>"},{"location":"architecture-multi-tenancy/#authentication-and-authorization-flow","title":"Authentication and Authorization Flow","text":"<p>User Authentication:</p> <ul> <li>Users authenticate through Keycloak</li> <li>Upon successful authentication, users receive JSON Web Tokens (JWTs)</li> </ul> <p>Group and Role Assignment:</p> <ul> <li>Users are assigned to Keycloak Groups based on their OrganizationGroup membership</li> <li>Keycloak maps these groups to corresponding roles</li> </ul> <p>Kubernetes Authorization:</p> <ul> <li>The Kubernetes API server validates the user's JWT</li> <li>RoleBindings determine what actions the user can perform within each namespace</li> <li>Resource access is controlled at the Project (namespace) level</li> </ul> <p>Resource Access:</p> <ul> <li>Users can only access resources in projects where they have appropriate role assignments</li> <li>Actions are restricted based on the permissions defined in their roles</li> </ul>"},{"location":"architecture-multi-tenancy/#role-based-access-control","title":"Role-Based Access Control","text":"<p>Kube-DC provides several built-in roles that can be assigned to users via OrganizationGroups:</p> <ul> <li>Admin: Full access to all resources within a project</li> <li>Resource Manager: Can create and manage resources, but cannot modify project settings</li> <li>Viewer: Read-only access to project resources</li> </ul> <p>Example Role YAML:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: Role\nmetadata:\n  name: resource-manager\n  namespace: shalb\nspec:\n  rules:\n  - apiGroups: [\"*\"]\n    resources: [\"pods\", \"services\", \"deployments\", \"statefulsets\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n  - apiGroups: [\"kubevirt.io\"]\n    resources: [\"virtualmachines\", \"virtualmachineinstances\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n</code></pre>"},{"location":"architecture-multi-tenancy/#implementation-details","title":"Implementation Details","text":""},{"location":"architecture-multi-tenancy/#kubernetes-components","title":"Kubernetes Components","text":"<ul> <li>Namespaces: Used to isolate Organizations and Projects</li> <li>RBAC: Role-Based Access Control for managing permissions</li> <li>CRDs: Custom Resource Definitions for Kube-DC specific resources</li> <li>NetworkPolicies: Ensure network isolation between Projects</li> </ul>"},{"location":"architecture-multi-tenancy/#keycloak-integration","title":"Keycloak Integration","text":"<ul> <li>Realm: Represents the authentication domain</li> <li>Clients: Each Organization has a dedicated client</li> <li>Groups: Map to OrganizationGroups in Kube-DC</li> <li>Roles: Define permissions that can be assigned to users</li> <li>Role Mappings: Connect Keycloak roles to Kubernetes RBAC</li> </ul>"},{"location":"architecture-multi-tenancy/#practical-application","title":"Practical Application","text":"<p>When a user is added to an organization group in Kube-DC:</p> <ol> <li>The corresponding Keycloak group membership is created</li> <li>The user inherits roles based on the group's permissions</li> <li>When the user accesses the Kubernetes API, their JWT contains the group and role information</li> <li>Kubernetes RBAC evaluates the JWT against RoleBindings to determine access</li> <li>The user can operate only within the boundaries of their assigned permissions</li> </ol> <p>This multi-layered approach ensures secure isolation between tenants while providing fine-grained access control within each project.</p>"},{"location":"architecture-networking/","title":"Networking Architecture","text":"<p>Kube-DC provides enterprise-grade networking through Kube-OVN and Envoy Gateway, enabling multi-tenant isolation, flexible service exposure, and automatic TLS management.</p>"},{"location":"architecture-networking/#quick-navigation","title":"Quick Navigation","text":"Section Description Network Types Cloud vs Public networks Physical Layer VLANs and provider bridges OVN Architecture VPCs, subnets, routers Service Exposure LoadBalancers, Gateway Routes Envoy Gateway HTTP/HTTPS/gRPC routing"},{"location":"architecture-networking/#network-types","title":"Network Types","text":"<p>Kube-DC supports two external network types:</p> Type Subnet IP Range Internet Routable Use Case Cloud <code>ext-cloud</code> 100.65.0.0/16 \u274c No (NAT pool) Web apps, APIs, cost-effective Public <code>ext-public</code> 168.119.17.48/28 \u2705 Yes VMs, game servers, direct access"},{"location":"architecture-networking/#physical-network-layer","title":"Physical Network Layer","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         PHYSICAL NETWORK                                    \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502      VLAN 4011          \u2502              \u2502      VLAN 4013          \u2502       \u2502\n\u2502  \u2502      ext-public         \u2502              \u2502      ext-cloud          \u2502       \u2502\n\u2502  \u2502   168.119.17.48/28      \u2502              \u2502   100.65.0.0/16         \u2502       \u2502\n\u2502  \u2502                         \u2502              \u2502                         \u2502       \u2502\n\u2502  \u2502   Gateway: 168.119.17.49\u2502              \u2502   Gateway: 100.65.0.1   \u2502       \u2502\n\u2502  \u2502   Internet-routable     \u2502              \u2502   Internal-only         \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502              \u2502                                        \u2502                     \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502                               \u2502                                             \u2502\n\u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                   \u2502\n\u2502                     \u2502   Provider Bridge \u2502                                   \u2502\n\u2502                     \u2502   br-ext-cloud    \u2502                                   \u2502\n\u2502                     \u2502   (on each node)  \u2502                                   \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              OVN NETWORK                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-networking/#ovn-logical-network","title":"OVN Logical Network","text":""},{"location":"architecture-networking/#management-vpc-ovn-cluster","title":"Management VPC (ovn-cluster)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          ovn-cluster VPC (Management)                          \u2502\n\u2502                                                                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502   ovn-default   \u2502  \u2502    ext-cloud    \u2502  \u2502   ext-public    \u2502  \u2502   join    \u2502 \u2502\n\u2502   \u2502  10.100.0.0/16  \u2502  \u2502  100.65.0.0/16  \u2502  \u2502168.119.17.48/28 \u2502  \u2502172.30.0.0 \u2502 \u2502\n\u2502   \u2502                 \u2502  \u2502                 \u2502  \u2502                 \u2502  \u2502   /22     \u2502 \u2502\n\u2502   \u2502 \u2022 kube-system   \u2502  \u2502 \u2022 Cloud LB VIPs \u2502  \u2502 \u2022 Public LB VIPs\u2502  \u2502 \u2022 Node IPs\u2502 \u2502\n\u2502   \u2502 \u2022 envoy-gateway \u2502  \u2502 \u2022 Cloud EIPs    \u2502  \u2502 \u2022 Public EIPs   \u2502  \u2502           \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502            \u2502                    \u2502                    \u2502                 \u2502       \u2502\n\u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                 \u2502                    \u2502                         \u2502\n\u2502                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502                       \u2502         ovn-cluster Router             \u2502               \u2502\n\u2502                       \u2502                                        \u2502               \u2502\n\u2502                       \u2502  Ports:                                \u2502               \u2502\n\u2502                       \u2502  \u2022 ovn-default: 10.100.0.1             \u2502               \u2502\n\u2502                       \u2502  \u2022 ext-cloud: 100.65.0.101             \u2502               \u2502\n\u2502                       \u2502  \u2022 join: 172.30.0.1                    \u2502               \u2502\n\u2502                       \u2502                                        \u2502               \u2502\n\u2502                       \u2502  SNAT: 10.100.0.0/16 \u2192 100.65.0.101    \u2502               \u2502\n\u2502                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-networking/#project-vpcs","title":"Project VPCs","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Cloud Project VPC             \u2502  \u2502   Public Project VPC            \u2502\n\u2502   (egressNetworkType: cloud)    \u2502  \u2502   (egressNetworkType: public)   \u2502\n\u2502                                 \u2502  \u2502                                 \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  project-a-default      \u2502   \u2502  \u2502   \u2502  project-b-default      \u2502   \u2502\n\u2502   \u2502     10.0.10.0/24        \u2502   \u2502  \u2502   \u2502     10.0.20.0/24        \u2502   \u2502\n\u2502   \u2502                         \u2502   \u2502  \u2502   \u2502                         \u2502   \u2502\n\u2502   \u2502  \u2022 Customer pods        \u2502   \u2502  \u2502   \u2502  \u2022 Customer pods        \u2502   \u2502\n\u2502   \u2502  \u2022 Customer VMs         \u2502   \u2502  \u2502   \u2502  \u2022 Customer VMs         \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502               \u2502                 \u2502  \u2502               \u2502                 \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  project-a Router       \u2502   \u2502  \u2502   \u2502  project-b Router       \u2502   \u2502\n\u2502   \u2502                         \u2502   \u2502  \u2502   \u2502                         \u2502   \u2502\n\u2502   \u2502  EIP: 100.65.0.102      \u2502   \u2502  \u2502   \u2502  EIP: 168.119.17.51     \u2502   \u2502\n\u2502   \u2502  (ext-cloud)            \u2502   \u2502  \u2502   \u2502  (ext-public)           \u2502   \u2502\n\u2502   \u2502                         \u2502   \u2502  \u2502   \u2502                         \u2502   \u2502\n\u2502   \u2502  SNAT: 10.0.10.0/24     \u2502   \u2502  \u2502   \u2502  SNAT: 10.0.20.0/24     \u2502   \u2502\n\u2502   \u2502       \u2192 100.65.0.102    \u2502   \u2502  \u2502   \u2502       \u2192 168.119.17.51   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-networking/#subnet-summary","title":"Subnet Summary","text":"Subnet VPC CIDR Purpose <code>ovn-default</code> ovn-cluster 10.100.0.0/16 Management pods <code>ext-cloud</code> ovn-cluster 100.65.0.0/16 Cloud LB VIPs, EIPs <code>ext-public</code> ovn-cluster 168.119.17.48/28 Public LB VIPs, EIPs <code>join</code> ovn-cluster 172.30.0.0/22 Node-to-OVN connectivity <code>{project}-default</code> {project} 10.x.x.x/24 Customer pods/VMs"},{"location":"architecture-networking/#service-exposure","title":"Service Exposure","text":"<p>Kube-DC provides multiple ways to expose services:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         SERVICE EXPOSURE OPTIONS                                \u2502\n\u2502                                                                                 \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      1. Gateway Routes (Recommended)                    \u2502   \u2502\n\u2502   \u2502                                                                         \u2502   \u2502\n\u2502   \u2502   Internet \u2192 Envoy Gateway (88.99.29.250:443) \u2192 HTTPRoute \u2192 Service     \u2502   \u2502\n\u2502   \u2502                                                                         \u2502   \u2502\n\u2502   \u2502   -  Automatic TLS certificates                                         \u2502   \u2502\n\u2502   \u2502   -  Auto-generated hostnames                                           \u2502   \u2502\n\u2502   \u2502   -  Shared infrastructure (cost-effective)                             \u2502   \u2502\n\u2502   \u2502   -  HTTP/HTTPS/gRPC support                                            \u2502   \u2502\n\u2502   \u2502                                                                         \u2502   \u2502\n\u2502   \u2502   Annotations:                                                          \u2502   \u2502\n\u2502   \u2502   \u2022 expose-route: https                                                 \u2502   \u2502\n\u2502   \u2502   \u2022 route-hostname: custom.domain.com (optional)                        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                                 \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      2. EIP + LoadBalancer                              \u2502   \u2502\n\u2502   \u2502                                                                         \u2502   \u2502\n\u2502   \u2502   Internet \u2192 EIP (dedicated IP) \u2192 OVN LB \u2192 Service \u2192 Pods/VMs           \u2502   \u2502\n\u2502   \u2502                                                                         \u2502   \u2502\n\u2502   \u2502   -  Dedicated IP address                                               \u2502   \u2502\n\u2502   \u2502   -  Any TCP/UDP protocol                                               \u2502   \u2502\n\u2502   \u2502   -  Direct VM access                                                   \u2502   \u2502\n\u2502   \u2502                                                                         \u2502   \u2502\n\u2502   \u2502   Annotations:                                                          \u2502   \u2502\n\u2502   \u2502   \u2022 bind-on-default-gw-eip: \"true\"                                      \u2502   \u2502\n\u2502   \u2502   \u2022 bind-on-eip: \"my-eip\"                                               \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                                 \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                      3. Floating IP (FIP)                               \u2502   \u2502\n\u2502   \u2502                                                                         \u2502   \u2502\n\u2502   \u2502   Internet \u2192 EIP \u2192 1:1 NAT \u2192 Internal IP (VM/Pod)                       \u2502   \u2502\n\u2502   \u2502                                                                         \u2502   \u2502\n\u2502   \u2502   -  Direct IP mapping                                                  \u2502   \u2502\n\u2502   \u2502   -  VM sees public IP                                                  \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-networking/#network-elements","title":"Network Elements","text":""},{"location":"architecture-networking/#user-visible-network-resources","title":"User-Visible Network Resources","text":""},{"location":"architecture-networking/#external-ip-eip","title":"External IP (EIP)","text":"<p>External IPs provide connectivity from the public internet to resources within Kube-DC. Each EIP is allocated from the provider network.</p> <p>Example EIP YAML:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: EIp\nmetadata:\n  name: ssh-arti\n  namespace: shalb-demo\nspec: {}  \n</code></pre>"},{"location":"architecture-networking/#floating-ip-fip","title":"Floating IP (FIP)","text":"<p>Floating IPs map an internal IP address (of a VM or pod) to an External IP, enabling direct access to specific resources.</p> <p>Example FIP YAML:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: FIp\nmetadata:\n  name: fedora-arti\n  namespace: shalb-demo\nspec:\n  ipAddress: 10.0.10.171\n  eip: ssh-arti\n</code></pre>"},{"location":"architecture-networking/#kubernetes-service","title":"Kubernetes Service","text":"<p>Standard Kubernetes Services for in-cluster service discovery and load balancing.</p>"},{"location":"architecture-networking/#service-type-loadbalancer","title":"Service Type LoadBalancer","text":"<p>Creates and maps an EIP to a service that routes traffic to pods or VMs. Can use either a dedicated EIP or the project's default EIP.</p> <p>Example Service LoadBalancer YAML with default gateway EIP:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service-lb\n  namespace: shalb-demo\n  annotations:\n    service.nlb.kube-dc.com/bind-on-default-gw-eip: \"true\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: nginx\n  ports:\n    - name: http\n      protocol: TCP\n      port: 80\n      targetPort: 80\n    - name: https\n      protocol: TCP\n      port: 443\n      targetPort: 443\n</code></pre> <p>Example Service LoadBalancer for VM SSH access:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: vm-ssh\n  namespace: shalb-demo\n  annotations:\n    service.nlb.kube-dc.com/bind-on-default-gw-eip: \"true\"\nspec:\n  type: LoadBalancer\n  selector:\n    vm.kubevirt.io/name: debian\n  ports:\n    - name: ssh\n      protocol: TCP\n      port: 2222\n      targetPort: 22\n</code></pre>"},{"location":"architecture-networking/#internal-network-resources","title":"Internal Network Resources","text":""},{"location":"architecture-networking/#dnat-rule","title":"DNAT Rule","text":"<p>Destination Network Address Translation rules proxy requests from the internet through an EIP to resources within the VPC network. These are created automatically when an EIP is associated with a resource.</p>"},{"location":"architecture-networking/#snat","title":"SNAT","text":"<p>Source Network Address Translation is used for outbound connections from VPC subnets through EIPs, allowing resources within the VPC to communicate with the internet.</p>"},{"location":"architecture-networking/#project-network-provisioning","title":"Project Network Provisioning","text":"<p>When a new project is created in Kube-DC:</p> <ol> <li>The project is allocated a dedicated subnet from the VPC CIDR range</li> <li>Each project connected to the internet receives an EIP</li> <li>All project outbound traffic is routed through its assigned EIP</li> <li>Project-specific network policies are applied for isolation</li> </ol> <p>Example project creation with CIDR allocation:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: Project\nmetadata:\n  name: demo\n  namespace: shalb\nspec:\n  cidrBlock: \"10.0.10.0/24\"\n</code></pre>"},{"location":"architecture-networking/#load-balancer-implementation","title":"Load Balancer Implementation","text":"<p>Kube-DC uses a specialized implementation for Service LoadBalancers:</p> <ul> <li>When a Service with type <code>LoadBalancer</code> is created, an OVS-based LoadBalancer routes traffic to service endpoints</li> <li>Endpoints can be Kubernetes pods or KubeVirt VMs</li> <li>The LoadBalancer can use either:</li> <li>The project's default gateway EIP (with annotation <code>service.nlb.kube-dc.com/bind-on-default-gw-eip: \"true\"</code>)</li> <li>A dedicated EIP (with annotation <code>service.nlb.kube-dc.com/bind-on-eip: \"eip-name\"</code>)</li> </ul>"},{"location":"architecture-networking/#automatic-external-endpoints-v0134","title":"Automatic External Endpoints (v0.1.34+)","text":"<p>Kube-DC automatically creates external endpoints for LoadBalancer services to enable cross-VPC communication.</p> <p>When a LoadBalancer receives an external IP, the controller creates: - External Service (<code>&lt;service-name&gt;-ext</code>): Headless service - Endpoints (<code>&lt;service-name&gt;-ext</code>): Points to the LoadBalancer's external IP</p> <p>This solves cross-VPC access by providing stable DNS names (e.g., <code>etcd-lb-ext.shalb-envoy.svc.cluster.local</code>) instead of hardcoded IPs. Endpoints are automatically updated when IPs change and deleted with the LoadBalancer service.</p> <p>External endpoints are labeled with <code>kube-dc.com/managed-by: service-lb-controller</code>.</p>"},{"location":"architecture-networking/#kube-ovn-for-vpc-management","title":"Kube-OVN for VPC Management","text":"<p>Kube-OVN is a key component of Kube-DC's networking architecture, providing the foundation for multi-tenant network isolation through VPC networks.</p>"},{"location":"architecture-networking/#vpc-isolation","title":"VPC Isolation","text":"<p>Different VPC networks are independent of each other and can be separately configured with: - Subnet CIDRs - Routing policies - Security policies - Outbound gateways - EIP allocations</p>"},{"location":"architecture-networking/#overlay-vs-underlay-networks","title":"Overlay vs. Underlay Networks","text":"<p>Kube-DC supports both networking approaches:</p>"},{"location":"architecture-networking/#overlay-networks","title":"Overlay Networks","text":"<ul> <li>Software-defined networks that encapsulate packets</li> <li>Provide maximum flexibility for network segmentation</li> <li>Independent of physical network topology</li> <li>Managed entirely by Kube-OVN</li> <li>Ideal for multi-tenant environments</li> </ul>"},{"location":"architecture-networking/#underlay-networks","title":"Underlay Networks","text":"<ul> <li>Direct mapping to physical network infrastructure</li> <li>Better performance with reduced encapsulation overhead</li> <li>Requires coordination with physical network infrastructure</li> <li>Physical switches handle data-plane forwarding</li> <li>Cannot be isolated by VPCs as they are managed by physical switches</li> </ul>"},{"location":"architecture-networking/#network-security","title":"Network Security","text":"<p>Kube-DC implements multiple layers of network security:</p> <p>Project Isolation</p> <ul> <li>Each project receives its own subnet</li> <li>Traffic between projects is controlled by network policies</li> </ul> <p>VPC Segmentation</p> <ul> <li>Projects can be placed in different VPCs for stricter isolation</li> <li>Each VPC has its own network stack and routing tables</li> </ul> <p>Kubernetes Network Policies</p> <ul> <li>Fine-grained control over ingress and egress traffic</li> <li>Can be applied at the namespace, pod, or service level</li> </ul> <p>Subnet ACLs</p> <ul> <li>Control traffic at the subnet level</li> <li>Provide an additional layer of security beyond network policies</li> </ul>"},{"location":"architecture-networking/#envoy-gateway","title":"Envoy Gateway","text":"<p>Envoy Gateway provides HTTP/HTTPS/gRPC routing with automatic TLS management.</p>"},{"location":"architecture-networking/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         ENVOY GATEWAY ARCHITECTURE                           \u2502\n\u2502                                                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                    envoy-gateway-system namespace                     \u2502  \u2502\n\u2502   \u2502                    (in ovn-default subnet: 10.100.0.0/16)             \u2502  \u2502\n\u2502   \u2502                                                                       \u2502  \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502   \u2502   \u2502  Envoy Gateway         \u2502     \u2502  Envoy Proxy Pod               \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  Controller            \u2502     \u2502                                \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502                        \u2502     \u2502  Listens on:                   \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  \u2022 Watches Gateway,    \u2502     \u2502  \u2022 :443 (HTTPS)                \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502    HTTPRoute, TLSRoute \u2502     \u2502  \u2022 :80 (HTTP)                  \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  \u2022 Manages certs       \u2502     \u2502                                \u2502   \u2502  \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502   \u2502                                                   \u2502                   \u2502  \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502   \u2502   \u2502  Gateway: eg                                                  \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502                                                               \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  Listeners:                                                   \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  \u2022 http (80)    - Redirect to HTTPS / ACME challenges         \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  \u2022 https (443)  - Dynamic per-service listeners               \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  \u2022 tls (443)    - TLS passthrough for Kubernetes API          \u2502   \u2502  \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                              \u2502\n\u2502                                        \u2502                                     \u2502\n\u2502                                        \u2502 externalIPs: 88.99.29.250           \u2502\n\u2502                                        \u25bc                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                         TRAFFIC FLOW                                  \u2502  \u2502\n\u2502   \u2502                                                                       \u2502  \u2502\n\u2502   \u2502   Client (https://my-app.stage.kube-dc.com)                           \u2502  \u2502\n\u2502   \u2502         \u2502                                                             \u2502  \u2502\n\u2502   \u2502         \u25bc                                                             \u2502  \u2502\n\u2502   \u2502   DNS \u2192 88.99.29.250 (Gateway external IP)                            \u2502  \u2502\n\u2502   \u2502         \u2502                                                             \u2502  \u2502\n\u2502   \u2502         \u25bc                                                             \u2502  \u2502\n\u2502   \u2502   Envoy Gateway (TLS termination with auto-cert)                      \u2502  \u2502\n\u2502   \u2502         \u2502                                                             \u2502  \u2502\n\u2502   \u2502         \u25bc HTTPRoute matches hostname                                  \u2502  \u2502\n\u2502   \u2502   Backend Service (in customer namespace)                             \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-networking/#gateway-route-flow","title":"Gateway Route Flow","text":"<p>When a service with <code>expose-route: https</code> annotation is created:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     GATEWAY ROUTE CREATION FLOW                             \u2502\n\u2502                                                                             \u2502\n\u2502   1. Service Created                                                        \u2502\n\u2502      \u2514\u2500\u25ba annotations:                                                       \u2502\n\u2502            service.nlb.kube-dc.com/expose-route: \"https\"                    \u2502\n\u2502                                                                             \u2502\n\u2502   2. Controller Creates:                                                    \u2502\n\u2502      \u251c\u2500\u25ba Certificate (cert-manager)                                         \u2502\n\u2502      \u2502     name: my-app-tls                                                 \u2502\n\u2502      \u2502     issuer: letsencrypt                                              \u2502\n\u2502      \u2502                                                                      \u2502\n\u2502      \u251c\u2500\u25ba Gateway Listener (patched into Gateway)                            \u2502\n\u2502      \u2502     name: https-my-app-namespace                                     \u2502\n\u2502      \u2502     port: 443                                                        \u2502\n\u2502      \u2502     hostname: my-app-namespace.stage.kube-dc.com                     \u2502\n\u2502      \u2502     certificateRef: my-app-tls                                       \u2502\n\u2502      \u2502                                                                      \u2502\n\u2502      \u251c\u2500\u25ba HTTPRoute                                                          \u2502\n\u2502      \u2502     parentRef: Gateway/eg (listener: https-my-app-namespace)         \u2502\n\u2502      \u2502     backendRef: Service/my-app                                       \u2502\n\u2502      \u2502                                                                      \u2502\n\u2502      \u2514\u2500\u25ba ReferenceGrant (if cross-namespace)                                \u2502\n\u2502                                                                             \u2502\n\u2502   3. Status Updated:                                                        \u2502\n\u2502      \u2514\u2500\u25ba route-hostname-status: my-app-namespace.stage.kube-dc.com          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-networking/#route-types","title":"Route Types","text":"Type Port TLS Handling Use Case <code>http</code> 80 None Plain HTTP traffic <code>https</code> 443 Gateway terminates (auto-cert) Web apps, APIs <code>tls-passthrough</code> 443 App terminates Kubernetes API, end-to-end encryption"},{"location":"architecture-networking/#related-documentation","title":"Related Documentation","text":"<ul> <li>Service Exposure Guide - How to expose services</li> <li>Virtual Machines - VM networking</li> <li>User &amp; Group Management - RBAC for network resources</li> </ul>"},{"location":"architecture-overview/","title":"Overall Architecture","text":"<p>Kube-DC provides a comprehensive multi-tenant cloud infrastructure platform built on Kubernetes and enhanced with enterprise-grade features like virtualization, networking, and identity management.</p>"},{"location":"architecture-overview/#core-components","title":"Core Components","text":"<p>The Kube-DC architecture consists of several key components that work together to deliver a complete cloud platform:</p> <p></p>"},{"location":"architecture-overview/#architectural-layers","title":"Architectural Layers","text":"<p>Kube-DC is organized into main architectural layers:</p> <pre><code>graph TD\n    K8s[Kubernetes] --&gt; KubeVirt[KubeVirt]    \n    K8s --&gt; KubeOVN[Kube-OVN]    \n    K8s --&gt; Keycloak[Keycloak]    \n    K8s --&gt; LBController[Kube-DC LB Controller]    \n    K8s --&gt; MultiTenant[Multi-Tenant Controller]\n\n    KubeVirt --&gt;|Provides| VMs[Virtual Machines]\n    KubeOVN --&gt;|Manages| Networking[Network VLANs/VPCs]\n    Keycloak --&gt;|Controls| IAM[Identity &amp; Access]\n    LBController --&gt;|Enables| LoadBalancing[Load Balancing, Floating IPs]\n    MultiTenant --&gt;|Organizes| Resources[Organization and Projects]</code></pre> <p>Infrastructure Layer</p> <ul> <li>Bare metal servers or cloud infrastructure</li> <li>Kubernetes core services</li> <li>Storage subsystems</li> </ul> <p>Virtualization Layer</p> <ul> <li>KubeVirt for VM provisioning and management</li> <li>Container workloads</li> <li>Hybrid application support</li> </ul> <p>Networking Layer</p> <ul> <li>Kube-OVN for software-defined networking</li> <li>Multi-tenant network isolation</li> <li>External IP addressing and service exposure</li> </ul> <p>Management Layer</p> <ul> <li>Multi-tenancy resource organization</li> <li>Identity and access management via Keycloak</li> <li>User interface and API access</li> </ul>"},{"location":"architecture-overview/#multi-tenant-organization","title":"Multi-Tenant Organization","text":"<p>Kube-DC introduces a hierarchical resource organization model:</p> <ul> <li>Organizations - Top-level entities representing companies or teams</li> <li>Projects - Logical groupings of resources within an organization</li> <li>Groups - Collections of users with defined roles and permissions</li> </ul> <p>This multi-tenant structure maps to Kubernetes and Keycloak components to provide isolation and access control. For detailed information on the multi-tenancy architecture, see the Multi-Tenancy &amp; RBAC documentation.</p>"},{"location":"architecture-overview/#network-architecture","title":"Network Architecture","text":"<p>Kube-DC leverages Kube-OVN to provide advanced networking capabilities:</p> <ul> <li>Virtual Private Clouds (VPCs) for network isolation</li> <li>External and Floating IPs for service exposure</li> <li>Load balancing and service routing</li> </ul> <p>For detailed information on the networking architecture, see the Networking (Kube-OVN, VLANs) documentation.</p>"},{"location":"architecture-overview/#virtualization-architecture","title":"Virtualization Architecture","text":"<p>Kube-DC integrates KubeVirt to enable VM workloads alongside containers:</p> <ul> <li>VM lifecycle management through Kubernetes APIs</li> <li>Hardware passthrough capabilities</li> <li>Mixed container and VM environments</li> </ul> <p>For detailed information on the virtualization architecture, see the Virtualization (KubeVirt) documentation.</p>"},{"location":"architecture-overview/#key-benefits","title":"Key Benefits","text":"<ul> <li>Multi-tenant isolation: Secure separation between organizations and projects</li> <li>Unified management: Single platform for VMs and containers</li> <li>Network flexibility: Advanced SDN capabilities with Kube-OVN</li> <li>Enterprise security: Integrated identity management with Keycloak</li> <li>API-driven architecture: Consistent interfaces for automation and integration</li> </ul>"},{"location":"architecture-virtualization/","title":"Virtualization (KubeVirt)","text":"<p>Kube-DC leverages KubeVirt to provide powerful virtual machine capabilities alongside traditional container workloads. This document covers the virtualization architecture, features, and how VMs are managed within the platform.</p>"},{"location":"architecture-virtualization/#virtualization-architecture","title":"Virtualization Architecture","text":"<p>Kube-DC's virtualization layer is built on KubeVirt, which extends Kubernetes to support virtual machine workloads. This architecture enables consistent management of both containers and VMs through the same API and tooling.</p> <pre><code>graph TD\n    K8s[Kubernetes API] --&gt; KV[KubeVirt Controller]\n    K8s --&gt; CDI[Containerized Data Importer]\n\n    KV --&gt; VMI[VM Instances]\n    CDI --&gt; DV[Data Volumes]\n\n    VMI --&gt; POD[VM Pods]\n    DV --&gt; PVC[Persistent Volumes]\n\n    subgraph \"VM Management\"\n        KV\n        VMI\n        POD\n    end\n\n    subgraph \"Storage Management\"\n        CDI\n        DV\n        PVC\n    end\n\n    UI[Kube-DC Dashboard] --&gt; K8s\n    CLI[kubectl/virtctl] --&gt; K8s</code></pre>"},{"location":"architecture-virtualization/#core-components","title":"Core Components","text":""},{"location":"architecture-virtualization/#kubevirt-controller","title":"KubeVirt Controller","text":"<p>The KubeVirt controller manages the lifecycle of virtual machines by:</p> <ul> <li>Translating VM specifications into Kubernetes resources</li> <li>Scheduling VMs on appropriate nodes</li> <li>Managing VM state (start, stop, pause, resume)</li> <li>Providing VM migration capabilities</li> <li>Handling VM monitoring and health checks</li> </ul>"},{"location":"architecture-virtualization/#containerized-data-importer-cdi","title":"Containerized Data Importer (CDI)","text":"<p>CDI handles storage provisioning for VMs by:</p> <ul> <li>Creating and managing Data Volumes</li> <li>Importing disk images from HTTP/S3 sources</li> <li>Converting disk formats as needed</li> <li>Cloning existing volumes</li> </ul>"},{"location":"architecture-virtualization/#data-volumes","title":"Data Volumes","text":"<p>Data Volumes serve as the storage backbone for VMs, providing:</p> <ul> <li>Storage allocation for VM disks</li> <li>Integration with Kubernetes storage classes</li> <li>Automated provisioning and cleanup</li> </ul>"},{"location":"architecture-virtualization/#vm-management-in-kube-dc","title":"VM Management in Kube-DC","text":""},{"location":"architecture-virtualization/#vm-creation-and-configuration","title":"VM Creation and Configuration","text":"<p>Kube-DC allows users to create VMs through YAML definitions or the web UI. VM configurations include:</p> <p>Example VM Definition:</p> <pre><code>apiVersion: kubevirt.io/v1\nkind: VirtualMachine\nmetadata:\n  name: ubuntu-vm\n  namespace: demo\nspec:\n  running: true\n  template:\n    spec:\n      networks:\n      - name: vpc_net_0\n        multus:\n          default: true\n          networkName: default/ovn-demo\n      domain:\n        devices:\n          interfaces:\n            - name: vpc_net_0\n              bridge: {}\n          disks:\n          - disk: \n              bus: virtio\n            name: root-volume\n        cpu:\n          cores: 2\n        memory:\n          guest: 4G\n      volumes:\n      - dataVolume:\n          name: ubuntu-base-img\n        name: root-volume\n</code></pre>"},{"location":"architecture-virtualization/#supported-operating-systems","title":"Supported Operating Systems","text":"<p>Kube-DC provides templates for a variety of operating systems:</p> <ul> <li>Ubuntu (20.04, 22.04, 24.04)</li> <li>Debian</li> <li>CentOS/RHEL</li> <li>Fedora</li> <li>Alpine Linux</li> <li>FreeBSD</li> <li>openSUSE</li> <li>Minimal images (cirros)</li> </ul>"},{"location":"architecture-virtualization/#network-integration","title":"Network Integration","text":"<p>VMs in Kube-DC are integrated with the same network architecture as containers:</p> <ul> <li>Each VM can connect to VPC networks via Multus CNI</li> <li>VMs receive IP addresses from the project's CIDR block</li> <li>Network policies apply to VMs just like containers</li> <li>VMs can use floating IPs and load balancer services</li> </ul>"},{"location":"architecture-virtualization/#storage-management","title":"Storage Management","text":"<p>Kube-DC provides flexible storage options for VMs:</p> <ul> <li>Support for multiple storage classes</li> <li>Persistent storage using Kubernetes PVCs</li> <li>Live volume resizing</li> <li>Volume snapshots and cloning</li> </ul>"},{"location":"architecture-virtualization/#vm-customization","title":"VM Customization","text":"<p>VMs can be customized through cloud-init configurations:</p> <pre><code>cloudInitNoCloud:\n  userData: |-\n    #cloud-config\n    chpasswd: { expire: False }\n    password: securepassword\n    ssh_pwauth: True\n    package_update: true\n    package_upgrade: true\n    packages:\n    - qemu-guest-agent\n    runcmd:\n    - [ systemctl, start, qemu-guest-agent ]\n</code></pre> <p>This allows for: - Setting initial passwords - SSH key distribution - Software installation - Custom scripts execution - Network configuration</p>"},{"location":"architecture-virtualization/#health-monitoring","title":"Health Monitoring","text":"<p>VMs in Kube-DC support health checks through:</p> <pre><code>readinessProbe:\n  guestAgentPing: {}\n  failureThreshold: 10\n  initialDelaySeconds: 20\n  periodSeconds: 10\n</code></pre> <p>Health checks ensure: - VM is properly booted - Guest agent is responsive - Cloud-init has completed - Custom health check scripts pass</p>"},{"location":"architecture-virtualization/#web-ui-management","title":"Web UI Management","text":"<p>Kube-DC provides an intuitive web interface for VM management:</p> <p></p>"},{"location":"architecture-virtualization/#vm-dashboard-features","title":"VM Dashboard Features","text":"<p>The VM dashboard provides:</p> <ul> <li>VM Status Monitoring: Running status, uptime, and conditions</li> <li>Performance Metrics: Real-time CPU, memory, and storage usage</li> <li>VM Details: OS version, network configuration, and node placement</li> <li>Console Access: Direct web-based console access to VMs</li> <li>SSH Terminal: Direct SSH access from the browser</li> <li>Network Information: IP addresses and VPC subnet details</li> </ul>"},{"location":"architecture-virtualization/#vm-lifecycle-management","title":"VM Lifecycle Management","text":"<p>Through the UI, administrators and users can:</p> <ul> <li>Create VMs from templates or custom images</li> <li>Start, stop, pause, and restart VMs</li> <li>Adjust resource allocations (CPU, memory)</li> <li>Take snapshots for backup purposes</li> <li>Clone VMs to create new instances</li> <li>Migrate VMs between nodes</li> </ul>"},{"location":"architecture-virtualization/#advanced-features","title":"Advanced Features","text":""},{"location":"architecture-virtualization/#gpu-passthrough","title":"GPU Passthrough","text":"<p>Kube-DC supports GPU passthrough for high-performance computing and AI workloads:</p> <pre><code>domain:\n  devices:\n    gpus:\n    - deviceName: nvidia.com/GP102GL_Tesla_P40\n      name: gpu1\n</code></pre>"},{"location":"architecture-virtualization/#live-migration","title":"Live Migration","text":"<p>VMs can be migrated between nodes without downtime:</p> <pre><code>spec:\n  strategy:\n    type: LiveMigrate\n</code></pre>"},{"location":"architecture-virtualization/#vm-snapshots","title":"VM Snapshots","text":"<p>Kube-DC supports VM snapshots for point-in-time recovery:</p> <pre><code>apiVersion: snapshot.kubevirt.io/v1alpha1\nkind: VirtualMachineSnapshot\nmetadata:\n  name: my-vm-snapshot\nspec:\n  source:\n    apiGroup: kubevirt.io\n    kind: VirtualMachine\n    name: my-vm\n</code></pre>"},{"location":"architecture-virtualization/#vm-templates","title":"VM Templates","text":"<p>Organization administrators can create standardized VM templates for their users, ensuring consistent deployments and reducing configuration errors.</p>"},{"location":"architecture-virtualization/#integration-with-multi-tenancy","title":"Integration with Multi-Tenancy","text":"<p>VMs in Kube-DC operate within the same multi-tenant architecture as containers:</p> <ul> <li>VMs are created within specific projects</li> <li>Organization and project permissions control VM access</li> <li>Network isolation is enforced between projects</li> <li>VM metrics are included in project billing and quotas</li> </ul>"},{"location":"architecture-virtualization/#best-practices","title":"Best Practices","text":""},{"location":"architecture-virtualization/#resource-allocation","title":"Resource Allocation","text":"<ul> <li>Allocate sufficient memory for the guest OS (minimum 1GB for most Linux distributions)</li> <li>Consider CPU overcommit ratios when planning node capacity</li> <li>Use appropriate storage classes for VM performance requirements</li> </ul>"},{"location":"architecture-virtualization/#vm-optimization","title":"VM Optimization","text":"<ul> <li>Install guest agents for improved integration</li> <li>Use cloud-init for automated VM configuration</li> <li>Configure readiness probes for proper health monitoring</li> <li>Use virtio drivers for improved performance</li> </ul>"},{"location":"architecture-virtualization/#conclusion","title":"Conclusion","text":"<p>Kube-DC's integration of KubeVirt provides a seamless experience for managing both VMs and containers in a single platform. This unified approach simplifies infrastructure management, improves resource utilization, and enables hybrid application architectures that combine the benefits of both virtualization and containerization.</p>"},{"location":"community-support/","title":"Community &amp; Support","text":"<p>Kube-DC has multiple channels for support, community engagement, and professional services. Choose the option that best fits your needs.</p>"},{"location":"community-support/#community-support_1","title":"Community Support","text":""},{"location":"community-support/#github-discussions","title":"GitHub Discussions","text":"<ul> <li>Ask questions and engage with the community</li> <li>Share your experiences and solutions</li> <li>Report bugs and request features</li> <li>Access to public roadmap and project updates</li> <li>Visit GitHub Discussions</li> </ul>"},{"location":"community-support/#slack-community","title":"Slack Community","text":"<p>Join our active Slack community to:</p> <ul> <li>Get real-time help from community members</li> <li>Connect with other Kube-DC users</li> <li>Share your use cases and solutions</li> <li>Stay updated on latest developments</li> <li>Join Kube-DC Slack</li> </ul>"},{"location":"community-support/#documentation","title":"Documentation","text":"<ul> <li>Comprehensive guides and tutorials</li> <li>API reference documentation</li> <li>Best practices and examples</li> <li>Browse Documentation</li> </ul>"},{"location":"community-support/#professional-services","title":"Professional Services","text":""},{"location":"community-support/#commercial-support","title":"Commercial Support","text":"<p>We offer various tiers of commercial support:</p>"},{"location":"community-support/#basic-support","title":"Basic Support","text":"<ul> <li>Business hours support (9/5)</li> <li>Email support</li> <li>24-hour response time</li> <li>Bug fixes and security updates</li> <li>Access to knowledge base</li> </ul>"},{"location":"community-support/#enterprise-support","title":"Enterprise Support","text":"<ul> <li>24/7 support coverage</li> <li>Priority response (2-hour SLA for critical issues)</li> <li>Direct access to engineering team</li> <li>Custom feature development</li> <li>Dedicated support engineer</li> <li>Regular health checks and reviews</li> </ul>"},{"location":"community-support/#professional-services_1","title":"Professional Services","text":""},{"location":"community-support/#implementation-services","title":"Implementation Services","text":"<ul> <li>Architecture design and review</li> <li>Production deployment assistance</li> <li>Migration planning and execution</li> <li>Performance optimization</li> <li>Security hardening</li> </ul>"},{"location":"community-support/#training","title":"Training","text":"<ul> <li>Admin and operator training</li> <li>Developer workshops</li> <li>Custom training programs</li> <li>Certification programs</li> </ul>"},{"location":"community-support/#consulting","title":"Consulting","text":"<ul> <li>Technical architecture consulting</li> <li>Scalability planning</li> <li>High availability design</li> <li>Security assessment</li> <li>Performance optimization</li> <li>Custom integration development</li> </ul>"},{"location":"community-support/#getting-support","title":"Getting Support","text":""},{"location":"community-support/#for-community-support","title":"For Community Support","text":"<ol> <li>Check the documentation</li> <li>Search existing GitHub Issues</li> <li>Join our Slack community</li> <li>Post on GitHub Discussions</li> </ol>"},{"location":"community-support/#for-commercial-support","title":"For Commercial Support","text":"<p>Contact our sales team:</p> <ul> <li>Email: support@kube-dc.com</li> <li>Website: https://kube-dc.com/</li> <li>Phone: +380632441621</li> </ul>"},{"location":"community-support/#contributing","title":"Contributing","text":"<p>We welcome contributions from the community! Check our Contributing Guide to learn how you can:</p> <ul> <li>Submit bug reports and feature requests</li> <li>Contribute code</li> <li>Improve documentation</li> <li>Share use cases and examples</li> </ul>"},{"location":"controller_diagram/","title":"Controller Architecture Diagram","text":"<p>A high-level view of Kube-DC controller components (excluding UI) and external dependencies.</p> <pre><code>flowchart TB\n  subgraph Installer\n    CD[cluster.dev IaC]\n  end\n\n  subgraph K8sCluster[\"Kubernetes Cluster &amp; CRDs\"]\n    CRDs[[\"Org, Project, OrgGroup, EIp, FIp CRDs\"]]\n  end\n\n  subgraph Manager[\"Controller Manager\"]\n    OR(OrganizationReconciler)\n    PR(ProjectReconciler)\n    OGR(OrganizationGroupReconciler)\n    EIP(EIpReconciler)\n    FIP(FIpReconciler)\n    SR(ServiceReconciler)\n  end\n\n  subgraph Logic[\"Business Logic Packages\"]\n    OGi[\"internal/organization\"]\n    PI[\"internal/project\"]\n    OGG[\"internal/organizationgroup\"]\n    SLP[\"internal/service_lb\"]\n    OBJ[\"internal/objmgr\"]\n    UTL[\"internal/utils\"]\n  end\n\n  subgraph Ext[\"External Dependencies\"]\n    KC[Keycloak]\n    KO[Kube-OVN]\n    KV[KubeVirt]\n    ML[Multus CNI]\n    CM[Cert-Manager]\n    PM[Prometheus &amp; Loki]\n  end\n\n  CD --&gt; CRDs\n  CRDs --&gt; OR &amp; PR &amp; OGR &amp; EIP &amp; FIP &amp; SR\n\n  OR --&gt; OGi\n  PR --&gt; PI\n  OGR --&gt; OGG\n  EIP --&gt; SLP\n  FIP --&gt; SLP\n  SR --&gt; SLP\n\n  SLP --&gt; KO\n  OGi --&gt; KC\n  PI --&gt; KO &amp; KV &amp; ML\n  PI --&gt; PM &amp; CM\n  PI --&gt; KC\n\n  style CRDs fill:#f9f,stroke:#333,stroke-width:2px\n  style Manager fill:#bbf,stroke:#333,stroke-width:2px\n  style Logic fill:#bfb,stroke:#333,stroke-width:2px\n  style Ext fill:#ffb,stroke:#333,stroke-width:2px\n  style Installer fill:#fbb,stroke:#333,stroke-width:2px</code></pre>"},{"location":"controller_diagram/#networking-integration-kube-ovn-multus","title":"Networking Integration (Kube-OVN &amp; Multus)","text":"<p>Below is a focused diagram showing how Kube-OVN and Multus CNI are installed and integrated via the Project NetworkAttachmentDefinition.</p> <pre><code>flowchart LR\n  subgraph Installer\n    KOV[\"Kube-OVN Helm Chart\"]\n    MULT[\"Multus CNI Helm Chart\"]\n  end\n\n  KOV --&gt; MULT\n\n  subgraph CNIInfra[\"CNI Infrastructure\"]\n    OVN[\"ovn-daemon (kube-ovn)\"]\n    MPods[\"Multus Pods\"]\n  end\n\n  MULT --&gt; MPods\n  KOV --&gt; OVN\n  OVN &amp; MPods --&gt; CNIInfra\n\n  NewNAD[\"NewProjectNad Controller\"]\n  NADCRD[\"NetworkAttachmentDefinition CR\"]\n  CNIConfig[\"Spec.Config: {type:'kube-ovn', server_socket:'/run/openvswitch/kube-ovn-daemon.sock', provider:&lt;proj&gt;} \"]\n  PodAttach[\"Pod annotation 'k8s.v1.cni.cncf.io/networks' = NAD\"]\n\n  NewNAD --&gt; NADCRD\n  NADCRD --&gt; CNIConfig\n  CNIConfig --&gt; PodAttach\n  PodAttach --&gt; CNIInfra\n\n  style Installer fill:#fbb,stroke:#333,stroke-width:1px\n  style CNIInfra fill:#ffb,stroke:#333,stroke-width:1px\n  style NewNAD fill:#bfb,stroke:#333,stroke-width:1px\n  style NADCRD fill:#f9f,stroke:#333,stroke-width:1px</code></pre> <p>Referenced code: - Scheme registration: \u3010F:cmd/main.go\u2020L57-L60\u3011 - NAD controller: \u3010F:internal/project/res_nad.go\u2020L12-L27\u3011   - Installer sequence: \u3010F:installer/kube-dc/templates/kube-dc/template.yaml\u2020L94-L102\u3011\u3010F:installer/kube-dc/templates/kube-dc/template.yaml\u2020L119-L127\u3011</p>"},{"location":"controller_diagram/#eip-fip-serviceloadbalancer-networking-flows","title":"EIP, FIP &amp; ServiceLoadBalancer Networking Flows","text":"<pre><code>flowchart TD\n  subgraph ProjectNet[\"Project Networking Controllers\"]\n    EIPdef[\"NewProjectEip (Default Gateway EIP)\"]\n    EIPcr[NewProjectEip CR]\n    EIPsync[EIpReconciler]\n    FIPsync[FIpReconciler]\n    LBsync[ServiceReconciler]\n  end\n\n  subgraph OVNNB[\"OVN Northbound DB &amp; OVS\"]\n    OVNNBdb[ovn-nb.db]\n    OVSOCK[ovs-db socket]\n  end\n\n  EIPdef --&gt; EIPcr\n  EIPcr --&gt; EIPsync\n  EIPsync --&gt; OVNNBdb\n\n  FIPsync --&gt;|Sync EIP + Floating IP| OVNNBdb\n\n  LBsync --&gt;|Ensure external IP via EIp CR| OVNNBdb\n  LBsync --&gt;|Configure Virtual IPs in LB| OVNNBdb\n\n  OVNNBdb --&gt; OVSOCK\n\n  classDef flow fill:#eef,stroke:#666,stroke-width:1px;\n  class EIPdef,EIPcr,EIPsync,FIPsync,LBsync flow;</code></pre>"},{"location":"controller_diagram/#detailed-network-stack-implementation","title":"Detailed Network Stack Implementation","text":"<ol> <li>Project VPC &amp; Subnet provisioning (<code>internal/project/res_vpc.go</code>)</li> <li>Creates an OVN Virtual Private Cloud via <code>OvnVpc</code> CR and logical switch.</li> <li>NetworkAttachmentDefinition (<code>internal/project/res_nad.go</code>)</li> <li>Defines a Multus NAD with CNI config for <code>kube-ovn</code>, pointing at the OVS socket and project provider.</li> <li>SNAT Rule (<code>internal/project/res_snat.go</code>)</li> <li>Installs an <code>OvnSnatRule</code> to translate pod-source IPs to the project gateway EIP for outbound internet.</li> <li>Default Gateway EIP (<code>internal/project/res_eip_default.go</code>)</li> <li>Ensures a project-scoped <code>EIp</code> CR representing the default gateway external IP, created via <code>NewEipDefault</code>.</li> <li>Floating IP (FIp) (<code>internal/fip/res_eip.go</code> &amp; <code>FIpReconciler</code>)</li> <li>Syncs or creates EIp owned by FIp, then updates <code>FIp.Status.ExternalIP</code> after attaching the EIp to pods via OVN.</li> <li>Service LoadBalancer (<code>internal/service_lb/service_lb.go</code>, <code>internal/service_lb/eip_res.go</code>, <code>ServiceReconciler</code>)</li> <li><code>NewSvcLbEIpRes</code> allocates or binds an external IP for the Service.</li> <li><code>NewLoadBalancerRes</code> uses OVN NB client to define load balancer VIP\u2192backend mappings and injects rules into logical router/switch.</li> <li>Extra External Subnets (<code>internal/project/res_vpc.go</code>)</li> <li>Adds <code>ExtraExternalSubnets</code> field to <code>Vpc.Spec</code> when <code>project.Spec.EgressNetworkType</code> differs from the default external subnet, enabling multi-network external connectivity.    <pre><code>if externalNetwork.Name != defaultExternalSubnet.Name {\n    vpc.Spec.ExtraExternalSubnets = []string{externalNetwork.Name}\n}\n</code></pre>    \u3010F:internal/project/res_vpc.go\u2020L45-L52\u3011</li> </ol> <p>-Refer to code for detailed behavior: - Preamble and flag parsing: \u3010F:cmd/main.go\u2020L117-L131\u3011 - NAD CNI config: \u3010F:internal/project/res_nad.go\u2020L14-L31\u3011 - SNAT via OVN: \u3010F:internal/project/res_snat.go\u2020L14-L45\u3011 - Default EIP creation: \u3010F:internal/project/res_eip_default.go\u2020L15-L42\u3011 - FIp EIP sync: \u3010F:internal/fip/res_eip.go\u2020L25-L50\u3011 - Service LB orchestration: \u3010F:internal/service_lb/service_lb.go\u2020L30-L58\u3011\u3010F:internal/service_lb/eip_res.go\u2020L18-L40\u3011</p>"},{"location":"controller_diagram/#public-vs-cloud-external-networking","title":"Public vs Cloud External Networking","text":"<p>Kube-DC supports two external network types: public (direct public IPs) and cloud (cloud-provider-backed). The type influences EIP/FIP provisioning and SNAT rules:</p> <p><pre><code>// ExternalNetworkType defines how external networks are treated:\ntype ExternalNetworkType string\nconst (\n  ExternalNetworkTypePublic ExternalNetworkType = \"public\"\n  ExternalNetworkTypeCloud  ExternalNetworkType = \"cloud\"\n)\n\n// MasterConfig defaults per resource if not overridden:\nDefaultGwNetworkType, DefaultEipNetworkType,\nDefaultFipNetworkType, DefaultSvcLbNetworkType\n</code></pre> \u3010F:api/kube-dc.com/v1/types.go\u2020L1-L18\u3011</p>"},{"location":"controller_diagram/#project-egress-network-selection","title":"Project Egress Network Selection","text":"<p>The project spec may set <code>egressNetworkType</code> to choose the external subnet for VPC/SNAT/EIP.</p> <p><code>go // GenerateProjectVpc picks externalSubnet based on project.Spec.EgressNetworkType: externalNetwork, _ := utils.SelectBestExternalSubnet(ctx, cli, project.Spec.EgressNetworkType)</code>\u3010F:internal/project/res_vpc.go\u2020L55-L61\u3011</p>"},{"location":"controller_diagram/#snat-rules-for-outbound-traffic","title":"SNAT Rules for Outbound Traffic","text":"<p>SNAT rules ensure pod egress to internet through the gateway EIP:</p> <p><code>go // NewProjectSnat creates OvnSnatRule linking project namespace to gateway EIP base.GeneratedObject = &amp;kubeovn.OvnSnatRule{   Spec: OvnSnatRuleSpec{     OvnEip: DefaultOvnEipName(project, externalSubnet.Name),     Vpc:    projectNamespace,     VpcSubnet: SubnetName(project),   }, }</code>\u3010F:internal/project/res_snat.go\u2020L14-L45\u3011</p>"},{"location":"controller_diagram/#default-gateway-eip-vs-floating-ip","title":"Default Gateway EIP vs Floating IP","text":"<ul> <li>Default Gateway EIP: A single EIp CR per project created by <code>NewProjectEip</code> when no explicit EIP exists. Used for SNAT and default outbound.</li> <li>Floating IP (FIp): EIp allocated per FIp CR to attach public IPs to specific workloads.</li> </ul> <p><code>go // NewProjectEip ensures default project gateway EIp exists WithGetFunction(func(...) {   eip, err := resourcesProcessor.GetProjectGwEip()   if IsNotFound(err) {     newEip, _ := NewEipDefault(...)     base.GeneratedObject = newEip   } })</code>\u3010F:internal/project/res_eip_default.go\u2020L15-L37\u3011</p> <p><code>go // SyncEip for FIp: derives EIp name from FIp and creates/gets it // then FIpReconciler attaches exclusive ownership in OVN</code>\u3010F:internal/fip/res_eip.go\u2020L25-L40\u3011</p>"},{"location":"controller_diagram/#service-loadbalancer-external-ip-binding","title":"Service LoadBalancer External IP Binding","text":"<p>ServiceReconciler uses annotations or defaults to bind EIp to Services:</p> <p>```go // Get or create EIp for Service LB via NewSvcLbEIpRes eipSyncer := NewSvcLbEIpRes(ctx, cli, svc, project) eipSyncer.Sync(ctx)</p> <p>// Configure OVN LB VRRP rules via NewLoadBalancerRes lbRes := NewLoadBalancerRes(ctx, cli, svc, endpoints, eipSyncer.Found(), project) lbRes.Sync(ctx) ```\u3010F:internal/service_lb/eip_res.go\u2020L18-L40\u3011\u3010F:internal/service_lb/service_lb.go\u2020L75-L98\u3011</p>"},{"location":"core-features/","title":"Core Features","text":"<p>Kube-DC extends Kubernetes with a robust set of features designed for enterprise data center operations. This page provides detailed technical specifications and use cases for each of Kube-DC's core capabilities.</p> <p>Looking for a Architectural details? Visit our architectural overview.</p>"},{"location":"core-features/#organization-management","title":"Organization Management","text":"<p>Foundation for Multi-Tenancy</p> <p>Organization Management provides the foundation for Kube-DC's multi-tenant capabilities, enabling complete isolation between different users and groups.</p> <p>Kube-DC's multi-tenant architecture allows service providers to host multiple organizations with complete isolation and customization.</p> <p>Capabilities:</p> <ul> <li>Multi-Organization Support: Host multiple organizations on a single Kube-DC installation with complete logical separation</li> <li>Custom SSO Integration: Each organization can configure its own identity provider:<ul> <li>Google Workspace / Gmail</li> <li>Microsoft Active Directory / Azure AD</li> <li>GitHub</li> <li>GitLab</li> <li>LDAP</li> <li>SAML 2.0 providers</li> <li>OpenID Connect providers</li> </ul> </li> <li>Hierarchical Group Management: Create and manage groups within organizations with inheritance of permissions</li> <li>Flexible RBAC: Assign fine-grained permissions to groups for specific projects or resources</li> <li>Organizational Quotas: Set resource limits at the organization level to ensure fair resource allocation</li> </ul> <p>Real-World Applications</p> <ul> <li>Managed Service Providers: Host multiple client organizations with separate authentication systems</li> <li>Enterprise IT: Separate departments with different authentication requirements</li> <li>Educational Institutions: Provide isolated environments for different departments or research groups</li> </ul>"},{"location":"core-features/#namespace-as-a-service","title":"Namespace as a Service","text":"<p>Projects and Workloads</p> <p>Namespaces in Kube-DC function as projects, providing isolated environments for deploying and managing diverse workloads.</p> <p>Every project in Kube-DC is allocated its own Kubernetes namespace with extended capabilities for running both containers and virtual machines.</p> <p>Capabilities:</p> <ul> <li>Unified Management: Deploy and manage both VMs and containers from a single interface</li> <li>Project Isolation: Complete network and resource isolation between projects</li> <li>Resource Quotas: Set limits on CPU, memory, storage, and other resources per project</li> <li>Integrated Dashboard: View and manage all workloads through a unified web interface</li> <li>Custom Templates: Create and use templates for quick deployment of common workloads</li> </ul> <p>Real-World Applications</p> <ul> <li>Application Modernization: Run legacy VMs alongside containerized microservices</li> <li>Development Environments: Provide isolated environments for development, testing, and staging</li> <li>Mixed Workloads: Support teams that require both traditional and cloud-native infrastructure</li> </ul>"},{"location":"core-features/#network-management","title":"Network Management","text":"<p>Advanced Connectivity</p> <p>Kube-DC's network capabilities enable sophisticated connectivity options while maintaining isolation between projects.</p> <p>Kube-DC provides advanced networking capabilities that bridge traditional data center networking with cloud-native concepts.</p> <p>Capabilities:</p> <ul> <li>Dedicated VPC per Project: Each project gets its own virtual network environment</li> <li>VLAN Integration: Connect to physical network infrastructure using VLANs</li> <li>Software-Defined Networking: Create overlay networks with software-defined control</li> <li>Network Peering: Connect project networks with each other or with external networks</li> <li>NAT and Internet Gateway: Control outbound and inbound internet access per project</li> <li>External IP Assignment: Assign public IPs directly to VMs or Kubernetes services</li> <li>Load Balancer Integration: Create and manage load balancers for services and VMs</li> <li>Network Policies: Define granular rules for network traffic filtering</li> <li>DNS Management: Automatic DNS for services and VMs with custom domain support</li> </ul> <p>Real-World Applications</p> <ul> <li>Hybrid Cloud Deployments: Extend on-premises networks to containerized workloads</li> <li>Multi-Tier Applications: Create complex network topologies for enterprise applications</li> <li>Secure Isolation: Create zero-trust network environments with fine-grained control</li> </ul>"},{"location":"core-features/#virtualization","title":"Virtualization","text":"<p>KubeVirt Integration</p> <p>Built on KubeVirt, Kube-DC provides enterprise-grade virtualization capabilities fully integrated with Kubernetes.</p> <p>Built on KubeVirt, Kube-DC provides enterprise-grade virtualization capabilities integrated with Kubernetes.</p> <p>Capabilities:</p> <ul> <li>Hardware Vendor Support: Compatible with major hardware vendors' servers and components</li> <li>GPU Passthrough: Support for Nvidia GPU passthrough to virtual machines</li> <li>ARM Support: Run VMs on ARM-based infrastructure</li> <li>Web Console: Access VM consoles directly through the web UI</li> <li>SSH Integration: SSH access management with key authentication</li> <li>Live Migration: Move running VMs between nodes without downtime</li> <li>Snapshots: Create point-in-time snapshots of VM volumes</li> <li>VM Templates: Create and use templates for rapid VM provisioning</li> <li>Custom Boot Options: Configure boot order, firmware settings, and UEFI support</li> <li>VM Import/Export: Import existing VMs from other platforms</li> </ul> <p>Real-World Applications</p> <ul> <li>Legacy Application Support: Run applications that require traditional VMs</li> <li>Windows Workloads: Host Windows servers alongside Linux containers</li> <li>GPU-Accelerated Computing: Provide GPU resources for AI/ML or rendering workloads</li> <li>Specialized Operating Systems: Run operating systems not supported in containers</li> </ul>"},{"location":"core-features/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>API-Driven Architecture</p> <p>Kube-DC's API-driven approach enables automation and integration with popular infrastructure tools.</p> <p>Kube-DC leverages and extends the Kubernetes API to enable comprehensive infrastructure automation.</p> <p>Capabilities:</p> <ul> <li>Native Kubernetes API: Manage all Kube-DC resources using standard Kubernetes tools</li> <li>Custom Resource Definitions (CRDs): Extended Kubernetes objects for managing organizations, projects, VMs, and more</li> <li>GitOps Compatible: Deploy and manage infrastructure using GitOps workflows</li> </ul> <p>Real-World Applications</p> <ul> <li>Automated Infrastructure: Create fully automated infrastructure provisioning workflows</li> <li>Self-Service Portals: Build custom self-service interfaces using the Kube-DC API</li> <li>CI/CD Integration: Include infrastructure provisioning in CI/CD pipelines</li> <li>Multi-Cloud Management: Manage Kube-DC resources alongside other cloud resources</li> </ul>"},{"location":"core-features/#integrated-flexible-billing","title":"Integrated Flexible Billing","text":"<p>Cost Management</p> <p>Track, allocate, and manage costs across all resources with Kube-DC's comprehensive billing capabilities.</p> <p>Kube-DC includes comprehensive resource tracking and billing capabilities suitable for both service providers and internal IT organizations.</p> <p>Capabilities:</p> <ul> <li>Resource Metering: Track usage of CPU, memory, storage, GPU, and network resources</li> <li>Custom Pricing Models: Define pricing tiers for different resource types and customers</li> <li>Project-Based Billing: Track and bill resource usage at the project level</li> <li>Cost Allocation: Assign costs to organizational units, projects, or individual resources</li> <li>Quota Enforcement: Automatically enforce resource limits based on billing status</li> <li>Usage Reporting: Generate detailed usage reports for analysis and billing</li> <li>Billing API: Integrate with external billing systems through a comprehensive API</li> <li>Chargeback Models: Support for various internal chargeback models for enterprise use</li> </ul> <p>Real-World Applications</p> <ul> <li>Managed Service Providers: Bill customers for exact resource usage</li> <li>Enterprise IT: Implement internal chargeback or showback for departmental resource usage</li> <li>Resource Optimization: Identify resource usage patterns and optimize costs</li> </ul>"},{"location":"core-features/#management-services","title":"Management Services","text":"<p>Value-Added Services</p> <p>Extend Kube-DC's capabilities by offering managed services on top of the core platform.</p> <p>Kube-DC provides a platform for delivering managed services on top of its infrastructure.</p> <p>Capabilities:</p> <p>Database as a Service: Deploy and manage databases with automated operations</p> <ul> <li>PostgreSQL</li> <li>MySQL/MariaDB</li> <li>Microsoft SQL Server</li> <li>And more</li> </ul> <p>Object Storage: S3-compatible storage with multi-tenancy support</p> <p>NoSQL Databases: Managed NoSQL database offerings</p> <ul> <li>Redis</li> <li>MongoDB</li> <li>Elasticsearch/OpenSearch</li> </ul> <p>AI/ML Platform: Infrastructure for deploying and serving AI/ML models</p> <ul> <li>LLM serving</li> <li>Model training infrastructure</li> <li>GPU resource allocation</li> </ul> <p>Backup Services: Automated backup solutions for VMs and containers Monitoring as a Service: Multi-tenant monitoring solutions Service Catalog: Self-service provisioning of common services</p> <p>Real-World Applications</p> <ul> <li>Internal Platform Team: Provide managed services to development teams</li> <li>Managed Service Providers: Offer value-added services beyond basic infrastructure</li> <li>AI/ML Operations: Provide specialized infrastructure for data science teams</li> </ul>"},{"location":"internal-billing-integration/","title":"Internal Billing Integration Documentation","text":""},{"location":"internal-billing-integration/#overview","title":"Overview","text":"<p>This document describes the internal architecture and implementation details of the billing API integration within the Kube-DC platform. This integration provides organization-level billing management and project-specific cost analysis through the Kube-DC UI.</p>"},{"location":"internal-billing-integration/#architecture-overview","title":"Architecture Overview","text":""},{"location":"internal-billing-integration/#system-components","title":"System Components","text":"<pre><code>graph TB\n    subgraph \"Kube-DC Frontend\"\n        UI[Billing UI Component]\n        Auth[JWT Authentication]\n    end\n\n    subgraph \"Kube-DC Backend\"\n        Proxy[Billing Proxy Controller]\n        TokenSvc[Token Service]\n        AuthZ[Authorization Layer]\n    end\n\n    subgraph \"Billing Service\"\n        API[Billing API]\n        DB[(PostgreSQL)]\n    end\n\n    UI --&gt; Auth\n    Auth --&gt; Proxy\n    Proxy --&gt; TokenSvc\n    TokenSvc --&gt; AuthZ\n    AuthZ --&gt; API\n    API --&gt; DB</code></pre>"},{"location":"internal-billing-integration/#authentication-authorization-flow","title":"Authentication &amp; Authorization Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Frontend\n    participant Backend\n    participant BillingAPI\n\n    User-&gt;&gt;Frontend: Access Billing Page\n    Frontend-&gt;&gt;Backend: GET /api/billing/project/{ns}/overview\n    Note over Frontend,Backend: JWT Token in Authorization header\n\n    Backend-&gt;&gt;Backend: Extract &amp; validate JWT token\n    Backend-&gt;&gt;Backend: Check namespace permissions\n\n    alt Valid token &amp; authorized namespace\n        Backend-&gt;&gt;BillingAPI: GET /api/project/{ns}/overview\n        BillingAPI-&gt;&gt;Backend: Billing data response\n        Backend-&gt;&gt;Frontend: Authorized data\n        Frontend-&gt;&gt;User: Display billing information\n    else Invalid token or unauthorized\n        Backend-&gt;&gt;Frontend: 401/403 Error\n        Frontend-&gt;&gt;User: Access denied message\n    end</code></pre>"},{"location":"internal-billing-integration/#implementation-details","title":"Implementation Details","text":""},{"location":"internal-billing-integration/#backend-integration","title":"Backend Integration","text":""},{"location":"internal-billing-integration/#file-structure","title":"File Structure","text":"<pre><code>ui/backend/\n\u251c\u2500\u2500 controllers/billing/\n\u2502   \u2514\u2500\u2500 billingController.js     # Main billing proxy controller\n\u251c\u2500\u2500 routes/\n\u2502   \u2514\u2500\u2500 billing.js              # Billing API routes\n\u251c\u2500\u2500 utils/\n\u2502   \u2514\u2500\u2500 logger.js               # Logging utility\n\u2514\u2500\u2500 app.js                      # Main app with billing routes\n</code></pre>"},{"location":"internal-billing-integration/#key-components","title":"Key Components","text":"<p>Billing Controller (<code>controllers/billing/billingController.js</code>) - Proxies requests to internal billing service - Implements JWT token validation - Enforces namespace-based authorization - Handles error responses and logging</p> <p>Authentication Flow <pre><code>// Token extraction\nconst token = tokenService.getToken(req);\n\n// JWT decoding and validation\nconst decodedToken = decodeJWT(token);\nconst userNamespaces = decodedToken.namespaces || [];\n\n// Authorization check\nif (!userNamespaces.includes(namespace)) {\n  return sendErrorResponse(res, 403, 'Access denied to namespace');\n}\n</code></pre></p> <p>Service Communication - Internal service URL: <code>billing-dashboard-svc.billing.svc.cluster.local:5000</code> - Uses Kubernetes service discovery - No external network access required</p>"},{"location":"internal-billing-integration/#frontend-integration","title":"Frontend Integration","text":""},{"location":"internal-billing-integration/#file-structure_1","title":"File Structure","text":"<pre><code>ui/frontend/src/app/ManageOrganization/\n\u251c\u2500\u2500 Billing/\n\u2502   \u2514\u2500\u2500 Billing.tsx             # Main billing component\n\u251c\u2500\u2500 OrganizationRoutes.tsx      # Route definitions\n\u251c\u2500\u2500 OrganizationSidebar.tsx     # Navigation sidebar\n\u2514\u2500\u2500 OrganizationLayout.tsx      # Layout logic\n</code></pre>"},{"location":"internal-billing-integration/#key-features","title":"Key Features","text":"<p>Billing Component (<code>Billing/Billing.tsx</code>) - Uses PatternFly design system - Displays project billing summaries in table format - Implements loading states and error handling - Follows existing Kube-DC UI patterns</p> <p>Security Implementation <pre><code>// Namespace extraction from JWT\nconst getUserNamespaces = React.useMemo(() =&gt; {\n  if (!token) return [];\n  try {\n    const decodedToken = decodeJWT(token);\n    return decodedToken.namespaces || [];\n  } catch (error) {\n    return [];\n  }\n}, [token]);\n\n// API calls with authentication\nconst response = await fetch(`/api/billing/project/${namespace}/overview`, {\n  headers: {\n    'Authorization': `Bearer ${token}`,\n    'Content-Type': 'application/json'\n  },\n  credentials: 'include'\n});\n</code></pre></p>"},{"location":"internal-billing-integration/#api-endpoints","title":"API Endpoints","text":""},{"location":"internal-billing-integration/#available-endpoints","title":"Available Endpoints","text":"Method Endpoint Description Authentication GET <code>/api/billing/health</code> Service health check Required GET <code>/api/billing/projects</code> List accessible projects Required GET <code>/api/billing/project/:namespace/overview</code> Project billing details Required + Namespace access"},{"location":"internal-billing-integration/#response-format","title":"Response Format","text":"<p>Project Overview Response <pre><code>{\n  \"success\": true,\n  \"data\": {\n    \"namespace\": \"project-name\",\n    \"billing_summary\": {\n      \"current_month_total\": 1672.31,\n      \"last_day_spend\": 109.16,\n      \"billing_period\": \"2025-09\",\n      \"total_cost_per_hour\": 2.32\n    },\n    \"compute_instances\": {\n      \"running_pods\": 10,\n      \"running_vms\": 1,\n      \"cpu_cores\": 2.4,\n      \"memory_gib\": 8.8,\n      \"cost_per_hour\": 0.15\n    },\n    \"cost_breakdown\": {\n      \"cpu_cost\": 89.45,\n      \"memory_cost\": 45.23,\n      \"storage_cost\": 12.67,\n      \"network_cost\": 0.00,\n      \"public_ip_cost\": 0.00\n    }\n  },\n  \"timestamp\": \"2025-10-01T15:25:00.000Z\"\n}\n</code></pre></p>"},{"location":"internal-billing-integration/#security-model","title":"Security Model","text":""},{"location":"internal-billing-integration/#jwt-token-structure","title":"JWT Token Structure","text":"<pre><code>{\n  \"org\": \"organization-name\",\n  \"namespaces\": [\"project-1\", \"project-2\"],\n  \"groups\": [\"org-admin\", \"user\"],\n  \"exp\": 1696176000,\n  \"iat\": 1696089600\n}\n</code></pre>"},{"location":"internal-billing-integration/#authorization-levels","title":"Authorization Levels","text":"Role Access Level Permissions <code>org-admin</code> Organization-wide All projects in organization <code>project-user</code> Project-specific Only assigned namespaces <code>guest</code> No access No billing data access"},{"location":"internal-billing-integration/#security-layers","title":"Security Layers","text":"<ol> <li>OIDC Authentication - External identity provider</li> <li>JWT Token Validation - Backend token verification</li> <li>Namespace Authorization - Per-project access control</li> <li>Network Security - Internal service communication only</li> </ol>"},{"location":"internal-billing-integration/#configuration","title":"Configuration","text":""},{"location":"internal-billing-integration/#environment-variables","title":"Environment Variables","text":"<p>Backend Configuration <pre><code># Billing service endpoint (internal)\nBILLING_API_URL=http://billing-dashboard-svc.billing.svc.cluster.local:5000\n\n# Logging level\nLOG_LEVEL=info\n</code></pre></p> <p>Frontend Configuration Uses existing Kube-DC ConfigMap pattern: <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kube-dc-frontend-config\ndata:\n  env.js: |\n    window.backendURL = 'https://backend.stage.kube-dc.com';\n    window.frontendURL = 'https://console.stage.kube-dc.com';\n    window.keycloakURL = 'https://login.stage.kube-dc.com';\n</code></pre></p>"},{"location":"internal-billing-integration/#network-policies","title":"Network Policies","text":"<pre><code># Internal service communication\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: kube-dc-billing-access\nspec:\n  podSelector:\n    matchLabels:\n      app: kube-dc-backend\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: billing\n    ports:\n    - protocol: TCP\n      port: 5000\n</code></pre>"},{"location":"internal-billing-integration/#error-handling","title":"Error Handling","text":""},{"location":"internal-billing-integration/#http-status-codes","title":"HTTP Status Codes","text":"Code Description Cause 200 Success Request completed successfully 401 Unauthorized Missing or invalid JWT token 403 Forbidden Valid token, insufficient permissions 503 Service Unavailable Billing service unreachable 500 Internal Server Error Unexpected server error"},{"location":"internal-billing-integration/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"success\": false,\n  \"error\": \"Access denied to namespace\",\n  \"details\": {\n    \"namespace\": \"requested-project\",\n    \"availableNamespaces\": [\"project-1\", \"project-2\"]\n  },\n  \"timestamp\": \"2025-10-01T15:25:00.000Z\"\n}\n</code></pre>"},{"location":"internal-billing-integration/#monitoring-logging","title":"Monitoring &amp; Logging","text":""},{"location":"internal-billing-integration/#log-levels","title":"Log Levels","text":"<ul> <li>INFO: Normal operations, API calls</li> <li>WARN: Authentication failures, permission denials  </li> <li>ERROR: Service errors, network issues</li> <li>DEBUG: Detailed request/response data (development only)</li> </ul>"},{"location":"internal-billing-integration/#key-metrics-to-monitor","title":"Key Metrics to Monitor","text":"<ul> <li>API response times</li> <li>Authentication failure rates</li> <li>Service availability</li> <li>Error rates by endpoint</li> <li>Namespace access patterns</li> </ul>"},{"location":"internal-billing-integration/#development-guidelines","title":"Development Guidelines","text":""},{"location":"internal-billing-integration/#code-standards","title":"Code Standards","text":"<ul> <li>Follow existing Kube-DC patterns</li> <li>Use PatternFly components for UI consistency</li> <li>Implement proper error handling</li> <li>Add comprehensive logging</li> <li>Write JSDoc comments for public methods</li> </ul>"},{"location":"internal-billing-integration/#testing-approach","title":"Testing Approach","text":"<ul> <li>Unit tests for controller logic</li> <li>Integration tests for API endpoints</li> <li>Frontend component tests</li> <li>End-to-end authentication flows</li> </ul>"},{"location":"internal-billing-integration/#deployment-process","title":"Deployment Process","text":"<ol> <li>Backend changes deployed via Helm chart</li> <li>Frontend changes built into container image</li> <li>Configuration updates via ConfigMaps</li> <li>Rolling deployment with health checks</li> </ol>"},{"location":"internal-billing-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"internal-billing-integration/#common-issues","title":"Common Issues","text":"<p>\"Authentication token required\" - Check JWT token presence in request headers - Verify token format (Bearer scheme) - Confirm OIDC authentication is working</p> <p>\"Access denied to namespace\" - Verify user has access to requested project - Check JWT token namespace claims - Confirm RBAC configuration</p> <p>\"Billing service unreachable\" - Check billing service pod status - Verify network connectivity - Confirm service DNS resolution</p>"},{"location":"internal-billing-integration/#debug-commands","title":"Debug Commands","text":"<pre><code># Check service status\nkubectl get pods -n kube-dc\nkubectl get pods -n billing\n\n# Check service connectivity\nkubectl exec -n kube-dc deployment/kube-dc-backend -- \\\n  curl -v http://billing-dashboard-svc.billing.svc.cluster.local:5000/api/health\n\n# Check logs\nkubectl logs -n kube-dc deployment/kube-dc-backend\nkubectl logs -n billing deployment/billing-dashboard\n</code></pre>"},{"location":"internal-billing-integration/#future-enhancements","title":"Future Enhancements","text":""},{"location":"internal-billing-integration/#planned-features","title":"Planned Features","text":"<ul> <li>Cost trend analysis and forecasting</li> <li>Budget alerts and notifications</li> <li>Resource optimization recommendations</li> <li>Detailed cost attribution reports</li> <li>Integration with cloud provider billing APIs</li> </ul>"},{"location":"internal-billing-integration/#technical-improvements","title":"Technical Improvements","text":"<ul> <li>Response caching for performance</li> <li>Real-time cost updates via WebSocket</li> <li>Advanced filtering and search capabilities</li> <li>Export functionality for billing reports</li> <li>Integration with monitoring systems</li> </ul> <p>This document is maintained by the Kube-DC development team. For questions or updates, please contact the platform team.</p>"},{"location":"managing-os-images/","title":"Managing OS Images in Kube-DC","text":"<p>This guide explains how to manage operating system images in the Kube-DC platform, including adding new OS options, modifying existing configurations, and updating the system.</p>"},{"location":"managing-os-images/#overview","title":"Overview","text":"<p>OS images in Kube-DC are configured through a Kubernetes ConfigMap that defines: - Available operating systems in the VM creation UI - Default resource requirements (memory, CPU, storage) - Firmware and virtualization settings - Cloud-init configurations - Image URLs and user credentials</p>"},{"location":"managing-os-images/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Helm Chart    \u2502\u2500\u2500\u2500\u25b6\u2502   ConfigMap      \u2502\u2500\u2500\u2500\u25b6\u2502  Backend API    \u2502\n\u2502   Template      \u2502    \u2502 images-configmap \u2502    \u2502 /os-images      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                       \u2502  Frontend UI    \u2502\n                       \u2502 Create VM Modal \u2502\n                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"managing-os-images/#configmap-structure","title":"ConfigMap Structure","text":"<p>The OS images are defined in <code>/charts/kube-dc/templates/os-images-configmap.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: images-configmap\n  namespace: {{ .Release.Namespace }}\ndata:\n  images.yaml: |\n    images:\n      - OS_NAME: \"Ubuntu 24.04\"\n        CLOUD_USER: ubuntu\n        OS_IMAGE_URL: \"https://cloud-images.ubuntu.com/noble/current/noble-server-cloudimg-amd64.img\"\n        MIN_MEMORY: \"1G\"\n        MIN_VCPU: \"1\"\n        MIN_STORAGE: \"20G\"\n        FIRMWARE_TYPE: \"bios\"\n        MACHINE_TYPE: \"q35\"\n        FEATURES: \"acpi\"\n        CLOUD_INIT: |\n          #cloud-config\n          package_update: true\n          packages:\n            - qemu-guest-agent\n</code></pre>"},{"location":"managing-os-images/#configuration-fields","title":"Configuration Fields","text":""},{"location":"managing-os-images/#required-fields","title":"Required Fields","text":"Field Description Example <code>OS_NAME</code> Display name in UI dropdown <code>\"Ubuntu 24.04\"</code> <code>CLOUD_USER</code> Default SSH user for the OS <code>ubuntu</code> <code>OS_IMAGE_URL</code> HTTP URL to the disk image <code>https://example.com/image.qcow2</code>"},{"location":"managing-os-images/#resource-requirements","title":"Resource Requirements","text":"Field Description Example Notes <code>MIN_MEMORY</code> Minimum RAM requirement <code>\"8G\"</code>, <code>\"512M\"</code> Supports G/M suffixes <code>MIN_VCPU</code> Minimum CPU cores <code>\"2\"</code> String format <code>MIN_STORAGE</code> Minimum disk size <code>\"60G\"</code> Supports G suffix"},{"location":"managing-os-images/#virtualization-settings","title":"Virtualization Settings","text":"Field Description Options Notes <code>FIRMWARE_TYPE</code> Boot firmware <code>\"bios\"</code>, <code>\"efi\"</code> EFI required for Windows 11 <code>MACHINE_TYPE</code> QEMU machine type <code>\"q35\"</code>, <code>\"pc-q35-rhel8.6.0\"</code> Specific types for compatibility <code>FEATURES</code> Virtualization features <code>\"acpi\"</code>, <code>\"hyperv,acpi,apic,smm,tpm\"</code> Comma-separated list"},{"location":"managing-os-images/#supported-features","title":"Supported Features","text":"<ul> <li><code>acpi</code> - Advanced Configuration and Power Interface</li> <li><code>apic</code> - Advanced Programmable Interrupt Controller  </li> <li><code>hyperv</code> - Microsoft Hyper-V enlightenments</li> <li><code>smm</code> - System Management Mode</li> <li><code>tpm</code> - Trusted Platform Module (required for Windows 11)</li> </ul>"},{"location":"managing-os-images/#os-specific-configurations","title":"OS-Specific Configurations","text":""},{"location":"managing-os-images/#linux-distributions","title":"Linux Distributions","text":"<p>Ubuntu/Debian: <pre><code>- OS_NAME: \"Ubuntu 24.04\"\n  CLOUD_USER: ubuntu\n  MIN_MEMORY: \"1G\"\n  MIN_VCPU: \"1\"\n  MIN_STORAGE: \"20G\"\n  FIRMWARE_TYPE: \"bios\"\n  MACHINE_TYPE: \"q35\"\n  FEATURES: \"acpi\"\n</code></pre></p> <p>CentOS/RHEL: <pre><code>- OS_NAME: \"CentOS Stream 9\"\n  CLOUD_USER: centos\n  MIN_MEMORY: \"2G\"\n  MIN_VCPU: \"1\"\n  MIN_STORAGE: \"20G\"\n  FIRMWARE_TYPE: \"bios\"\n  MACHINE_TYPE: \"q35\"\n  FEATURES: \"acpi\"\n</code></pre></p>"},{"location":"managing-os-images/#windows-systems","title":"Windows Systems","text":"<p>Windows 11: <pre><code>- OS_NAME: \"Windows 11 Enterprise\"\n  CLOUD_USER: Administrator\n  MIN_MEMORY: \"8G\"\n  MIN_VCPU: \"4\"\n  MIN_STORAGE: \"60G\"\n  FIRMWARE_TYPE: \"efi\"\n  MACHINE_TYPE: \"pc-q35-rhel8.6.0\"\n  FEATURES: \"hyperv,acpi,apic,smm,tpm\"\n</code></pre></p>"},{"location":"managing-os-images/#adding-a-new-os-image","title":"Adding a New OS Image","text":""},{"location":"managing-os-images/#step-1-prepare-the-image","title":"Step 1: Prepare the Image","text":"<ol> <li>Obtain the disk image (qcow2, raw, or vmdk format)</li> <li>Host the image on an HTTP server accessible to your cluster</li> <li>Test the image to ensure it boots correctly</li> </ol>"},{"location":"managing-os-images/#step-2-update-the-configmap","title":"Step 2: Update the ConfigMap","text":"<p>Edit <code>/charts/kube-dc/templates/os-images-configmap.yaml</code>:</p> <pre><code># Add your new OS entry\n- OS_NAME: \"Fedora 40\"\n  CLOUD_USER: fedora\n  OS_IMAGE_URL: \"https://download.fedoraproject.org/pub/fedora/linux/releases/40/Cloud/x86_64/images/Fedora-Cloud-Base-40-1.14.x86_64.qcow2\"\n  MIN_MEMORY: \"2G\"\n  MIN_VCPU: \"1\"\n  MIN_STORAGE: \"25G\"\n  FIRMWARE_TYPE: \"bios\"\n  MACHINE_TYPE: \"q35\"\n  FEATURES: \"acpi\"\n  CLOUD_INIT: |\n    #cloud-config\n    package_update: true\n    packages:\n      - qemu-guest-agent\n    runcmd:\n      - systemctl enable --now qemu-guest-agent\n</code></pre>"},{"location":"managing-os-images/#step-3-deploy-the-changes","title":"Step 3: Deploy the Changes","text":"<p>Option A: Helm Upgrade (Recommended) <pre><code># From the project root\nhelm upgrade kube-dc ./charts/kube-dc -n kube-dc\n</code></pre></p> <p>Option B: Direct ConfigMap Update <pre><code># Apply the ConfigMap directly\nkubectl apply -f charts/kube-dc/templates/os-images-configmap.yaml\n</code></pre></p>"},{"location":"managing-os-images/#step-4-reload-the-backend","title":"Step 4: Reload the Backend","text":"<p>The backend caches OS images for performance. After updating the ConfigMap:</p> <pre><code># Restart the backend to reload the cache\nkubectl rollout restart deployment/kube-dc-backend -n kube-dc\n\n# Or wait for the cache TTL (30 seconds) to expire\n</code></pre>"},{"location":"managing-os-images/#modifying-existing-os-images","title":"Modifying Existing OS Images","text":""},{"location":"managing-os-images/#inline-editing","title":"Inline Editing","text":"<p>You can modify the ConfigMap directly in Kubernetes:</p> <pre><code># Edit the ConfigMap in your cluster\nkubectl edit configmap images-configmap -n kube-dc\n</code></pre> <p>Example: Increase Windows 11 memory requirement: <pre><code># Change from:\nMIN_MEMORY: \"8G\"\n# To:\nMIN_MEMORY: \"16G\"\n</code></pre></p> <p>After saving, restart the backend: <pre><code>kubectl rollout restart deployment/kube-dc-backend -n kube-dc\n</code></pre></p>"},{"location":"managing-os-images/#updating-image-urls","title":"Updating Image URLs","text":"<p>If an image URL changes or becomes unavailable:</p> <ol> <li> <p>Update the ConfigMap: <pre><code># Old URL\nOS_IMAGE_URL: \"https://old-server.com/ubuntu-24.04.qcow2\"\n# New URL  \nOS_IMAGE_URL: \"https://new-server.com/ubuntu-24.04.qcow2\"\n</code></pre></p> </li> <li> <p>Apply changes: <pre><code>kubectl apply -f charts/kube-dc/templates/os-images-configmap.yaml\nkubectl rollout restart deployment/kube-dc-backend -n kube-dc\n</code></pre></p> </li> </ol>"},{"location":"managing-os-images/#testing-changes","title":"Testing Changes","text":""},{"location":"managing-os-images/#verify-configmap-update","title":"Verify ConfigMap Update","text":"<pre><code># Check the ConfigMap was updated\nkubectl get configmap images-configmap -n kube-dc -o yaml\n\n# Test the API endpoint\ncurl -s \"https://backend.stage.kube-dc.com/api/create-vm/your-namespace/os-images\" | jq '.[].OS_NAME'\n</code></pre>"},{"location":"managing-os-images/#test-in-ui","title":"Test in UI","text":"<ol> <li>Open the Kube-DC web interface</li> <li>Navigate to Create VM</li> <li>Check the Operation System dropdown</li> <li>Verify your new OS appears with correct parameters</li> <li>Select the OS and confirm memory/CPU/storage auto-populate</li> </ol>"},{"location":"managing-os-images/#troubleshooting","title":"Troubleshooting","text":""},{"location":"managing-os-images/#os-not-appearing-in-ui","title":"OS Not Appearing in UI","text":"<p>Check the ConfigMap: <pre><code>kubectl describe configmap images-configmap -n kube-dc\n</code></pre></p> <p>Verify backend logs: <pre><code>kubectl logs -n kube-dc deployment/kube-dc-backend --tail=50\n</code></pre></p> <p>Common issues: - YAML syntax errors in ConfigMap - Backend cache not refreshed - Network connectivity to image URL</p>"},{"location":"managing-os-images/#vm-creation-fails","title":"VM Creation Fails","text":"<p>Check image accessibility: <pre><code># Test if the image URL is reachable\ncurl -I \"https://your-image-url.com/image.qcow2\"\n</code></pre></p> <p>Verify resource requirements: - Ensure cluster has sufficient resources - Check storage class availability - Verify network policies allow image downloads</p>"},{"location":"managing-os-images/#backend-cache-issues","title":"Backend Cache Issues","text":"<p>The backend caches OS images for 30 seconds. To force refresh:</p> <pre><code># Restart backend pods\nkubectl rollout restart deployment/kube-dc-backend -n kube-dc\n\n# Or wait for cache expiration (30 seconds)\n</code></pre>"},{"location":"managing-os-images/#best-practices","title":"Best Practices","text":""},{"location":"managing-os-images/#image-management","title":"Image Management","text":"<ol> <li>Use stable URLs - Avoid URLs that change frequently</li> <li>Host images reliably - Use CDNs or reliable hosting</li> <li>Test images - Verify images boot before adding to production</li> <li>Document changes - Keep track of image versions and changes</li> </ol>"},{"location":"managing-os-images/#resource-requirements_1","title":"Resource Requirements","text":"<ol> <li>Set realistic minimums - Don't under-provision resources</li> <li>Consider workload - Different use cases need different resources  </li> <li>Test performance - Verify VMs perform well with set resources</li> </ol>"},{"location":"managing-os-images/#security","title":"Security","text":"<ol> <li>Verify image sources - Only use trusted image providers</li> <li>Scan images - Check for vulnerabilities before deployment</li> <li>Use HTTPS - Always use secure URLs for image downloads</li> <li>Regular updates - Keep OS images updated with security patches</li> </ol>"},{"location":"managing-os-images/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"managing-os-images/#custom-cloud-init","title":"Custom Cloud-Init","text":"<p>For complex initialization requirements:</p> <pre><code>CLOUD_INIT: |\n  #cloud-config\n  users:\n    - name: admin\n      groups: sudo\n      shell: /bin/bash\n      sudo: ALL=(ALL) NOPASSWD:ALL\n  packages:\n    - docker.io\n    - nginx\n  runcmd:\n    - systemctl enable docker\n    - systemctl start docker\n    - docker run -d -p 80:80 nginx\n</code></pre>"},{"location":"managing-os-images/#windows-specific-settings","title":"Windows-Specific Settings","text":"<p>For Windows VMs, additional configuration may be needed:</p> <pre><code># Windows Server 2022\n- OS_NAME: \"Windows Server 2022\"\n  CLOUD_USER: Administrator\n  MIN_MEMORY: \"4G\"\n  MIN_VCPU: \"2\"\n  MIN_STORAGE: \"80G\"\n  FIRMWARE_TYPE: \"efi\"\n  MACHINE_TYPE: \"pc-q35-rhel8.6.0\"\n  FEATURES: \"hyperv,acpi,apic,smm,tpm\"\n  BOOT_ORDER: \"cdrom,disk\"\n  ADDITIONAL_DISKS: \"virtio-drivers\"\n</code></pre>"},{"location":"managing-os-images/#api-reference","title":"API Reference","text":"<p>The OS images are served via the backend API:</p> <p>Endpoint: <code>GET /api/create-vm/{namespace}/os-images</code></p> <p>Response format: <pre><code>[\n  {\n    \"OS_NAME\": \"Ubuntu 24.04\",\n    \"CLOUD_USER\": \"ubuntu\",\n    \"OS_IMAGE_URL\": \"https://cloud-images.ubuntu.com/...\",\n    \"MIN_MEMORY\": \"1G\",\n    \"MIN_VCPU\": \"1\",\n    \"MIN_STORAGE\": \"20G\",\n    \"FIRMWARE_TYPE\": \"bios\",\n    \"MACHINE_TYPE\": \"q35\",\n    \"FEATURES\": \"acpi\",\n    \"CLOUD_INIT\": \"#cloud-config\\n...\"\n  }\n]\n</code></pre></p>"},{"location":"managing-os-images/#support","title":"Support","text":"<p>For additional help: - Check the Kube-DC documentation - Review troubleshooting guides - Open an issue in the project repository</p>"},{"location":"product-backlog/","title":"Kube-DC Product Backlog","text":"<p>This document outlines the current product backlog for the Kube-DC project, organized by epics and features.</p>"},{"location":"product-backlog/#active-epics","title":"\ud83d\ude80 Active Epics","text":""},{"location":"product-backlog/#epic-windows-support","title":"[Epic] Windows Support","text":"<p>Status: Done</p>"},{"location":"product-backlog/#epic-vmware-migration","title":"[Epic] VMware Migration","text":"<p>Status: Research Phase</p> <ul> <li>\ud83d\udd0d VMware vSphere migration research (CDI, vjailbreak)</li> <li>Investigate migration tools and methodologies</li> <li>Evaluate CDI (Containerized Data Importer) for VM migration</li> <li>Research vjailbreak and other migration utilities</li> </ul>"},{"location":"product-backlog/#epic-organization-management","title":"[Epic] Organization Management","text":"<p>Status: Planning</p> <ul> <li>\ud83d\udccb UI for project and roles</li> <li>Implement project management interface </li> <li>Role-based access control UI components</li> <li> <p>User and group management interfaces</p> </li> <li> <p>\ud83c\udfa8 Customize Login Page</p> </li> <li>Branding and customization options</li> <li>Organization-specific login themes</li> </ul>"},{"location":"product-backlog/#epic-ui-implementation-on-backend","title":"[Epic] UI Implementation on Backend","text":"<p>Status: Multiple Items in Progress</p> <ul> <li>\u274c UI Clone Disks - Not working</li> <li>Fix disk cloning functionality in UI</li> <li> <p>Ensure proper CDI integration</p> </li> <li> <p>\ud83d\udccb UI Create VM from PVC/DataVolume</p> </li> <li>Interface for VM creation from existing storage</li> <li> <p>DataVolume selection and configuration</p> </li> <li> <p>\ud83c\udf10 UI Add VM Static IP</p> </li> <li>Static IP assignment interface</li> <li> <p>Network configuration management</p> </li> <li> <p>\ud83c\udf10 UI Add VM FIP (Floating IP)</p> </li> <li>Floating IP assignment and management</li> <li> <p>Integration with FIP CRD resources</p> </li> <li> <p>\u2696\ufe0f UI Add Load Balancer Setup</p> </li> <li>Load balancer configuration interface</li> <li> <p>Service exposure management</p> </li> <li> <p>\ud83d\udd04 UI Migrate/Clone VM (rook/ceph)</p> </li> <li>VM migration interface with Rook/Ceph backend</li> <li> <p>Live migration capabilities</p> </li> <li> <p>\ud83d\udc65 UI VM Groups</p> </li> <li>VM grouping and management features</li> <li>Bulk operations on VM groups</li> </ul>"},{"location":"product-backlog/#epic-installer","title":"[Epic] Installer","text":"<p>Status: Enhancement Phase</p> <ul> <li>\ud83d\uddc4\ufe0f Postgres DB for Keycloak and Billing to be dedicated in installer stack</li> <li>Separate PostgreSQL deployment for Keycloak</li> <li> <p>Database isolation and management</p> </li> <li> <p>\u26a1 Simplify Installer</p> </li> <li>Streamline installation process</li> <li> <p>Reduce complexity and dependencies</p> </li> <li> <p>\ud83d\udda5\ufe0f Single host install</p> </li> <li>Support for single-node deployments</li> <li> <p>All-in-one installation option</p> </li> <li> <p>\ud83d\udd27 Test on VMware vSX</p> </li> <li>Validation on VMware infrastructure</li> <li> <p>Compatibility testing and documentation</p> </li> <li> <p>\ud83d\udd10 Fix hardcoded passwords in loki.yaml</p> </li> <li>Security improvement for Loki configuration</li> <li>Dynamic password generation</li> </ul>"},{"location":"product-backlog/#epic-licensing","title":"[Epic] Licensing","text":"<p>Status: Planning</p> <ul> <li>\ud83d\udcc4 License for Node Limits per installation</li> <li>Implement licensing system</li> <li>Node-based licensing model</li> <li>License validation and enforcement</li> </ul>"},{"location":"product-backlog/#epic-billing","title":"[Epic] Billing","text":"<p>Status: Planning</p> <ul> <li>\ud83d\udcb0 Billing system implementation</li> <li>Usage tracking and billing</li> <li>Integration with licensing system</li> <li>Cost management features</li> </ul>"},{"location":"product-backlog/#epic-observability","title":"[Epic] Observability","text":"<p>Status: Enhancement Phase</p> <ul> <li>\ud83d\udcca Logs</li> <li>Centralized logging improvements</li> <li> <p>Log aggregation and analysis</p> </li> <li> <p>\ud83d\udcc8 Metrics</p> </li> <li>Enhanced monitoring and metrics collection</li> <li> <p>Performance dashboards</p> </li> <li> <p>\ud83d\udea8 Alerts</p> </li> <li>Alerting system implementation</li> <li>Notification and escalation policies</li> </ul>"},{"location":"product-backlog/#epic-gpu-support","title":"[Epic] GPU Support","text":"<p>Status: Research Phase</p> <ul> <li>\ud83c\udfae Evaluate Project HAMI</li> <li>GPU sharing and management solution</li> <li>Integration assessment with KubeVirt</li> </ul>"},{"location":"product-backlog/#epic-managed-services","title":"[Epic] Managed Services","text":"<p>Status: Planning</p> <ul> <li>\u2638\ufe0f K8s CAPI (Cluster API)</li> <li>Kubernetes cluster management</li> <li> <p>Multi-cluster operations</p> </li> <li> <p>\u2638\ufe0f K8s Vcluster</p> </li> <li>Virtual cluster implementation</li> <li> <p>Tenant isolation improvements</p> </li> <li> <p>\ud83d\uddc4\ufe0f Rook S3</p> </li> <li>Object storage services</li> <li> <p>S3-compatible storage backend</p> </li> <li> <p>\ud83d\uddc4\ufe0f RDS Percona Operators</p> </li> <li>Database-as-a-Service implementation</li> <li>MySQL/PostgreSQL managed services</li> </ul>"},{"location":"product-backlog/#epic-kubevirt-enhancements","title":"[Epic] KubeVirt Enhancements","text":"<p>Status: High Priority</p> <ul> <li>\ud83d\udd04 CDI Cloning (Priority)</li> <li>VM disk cloning capabilities</li> <li> <p>Efficient storage management</p> </li> <li> <p>\ud83d\udd25 CPU, Memory, GPU Hotplug</p> </li> <li>Dynamic resource allocation</li> <li>Live resource scaling for VMs</li> </ul>"},{"location":"product-backlog/#bug-fixes","title":"\ud83d\udc1b Bug Fixes","text":""},{"location":"product-backlog/#critical-bugs","title":"Critical Bugs","text":"<ul> <li>\ud83d\udd27 UI get_kubeconfig.sh namespace issue</li> <li>Fix namespace handling in kubeconfig generation</li> <li> <p>Ensure proper authentication and authorization</p> </li> <li> <p>\ud83e\uddf9 Fix issue with stale jobs with pshell</p> </li> <li>Clean up orphaned pshell jobs</li> <li>Improve job lifecycle management</li> </ul>"},{"location":"product-backlog/#priority-matrix","title":"\ud83d\udcca Priority Matrix","text":""},{"location":"product-backlog/#high-priority","title":"High Priority","text":"<ol> <li>CDI Cloning functionality</li> <li>Windows metrics fixes</li> <li>UI disk cloning repairs</li> <li>Critical bug fixes (kubeconfig, pshell jobs)</li> </ol>"},{"location":"product-backlog/#medium-priority","title":"Medium Priority","text":"<ol> <li>VMware migration research</li> <li>GPU support evaluation</li> <li>Installer simplification</li> <li>Observability enhancements</li> </ol>"},{"location":"product-backlog/#low-priority","title":"Low Priority","text":"<ol> <li>Licensing system</li> <li>Billing implementation</li> <li>Managed services expansion</li> <li>UI enhancements (VM groups, static IP)</li> </ol> <p>Last Updated: September 2025 Document Owner: Kube-DC Product Team</p>"},{"location":"project_resources/","title":"Project Resources Documentation","text":"<p>This document provides a comprehensive overview of all resources created by the Kube-DC Project controller, their finalizers, ownership patterns, and deletion dependencies.</p>"},{"location":"project_resources/#resource-creation-order","title":"Resource Creation Order","text":"<p>When a Project is created, resources are synchronized in this order:</p> <ol> <li>Namespace - Project namespace (<code>{org}-{project}</code>)</li> <li>VPC - Kube-OVN Virtual Private Cloud</li> <li>EIp (Default Gateway) - External IP for project gateway</li> <li>Subnet - Kube-OVN subnet for project pods</li> <li>NetworkAttachmentDefinition - CNI network configuration</li> <li>OvnSnatRule - SNAT rule for outbound traffic</li> <li>Secrets - SSH keypairs and authorized keys</li> <li>RBAC - Roles and RoleBindings</li> <li>VpcDns - DNS configuration for VPC</li> </ol>"},{"location":"project_resources/#detailed-resource-breakdown","title":"Detailed Resource Breakdown","text":""},{"location":"project_resources/#1-namespace","title":"1. Namespace","text":"<ul> <li>Resource: <code>v1.Namespace</code></li> <li>Name: <code>{organization}-{project}</code> (e.g., <code>shalb-envoy</code>)</li> <li>Finalizer: None (managed by Kubernetes)</li> <li>Created by: <code>NewProjectNamespace()</code> in <code>internal/project/res_namespace.go</code></li> <li>Dependencies: None (first resource created)</li> </ul>"},{"location":"project_resources/#2-vpc-virtual-private-cloud","title":"2. VPC (Virtual Private Cloud)","text":"<ul> <li>Resource: <code>kubeovn.io/v1.Vpc</code></li> <li>Name: <code>{organization}-{project}</code> (e.g., <code>shalb-envoy</code>)</li> <li>Finalizer: <code>kubeovn.io/kube-ovn-controller</code></li> <li>Created by: <code>NewProjectVpc()</code> in <code>internal/project/res_vpc.go</code></li> <li>Dependencies: Namespace must exist</li> <li> <p>Configuration:</p> </li> <li> <p>Static routes to external subnets</p> </li> <li>Extra external subnets based on <code>egressNetworkType</code></li> </ul>"},{"location":"project_resources/#3-eip-external-ip-default-gateway","title":"3. EIp (External IP - Default Gateway)","text":"<ul> <li>Resource: <code>kube-dc.com/v1.EIp</code></li> <li>Name: <code>default-gw</code></li> <li>Namespace: <code>{organization}-{project}</code></li> <li>Finalizer: <code>eip.kube-dc.com/finalizer</code></li> <li>Created by: <code>NewProjectEip()</code> in <code>internal/project/res_eip_default.go</code></li> <li>Dependencies: Namespace must exist</li> <li> <p>Ownership States:</p> </li> <li> <p><code>Released</code>: No active owners (initial state)</p> </li> <li><code>Shared</code>: Has SNAT rule and/or LoadBalancer services as owners</li> <li><code>Exclusive</code>: Used by FIp resources</li> </ul>"},{"location":"project_resources/#4-ovneip-underlying-ovn-external-ip","title":"4. OvnEip (Underlying OVN External IP)","text":"<ul> <li>Resource: <code>kubeovn.io/v1.OvnEip</code></li> <li>Name: <code>{organization}-{project}-{external-subnet}</code> (e.g., <code>shalb-envoy-ext-public</code>)</li> <li>Finalizer: <code>kubeovn.io/kube-ovn-controller</code></li> <li>Created by: EIp controller via <code>NewOvEipRes()</code> in <code>internal/eip/ovn_eip_res.go</code></li> <li>Dependencies: EIp must exist, external subnet must be available</li> <li> <p>Labels:</p> </li> <li> <p><code>network.kube-dc.com/eip</code>: <code>{namespace}.{eip-name}</code></p> </li> <li> <p>Annotations:</p> </li> <li> <p><code>kube-dc.com/ovn-eip-created-by-eip</code>: <code>{namespace}.{eip-name}</code></p> </li> </ul>"},{"location":"project_resources/#5-subnet","title":"5. Subnet","text":"<ul> <li>Resource: <code>kubeovn.io/v1.Subnet</code></li> <li>Name: <code>{organization}-{project}-default</code> (e.g., <code>shalb-envoy-default</code>)</li> <li>Finalizer: <code>kubeovn.io/kube-ovn-controller</code></li> <li>Created by: <code>NewProjectSubnet()</code> in <code>internal/project/res_subnet.go</code></li> <li>Dependencies: VPC must exist</li> <li> <p>Configuration:</p> </li> <li> <p>CIDR block from project spec</p> </li> <li>Associated with project VPC</li> <li>Gateway IP (first IP in CIDR)</li> </ul>"},{"location":"project_resources/#6-networkattachmentdefinition","title":"6. NetworkAttachmentDefinition","text":"<ul> <li>Resource: <code>k8s.cni.cncf.io/v1.NetworkAttachmentDefinition</code></li> <li>Name: <code>default</code></li> <li>Namespace: <code>{organization}-{project}</code></li> <li>Finalizer: <code>project.kube-dc.com/finalizer</code></li> <li>Created by: <code>NewProjectNad()</code> in <code>internal/project/res_nad.go</code></li> <li>Dependencies: Subnet must exist</li> <li>Configuration: Kube-OVN CNI configuration pointing to project subnet</li> </ul>"},{"location":"project_resources/#7-ovnsnatrule","title":"7. OvnSnatRule","text":"<ul> <li>Resource: <code>kubeovn.io/v1.OvnSnatRule</code></li> <li>Name: <code>{organization}-{project}</code> (e.g., <code>shalb-envoy</code>)</li> <li>Finalizer: <code>kubeovn.io/kube-ovn-controller</code></li> <li>Created by: <code>NewProjectSnat()</code> in <code>internal/project/res_snat.go</code></li> <li>Dependencies: OvnEip must exist and have IP assigned</li> <li> <p>Configuration:</p> </li> <li> <p>Links project subnet to external IP</p> </li> <li>Enables outbound internet access for pods</li> </ul>"},{"location":"project_resources/#8-secrets","title":"8. Secrets","text":""},{"location":"project_resources/#ssh-key-pair-secret","title":"SSH Key Pair Secret","text":"<ul> <li>Resource: <code>v1.Secret</code></li> <li>Name: <code>ssh-keypair-default</code></li> <li>Namespace: <code>{organization}-{project}</code></li> <li>Finalizer: <code>project.kube-dc.com/finalizer</code></li> <li>Created by: <code>NewProjectKeyPairSeret()</code> in <code>internal/project/res_secret.go</code></li> <li>Content: Generated SSH public/private key pair</li> </ul>"},{"location":"project_resources/#authorized-keys-secret","title":"Authorized Keys Secret","text":"<ul> <li>Resource: <code>v1.Secret</code></li> <li>Name: <code>authorized-keys-default</code></li> <li>Namespace: <code>{organization}-{project}</code></li> <li>Finalizer: <code>project.kube-dc.com/finalizer</code></li> <li>Created by: <code>NewProjectAuthKeySecret()</code> in <code>internal/project/res_secret.go</code></li> <li>Content: SSH public keys for VM access</li> </ul>"},{"location":"project_resources/#9-rbac-resources","title":"9. RBAC Resources","text":""},{"location":"project_resources/#role","title":"Role","text":"<ul> <li>Resource: <code>rbac.authorization.k8s.io/v1.Role</code></li> <li>Name: <code>admin</code></li> <li>Namespace: <code>{organization}-{project}</code></li> <li>Finalizer: <code>project.kube-dc.com/finalizer</code></li> <li>Created by: <code>NewProjectRole()</code> in <code>internal/project/res_role.go</code></li> <li>Permissions: Full access to project resources (pods, services, VMs, etc.)</li> </ul>"},{"location":"project_resources/#rolebinding","title":"RoleBinding","text":"<ul> <li>Resource: <code>rbac.authorization.k8s.io/v1.RoleBinding</code></li> <li>Name: <code>org-admin</code></li> <li>Namespace: <code>{organization}-{project}</code></li> <li>Finalizer: <code>project.kube-dc.com/finalizer</code></li> <li>Created by: <code>NewProjectRoleBinding()</code> in <code>internal/project/res_role_binding.go</code></li> <li>Subject: <code>{organization}:org-admin</code> group</li> </ul>"},{"location":"project_resources/#10-vpcdns-service","title":"10. VpcDns Service","text":"<ul> <li>Resource: <code>v1.Service</code></li> <li>Name: <code>slr-vpc-dns-{organization}-{project}</code></li> <li>Namespace: <code>kube-system</code></li> <li>Finalizer: None (managed by service controller)</li> <li>Created by: <code>NewProjectVpcDns()</code> in <code>internal/project/res_vpc_dns.go</code></li> <li>Purpose: DNS resolution for VPC</li> </ul>"},{"location":"project_resources/#finalizers-summary","title":"Finalizers Summary","text":"Resource Type Finalizer Controller Project <code>project.kube-dc.com/finalizer</code> kube-dc-manager EIp <code>eip.kube-dc.com/finalizer</code> kube-dc-manager OvnEip <code>kubeovn.io/kube-ovn-controller</code> kube-ovn-controller Vpc <code>kubeovn.io/kube-ovn-controller</code> kube-ovn-controller Subnet <code>kubeovn.io/kube-ovn-controller</code> kube-ovn-controller OvnSnatRule <code>kubeovn.io/kube-ovn-controller</code> kube-ovn-controller NetworkAttachmentDefinition <code>project.kube-dc.com/finalizer</code> kube-dc-manager Secrets <code>project.kube-dc.com/finalizer</code> kube-dc-manager Role <code>project.kube-dc.com/finalizer</code> kube-dc-manager RoleBinding <code>project.kube-dc.com/finalizer</code> kube-dc-manager"},{"location":"project_resources/#deletion-order-and-dependencies","title":"Deletion Order and Dependencies","text":"<p>When a Project is deleted, resources must be removed in reverse dependency order:</p>"},{"location":"project_resources/#phase-1-application-resources","title":"Phase 1: Application Resources","text":"<ol> <li>Pods, Services, VMs - User workloads (deleted by users/operators)</li> <li>FIp resources - Floating IPs (if any exist)</li> </ol>"},{"location":"project_resources/#phase-2-snat-and-networking","title":"Phase 2: SNAT and Networking","text":"<ol> <li>OvnSnatRule - Must be deleted before OvnEip</li> <li>OvnEip - Must be deleted before EIp and Subnet</li> </ol>"},{"location":"project_resources/#phase-3-project-infrastructure","title":"Phase 3: Project Infrastructure","text":"<ol> <li>EIp - External IP resource</li> <li>NetworkAttachmentDefinition - CNI configuration</li> <li>Secrets - SSH keys and authorized keys</li> <li>RBAC - Roles and RoleBindings</li> <li>Subnet - Must be deleted before VPC</li> <li>VPC - Virtual Private Cloud</li> <li>VpcDns - DNS service</li> <li>Namespace - Project namespace (last)</li> </ol>"},{"location":"project_resources/#common-deletion-issues","title":"Common Deletion Issues","text":""},{"location":"project_resources/#stuck-finalizers","title":"Stuck Finalizers","text":"<ul> <li>OvnEip: May get stuck if SNAT rule deletion fails</li> <li>Subnet: May get stuck if pods are still running</li> <li>EIp: May get stuck if project is deleted before EIp controller processes it</li> </ul>"},{"location":"project_resources/#manual-cleanup-commands","title":"Manual Cleanup Commands","text":"<pre><code># Remove stuck finalizers (use with caution)\nkubectl patch ovn-snat-rule {name} -p '{\"metadata\":{\"finalizers\":null}}' --type=merge\nkubectl patch ovn-eip {name} -p '{\"metadata\":{\"finalizers\":null}}' --type=merge\nkubectl patch subnet {name} -p '{\"metadata\":{\"finalizers\":null}}' --type=merge\nkubectl patch eip {name} -n {namespace} -p '{\"metadata\":{\"finalizers\":null}}' --type=merge\nkubectl patch project {name} -n {org-namespace} -p '{\"metadata\":{\"finalizers\":null}}' --type=merge\n</code></pre>"},{"location":"project_resources/#eip-ownership-patterns","title":"EIp Ownership Patterns","text":""},{"location":"project_resources/#ownership-states","title":"Ownership States","text":"<ul> <li>Released: <code>ownershipType: Released</code>, <code>owners: []</code> - No active users</li> <li>Shared: <code>ownershipType: Shared</code>, <code>owners: [...]</code> - Multiple users (SNAT + Services)</li> <li>Exclusive: <code>ownershipType: Exclusive</code>, <code>owners: [single]</code> - Single FIp owner</li> </ul>"},{"location":"project_resources/#owner-types","title":"Owner Types","text":"<ul> <li><code>Snat</code>: SNAT rule using the EIP for outbound traffic</li> <li><code>ServiceLb</code>: LoadBalancer service using the EIP</li> <li><code>FIp</code>: Floating IP using the EIP exclusively</li> </ul>"},{"location":"project_resources/#ownership-transitions","title":"Ownership Transitions","text":"<pre><code>Released \u2192 Shared (first owner added)\nShared \u2192 Released (last owner removed)\nReleased \u2192 Exclusive (FIp claims EIP)\nExclusive \u2192 Released (FIp releases EIP)\n</code></pre>"},{"location":"project_resources/#organization-limits","title":"Organization Limits","text":"<p>Organizations have a configurable limit on the number of ready projects they can contain (default: 3). This limit is enforced by the Project controller during reconciliation.</p> <ul> <li>Configuration: Set via <code>MasterConfig.OrganizationProjectsLimit</code></li> <li>Enforcement: Projects exceeding the limit will not be reconciled until space becomes available</li> <li>Status: Projects blocked by limits show as not ready but remain in the cluster</li> </ul>"},{"location":"project_resources/#enhanced-limit-enforcement-v0131-dev1","title":"Enhanced Limit Enforcement (v0.1.31-dev1+)","text":"<p>The Project controller now provides comprehensive feedback when organization limits are hit:</p> <p>Detailed Logging: - Organization project status with ready/pending counts and project names - Clear error messages with organization, namespace, and limit context - Debug-level logs showing available slots and project lists</p> <p>Status Conditions: Projects blocked by limits receive a <code>LimitCheck</code> condition: <pre><code>status:\n  ready: false\n  conditions:\n  - type: LimitCheck\n    status: \"False\"\n    reason: LimitExceeded\n    message: \"organization limit (3 projects) reached - ready projects: 3 (limit: 3)\"\n    lastTransitionTime: \"2025-01-19T16:45:00Z\"\n</code></pre></p> <p>Automatic Retry: - Projects are automatically requeued every 30 seconds - Reconciliation proceeds when limit space becomes available - No manual intervention required</p> <p>Projects can use different external network types: - cloud: Uses <code>ext-cloud</code> subnet (default) - public: Uses <code>ext-public</code> subnet (real public IPs)</p> <p>The <code>egressNetworkType</code> in Project spec determines which external subnet is used for the default gateway EIP.</p>"},{"location":"quickstart-hetzner/","title":"Master-Worker Setup on Hetzner Dedicated Servers","text":"<p>This guide provides step-by-step instructions for deploying a Kube-DC cluster with a master and worker node setup on Hetzner Dedicated Servers. This deployment leverages Hetzner's vSwitch and additional subnets to provide enterprise-grade networking capabilities for floating IPs and load balancers.</p>"},{"location":"quickstart-hetzner/#prerequisites","title":"Prerequisites","text":"<ol> <li>At least two Hetzner Dedicated Servers</li> <li>Access to Hetzner Robot interface</li> <li>A Hetzner vSwitch configured for your servers (see Hetzner vSwitch documentation)</li> <li>An additional subnet allocated through Hetzner Robot for external IPs and load balancers</li> <li>Wildcard domain ex: *.dev.kube-dc.com shoud be set to main public ip of master node.</li> </ol>"},{"location":"quickstart-hetzner/#server-configuration","title":"Server Configuration","text":""},{"location":"quickstart-hetzner/#1-prepare-servers","title":"1. Prepare Servers","text":"<p>Ensure your Hetzner Dedicated Servers meet these minimum requirements: - Master Node: 4+ CPU cores, 16+ GB RAM - Worker Node: 4+ CPU cores, 16+ GB RAM</p> <p>Install Ubuntu 24.04 LTS on all servers through the Hetzner Robot interface.</p>"},{"location":"quickstart-hetzner/#2-configure-vswitch","title":"2. Configure vSwitch","text":"<p>In the Hetzner Robot interface:</p> <ol> <li>Create a vSwitch if you don't have one already</li> <li>Add your servers to the vSwitch   </li> <li>Request an additional subnet to be used for external IPs (Floating IPs)</li> <li>Assign the subnet to your vSwitch:   </li> </ol> <p>You will get two vlan ids, one for the local network(in example 4012) and one for the external subnet with public ips(in example 4011).</p>"},{"location":"quickstart-hetzner/#network-configuration","title":"Network Configuration","text":""},{"location":"quickstart-hetzner/#1-configure-network-interfaces","title":"1. Configure Network Interfaces","text":"<p>SSH into each server and configure the networking using Netplan. Backup default netplan config: <pre><code>mkdir /root/tmp/\nmv /etc/netplan/*.yaml /root/tmp/\n</code></pre> Create new config(<code>/etc/netplan/60-kube-dc.yaml</code>) Replace values with <code>example</code> by values from default file(see it in <code>/root/tmp/</code>):</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s31f6_example:  # Primary network interface name (get it from default netplan config)\n      addresses:\n        - 22.22.22.2_example/24  # Primary IP address and subnet mask (get it from default netplan config)\n      routes:\n        - to: 0.0.0.0/0  # Default route for all traffic\n          via: 22.22.22.1_example  # Gateway IP address (get it from default netplan config)\n          on-link: true  # Indicates the gateway is directly reachable\n          metric: 100  # Route priority (lower = higher priority)\n      routing-policy:\n        - from: 22.22.22.2_example  # Source-based routing for traffic from gateway (Primary IP)\n          table: 100  # Custom routing table ID\n      nameservers:\n        addresses:\n          - 8.8.8.8  # Primary DNS server (Google)\n          - 8.8.4.4  # Secondary DNS server (Google)\n  vlans:\n    enp0s31f6.4012_example:  # VLAN interface name (format: interface.vlan_id, see your VLAN in https://robot.hetzner.com/vswitch/index)\n      id: 4012_example  # VLAN ID (must match your Hetzner vSwitch ID, same vlan_id)\n      link: enp0s31f6_example  # Parent interface for VLAN (same interface from default netplan config)\n      mtu: 1460  # Maximum Transmission Unit size\n      addresses:\n        - 192.168.100.2/22  # Master node IP on private network (This for master node setup)\n       #- 192.168.100.3/22  # Worker node IP                    (This for master node setup)\n</code></pre> <p>Apply the configuration:</p> <pre><code>sudo netplan apply\n</code></pre>"},{"location":"quickstart-hetzner/#2-system-optimization","title":"2. System Optimization","text":"<p>Downgrade kernel (due to a bug in kernel https://github.com/k3s-io/k3s/issues/11175):</p> <pre><code>sudo apt -y update\nsudo apt install linux-image-6.8.0-52-generic linux-headers-6.8.0-52-generic\n# Remove previous kernel\nsudo apt-get remove --purge linux-image-6.8.0-58-generic linux-headers-6.8.0-58-generic\n# Reboot\nsudo reboot\n</code></pre> <p>On all nodes, update, upgrade, and install required software:</p> <pre><code>sudo apt -y install unzip iptables linux-headers-$(uname -r)\n</code></pre> <p>Update to the latest kernel version:</p> <pre><code>sudo apt -y install linux-generic\nsudo reboot\n</code></pre> <p>After the server reboots, verify your kernel version:</p> <pre><code>uname -r\n</code></pre> <p>Optimize system settings by adding to <code>/etc/sysctl.conf</code>:</p> <pre><code># Increase inotify limits\nfs.inotify.max_user_watches=1524288\nfs.inotify.max_user_instances=4024\n\n# Enable packet forwarding\nnet.ipv4.ip_forward = 1\n</code></pre> <p>Ensure the nf_conntrack module is loaded:</p> <pre><code># Check if the module is loaded\nlsmod | grep nf_conntrack\n\n# If not loaded, load it manually\nsudo modprobe nf_conntrack\n\n# To ensure it's loaded on boot, add it to /etc/modules\necho \"nf_conntrack\" | sudo tee -a /etc/modules\n</code></pre> <p>Apply the changes:</p> <pre><code>sudo sysctl -p\n</code></pre> <p>Disable systemd-resolved to prevent DNS conflicts:</p> <pre><code>sudo systemctl stop systemd-resolved\nsudo systemctl disable systemd-resolved\nsudo rm /etc/resolv.conf\necho \"nameserver 8.8.8.8\" | sudo tee /etc/resolv.conf\necho \"nameserver 8.8.4.4\" | sudo tee -a /etc/resolv.conf\n</code></pre> <p>Update the hosts file on each server with the private IPs:</p> <pre><code># On Master Node\necho \"192.168.100.2 kube-dc-master-1\" | sudo tee -a /etc/hosts\n# On Worker Node\necho \"192.168.100.3 kube-dc-worker-1\" | sudo tee -a /etc/hosts\n</code></pre>"},{"location":"quickstart-hetzner/#kubernetes-installation","title":"Kubernetes Installation","text":""},{"location":"quickstart-hetzner/#1-install-clusterdev","title":"1. Install Cluster.dev","text":"<p>On the master node, install Cluster.dev:</p> <pre><code>curl -fsSL https://raw.githubusercontent.com/shalb/cluster.dev/master/scripts/get_cdev.sh | sh\n</code></pre>"},{"location":"quickstart-hetzner/#2-configure-and-install-rke2-on-master-node","title":"2. Configure and Install RKE2 on Master Node","text":"<p>Install kubectl:</p> <pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin/\n</code></pre> <p>Create RKE2 configuration (replace the external IP with your server's public IP):</p> <pre><code>sudo mkdir -p /etc/rancher/rke2/\n\ncat &lt;&lt;EOF | sudo tee /etc/rancher/rke2/config.yaml\nnode-name: kube-dc-master-1\ndisable-cloud-controller: true\ndisable: rke2-ingress-nginx\ncni: none\ncluster-cidr: \"10.100.0.0/16\"\nservice-cidr: \"10.101.0.0/16\"\ncluster-dns: \"10.101.0.11\"\nnode-label:\n  - kube-dc-manager=true\n  - kube-ovn/role=master\nkube-apiserver-arg: \n  - authentication-config=/etc/rancher/auth-conf.yaml\ndebug: true\nnode-external-ip: 22.22.22.2_example # Primary IP address (get it from default netplan config)\ntls-san:\n  - kube-api.yourdomain.com\n  - 192.168.100.2 # Master node IP on private network (This for master node setup)\nadvertise-address: 192.168.100.2 # Master node IP on private network (This for master node setup)\nnode-ip: 192.168.100.2 # Master node IP on private network (This for master node setup)\nEOF\n\ncat &lt;&lt;EOF | sudo tee /etc/rancher/auth-conf.yaml\napiVersion: apiserver.config.k8s.io/v1beta1\nkind: AuthenticationConfiguration\njwt: []\nEOF\nsudo chmod 666 /etc/rancher/auth-conf.yaml\n</code></pre> <p>Install RKE2 server:</p> <pre><code>export INSTALL_RKE2_VERSION=\"v1.32.1+rke2r1\"\nexport INSTALL_RKE2_TYPE=\"server\"\ncurl -sfL https://get.rke2.io | sh -\nsudo systemctl enable rke2-server.service\nsudo systemctl start rke2-server.service\n</code></pre> <p>You can check the installation logs here:</p> <pre><code>sudo journalctl -u rke2-server -f\n</code></pre> <p>Configure kubectl:</p> <pre><code>mkdir -p ~/.kube\nsudo cp /etc/rancher/rke2/rke2.yaml ~/.kube/config\nsudo chown $(id -u):$(id -g) ~/.kube/config\nchmod 600 ~/.kube/config\n</code></pre> <p>Verify the cluster status:</p> <pre><code>kubectl get nodes\n# If you see this output then you can proceed:\nNAME               STATUS     ROLES\nkube-dc-master-1   NotReady   control-plane,etcd,master\n</code></pre>"},{"location":"quickstart-hetzner/#4-join-worker-node-to-the-cluster","title":"4. Join Worker Node to the Cluster","text":"<p>Get the join token from the master node:</p> <pre><code># on master node\nsudo cat /var/lib/rancher/rke2/server/node-token\n</code></pre> <p>On the worker node, create the RKE2 configuration (replace TOKEN with the token from the master node):</p> <pre><code># on worker node\nsudo mkdir -p /etc/rancher/rke2/\n\ncat &lt;&lt;EOF | sudo tee /etc/rancher/rke2/config.yaml\ntoken: &lt;TOKEN&gt;\nserver: https://192.168.100.2:9345 # Master node local IP\nnode-name: kube-dc-worker-1\nnode-ip: 192.168.100.3\nEOF\n</code></pre> <p>Install RKE2 agent:</p> <pre><code># on worker node\nexport INSTALL_RKE2_VERSION=\"v1.32.1+rke2r1\"\nexport INSTALL_RKE2_TYPE=\"agent\"\ncurl -sfL https://get.rke2.io | sh -\nsudo systemctl enable rke2-agent.service\nsudo systemctl start rke2-agent.service\n</code></pre> <p>Monitor the agent service:</p> <pre><code># on worker node\nsudo journalctl -u rke2-agent -f\n</code></pre> <p>Verify on the master node that the worker joined successfully:</p> <pre><code># on master node\nkubectl get nodes\n</code></pre>"},{"location":"quickstart-hetzner/#install-kube-dc-components-on-master-node","title":"Install Kube-DC Components on Master Node","text":""},{"location":"quickstart-hetzner/#1-create-clusterdev-project-configuration","title":"1. Create Cluster.dev Project Configuration","text":"<p>On the master node, create a project configuration file:</p> <pre><code>mkdir -p ~/kube-dc-hetzner\ncat &lt;&lt;EOF &gt; ~/kube-dc-hetzner/project.yaml\nkind: Project\nname: kube-dc-hetzner\nbackend: \"default\"\nvariables:\n  kubeconfig: ~/.kube/config\n  debug: true\nEOF\n</code></pre>"},{"location":"quickstart-hetzner/#2-create-clusterdev-stack-configuration","title":"2. Create Cluster.dev Stack Configuration","text":"<p>Create the stack configuration file(replace <code>example</code> by appropriate values):</p> <pre><code>cat &lt;&lt;EOF &gt; ~/kube-dc-hetzner/stack.yaml\nname: cluster\ntemplate: https://github.com/kube-dc/kube-dc-public//installer/kube-dc/templates/kube-dc?ref=main\nkind: Stack\nbackend: default\nvariables:\n  debug: \"true\"\n  kubeconfig: /root/.kube/config # Change for your username path to RKE kubeconfig\n\n  cluster_config:\n    pod_cidr: \"10.100.0.0/16\"\n    svc_cidr: \"10.101.0.0/16\"\n    join_cidr: \"100.64.0.0/16\"\n    cluster_dns: \"10.101.0.11\"\n    default_external_network:\n      nodes_list: # list of nodes, where 4011 vlan (external network) is accessible\n        - kube-dc-master-1\n        - kube-dc-worker-1\n      name: external4011_example # VLAN interface for this name you can find here https://robot.hetzner.com/vswitch/index\n      vlan_id: \"4011_example\" # VLAN interface id, see your VLAN in https://robot.hetzner.com/vswitch/index\n      interface: \"enp0s31f6_example\" # Parent interface for VLAN (same interface from default netplan config)\n      cidr: \"33.33.33.33_example/29\" # External subnet provided by Hetzner (should see during VLAN creation here https://robot.hetzner.com/vswitch/index)\n      gateway: 33.33.33.34_example # Gateway for external subnet (should see during VLAN creation here https://robot.hetzner.com/vswitch/index)\n      mtu: \"1400\"\n\n  node_external_ip: 22.22.22.2_example # Primary IP address (get it from default netplan config). Wildcard *.dev.kube-dc.com shoud be faced on this ip\n\n\n  email: \"noreply@example.com\"\n  domain: \"dev.example-kube-dc.com\"\n  install_terraform: true\n\n  create_default:\n    organization:\n      name: example\n      description: \"My test org my-org 1\"\n      email: \"example@example.com\"\n    project:\n      name: demo\n      cidr_block: \"10.1.0.0/16\"\n\n  monitoring:\n    prom_storage: 20Gi\n    retention_size: 17GiB\n    retention: 365d\n\n  versions:\n    kube_dc: \"v0.1.21\" # release version\nEOF\n</code></pre>"},{"location":"quickstart-hetzner/#3-deploy-kube-dc","title":"3. Deploy Kube-DC","text":"<p>Run Cluster.dev to deploy Kube-DC components:</p> <pre><code>cd ~/kube-dc-hetzner\ncdev apply\n</code></pre> <p>This process will take 15-20 minutes to complete. You can monitor the deployment progress in the terminal output.</p>"},{"location":"quickstart-hetzner/#4-verify-installation","title":"4. Verify Installation","text":"<p>After successful deployment, you will receive console and login credentials for deployment admin user. Also if you have created some default organization youll get organization admin credentials. Example:</p> <pre><code>keycloak_user = admin\norganization_admin_username = admin\norganization_name = example\nproject_name = demo\nretrieve_organization_password = kubectl get secret realm-access -n example -o jsonpath='{.data.password}' | base64 -d\nretrieve_organization_realm_url = kubectl get secret realm-access -n example -o jsonpath='{.data.url}' | base64 -d\nconsole_url = https://console.dev.kube-dc.com\nkeycloak_password = XXXXXXXX\nkeycloak_url = https://login.dev.kube-dc.com\n</code></pre>"},{"location":"quickstart-hetzner/#post-installation-steps","title":"Post-Installation Steps","text":""},{"location":"quickstart-hetzner/#1-access-kube-dc-ui-using-default-organization-credentials","title":"1. Access Kube-DC UI using default organization credentials","text":"<p>After the installation completes, the Kube-DC UI should be accessible at <code>https://console.yourdomain.com</code>. In cdev output there are output for default organization, project and admin user for default organization(use <code>retrieve_organization_password</code> to login):</p> <pre><code>console_url = https://console.dev.kube-dc.com\norganization_admin_username = admin\norganization_name = example\nproject_name = demo\nretrieve_organization_password = kubectl get secret realm-access -n example -o jsonpath='{.data.password}' | base64 -d\nretrieve_organization_realm_url = kubectl get secret realm-access -n example -o jsonpath='{.data.url}' | base64 -d\n</code></pre>"},{"location":"quickstart-hetzner/#2-keep-credentials-for-keycloak-master-admin-user","title":"2. Keep credentials for Keycloak master admin user","text":"<p>You can save global Keycloak credentials if you need to manage Keycloak as super-admin.</p> <p>Master admin user credentials:</p> <pre><code>keycloak_user = admin\nkeycloak_password = XXXXXXXX\nkeycloak_url = https://login.dev.kube-dc.com\n</code></pre>"},{"location":"quickstart-hetzner/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues during the installation:</p> <ol> <li> <p>Check the RKE2 server/agent logs:    <pre><code>sudo journalctl -u rke2-server -f  # On master\nsudo journalctl -u rke2-agent -f   # On worker\n</code></pre></p> </li> <li> <p>Check the Kube-OVN logs:    <pre><code>kubectl logs -n kube-system -l app=kube-ovn-controller\n</code></pre></p> </li> <li> <p>Verify network connectivity between nodes on the private network:    <pre><code>ping 192.168.100.2  # From worker node\nping 192.168.100.3  # From master node\n</code></pre></p> </li> </ol> <p>For additional help, consult the Kube-DC community support resources.</p>"},{"location":"quickstart-overview/","title":"Kube-DC Installation Overview","text":"<p>This document provides a technical overview of the Kube-DC installation process, with detailed explanations of key configuration files and their parameters.</p>"},{"location":"quickstart-overview/#installation-methods","title":"Installation Methods","text":"<p>Kube-DC can be installed in several ways:</p> <ul> <li>Master-Worker deployment: Recommended starting point for new deployments</li> <li>Multi-node HA cluster: For production environments</li> </ul> <p>Start with actual tested deployment on Hetzner Bare Metal Servers.</p>"},{"location":"quickstart-overview/#prerequisites","title":"Prerequisites","text":"<p>Before installing Kube-DC, ensure your system meets the following requirements:</p> <ul> <li>Hardware: Minimum 4 CPU cores, 8GB RAM per node</li> <li>Operating System: Ubuntu 20.04 LTS or newer (24.04 LTS recommended)</li> <li>Network: Dedicated network interface for VM traffic with VLAN support</li> <li>Storage: Local or network storage with support for dynamic provisioning</li> <li>Kubernetes: Version 1.31+ if installing on existing cluster</li> </ul>"},{"location":"quickstart-overview/#network-configuration","title":"Network Configuration","text":"<p>Kube-DC requires proper network configuration for optimal performance. The key requirement is that your external network must be routed through a VLAN to enable advanced networking features.</p>"},{"location":"quickstart-overview/#external-network-requirements","title":"External Network Requirements","text":"<p>Kube-DC networking is built on top of Kube-OVN and requires the following network configuration:</p> <ul> <li>VLAN-capable network interface: A dedicated network interface with VLAN support</li> <li>External subnet with routing: An external subnet that's properly routed to your infrastructure</li> <li>Static IP configuration: Static IP addressing (no DHCP) to ensure network stability</li> </ul> <p>This configuration allows Kube-DC to implement:</p> <ul> <li>Floating IP allocation: Dynamically assign public IPs to workloads</li> <li>Load balancer with external IPs: Distribute traffic to services with public visibility</li> <li>Default gateway per project: Isolate network traffic between projects</li> </ul> <p>All of these features work as a wrapper on top of Kube-OVN, providing enterprise-grade networking capabilities for your infrastructure.</p>"},{"location":"quickstart-overview/#example-network-configuration","title":"Example Network Configuration","text":"<p>Below is an example Netplan configuration with detailed comments for a VLAN-enabled network:</p> <pre><code>network:\n  version: 2  # Netplan version\n  renderer: networkd  # Network renderer to use\n  ethernets:\n    eth0:  # Primary network interface name (check your actual interface name)\n      addresses:\n        - 192.168.1.2/24  # Primary IP address and subnet mask\n      routes:\n        - to: 0.0.0.0/0  # Default route for all traffic\n          via: 192.168.1.1  # Gateway IP address\n          on-link: true  # Indicates the gateway is directly reachable\n          metric: 100  # Route priority (lower = higher priority)\n      nameservers:\n        addresses:\n          - 8.8.8.8  # Primary DNS server (Google)\n          - 8.8.4.4  # Secondary DNS server (Google)\n  vlans:\n    eth0.100:  # VLAN interface (format: interface.vlan_id)\n      id: 100  # VLAN ID\n      link: eth0  # Parent interface for VLAN \n      mtu: 1500  # Recommended MTU for your network\n      addresses:\n        - 10.100.0.2/24  # Private IP on the VLAN network\n</code></pre> <p>Important</p> <p>Do not use DHCP for the VLAN interface as it would break the initial Kube-OVN setup. Always use static IP configuration.</p>"},{"location":"quickstart-overview/#networking-components","title":"Networking Components","text":"<p>The Kube-DC network setup consists of several key components that work together:</p> <ol> <li>Kube-OVN: Core CNI providing overlay and underlay networking</li> <li>Multus CNI: Enables multiple network interfaces for pods</li> <li>VLAN Integration: Connects Kubernetes networking to physical infrastructure</li> </ol>"},{"location":"quickstart-overview/#core-components","title":"Core Components","text":"<p>The Kube-DC installer deploys the following core components:</p> <ol> <li>Kube-OVN: Advanced networking solution that provides overlay and underlay networking</li> <li>Multus CNI: CNI that enables attaching multiple network interfaces to pods</li> <li>KubeVirt: Virtualization layer for running VMs on Kubernetes</li> <li>Keycloak: Identity and access management solution</li> <li>Cert-Manager: Certificate management for TLS</li> <li>Ingress-NGINX: Ingress controller for external access</li> <li>Prometheus &amp; Loki: Monitoring and logging stack</li> <li>Kube-DC Core: The core management components for Kube-DC</li> </ol>"},{"location":"quickstart-overview/#installation-process-overview","title":"Installation Process Overview","text":"<p>The installation process follows these high-level steps:</p> <ol> <li>System Preparation: Configure network, optimize system settings, and install prerequisites</li> <li>Kubernetes Installation: Install RKE2 on master and worker nodes</li> <li>Kube-DC Installation: Use cluster.dev to deploy Kube-DC components</li> <li>Post-Installation Setup: Configure authentication, networking, and initial organization</li> </ol> <p>For detailed step-by-step instructions, refer to: - Master-Worker Setup (Dedicated Servers)</p>"},{"location":"roadmap/","title":"Kube-DC Product Roadmap","text":"<p>Build Your Own AI &amp; GPU Cloud on Any Server Transform bare-metal servers into a modern cloud with Kubernetes-native orchestration, GPU sharing, and multi-tenancy.</p> <p>Last Updated: December 9, 2025</p>"},{"location":"roadmap/#executive-summary","title":"Executive Summary","text":"Milestone Target Date Key Deliverable Installer v2 Jan 2026 Single-node &amp; simplified installation Global Admin UI Feb 2026 Platform-wide administration console Database as a Service Mar 2026 PostgreSQL, MySQL, MongoDB, Redis S3 Object Storage Apr 2026 Rook/Ceph multi-tenant buckets GPU/AI Platform May 2026 HAMI sharing, KubeFlow integration Billing System Jun 2026 Metering, pricing, usage reports Licensing Jul 2026 Node-based license management Hybrid Cloud Sep 2026 Multi-cluster federation, DR Advanced Networking Oct 2026 VPN, Security Groups, Service Mesh Edge Computing Q1 2027 Lightweight edge deployments"},{"location":"roadmap/#current-state-v0135","title":"Current State (v0.1.35) \u2705","text":""},{"location":"roadmap/#core-platform-complete","title":"Core Platform \u2014 Complete","text":"<ul> <li>Multi-Tenancy: Organizations, Projects, Keycloak SSO, RBAC</li> <li>Networking: Kube-OVN VPC, EIP/FIP, LoadBalancer, multi-network support</li> <li>Virtualization: KubeVirt VMs, Linux/Windows support, VNC, SSH injection</li> <li>KaaS: Multi-tenant control planes (Kamaji), KubeVirt/CloudSigma workers, Cilium CNI</li> <li>Observability: Prometheus metrics, Loki logging, VM monitoring charts</li> <li>UI: Web console, VM lifecycle, monitoring dashboards</li> </ul>"},{"location":"roadmap/#2026-roadmap","title":"2026 Roadmap","text":""},{"location":"roadmap/#q1-2026-foundation-administration","title":"Q1 2026: Foundation &amp; Administration","text":""},{"location":"roadmap/#installer-v20-january-2026","title":"\ud83d\udce6 Installer v2.0 \u2014 January 2026","text":"Feature Description Single-node Install All-in-one deployment for dev/small production Simplified Setup Reduced dependencies, guided installation Air-gapped Support Offline installation capability Security Hardening Dynamic secrets, no hardcoded passwords"},{"location":"roadmap/#global-admin-view-february-2026","title":"\ud83d\udda5\ufe0f Global Admin View \u2014 February 2026","text":"Feature Description Platform Dashboard Cluster-wide resource overview Organization Management Create/manage all organizations User Administration Global user and group management System Health Infrastructure monitoring and alerts Audit Console Platform-wide audit log viewer"},{"location":"roadmap/#q2-2026-managed-services","title":"Q2 2026: Managed Services","text":""},{"location":"roadmap/#database-as-a-service-march-2026","title":"\ud83d\uddc4\ufe0f Database as a Service \u2014 March 2026","text":"Database Features PostgreSQL CloudNativePG, auto-failover, continuous backups MySQL/MariaDB Percona Operator, clustering, PITR MongoDB Sharding, replica sets, automated backups Redis Clustering, persistence, sentinel <p>Capabilities: One-click provisioning, automated backups, connection pooling, performance dashboards</p>"},{"location":"roadmap/#s3-object-storage-april-2026","title":"\ud83d\udcbe S3 Object Storage \u2014 April 2026","text":"Feature Description Rook/Ceph Backend Production-grade object storage Multi-tenant Buckets Per-project isolation IAM Policies Fine-grained access control Lifecycle Management Automated data retention"},{"location":"roadmap/#gpu-aiml-platform-may-2026","title":"\ud83c\udfae GPU &amp; AI/ML Platform \u2014 May 2026","text":"Feature Description GPU Passthrough Full Nvidia GPU to VMs/pods HAMI Integration Fractional GPU sharing vGPU Support Virtual GPUs for multi-tenant KubeFlow ML pipeline orchestration LLM Serving Model inference infrastructure Vector Databases AI-native data stores"},{"location":"roadmap/#q3-2026-monetization-operations","title":"Q3 2026: Monetization &amp; Operations","text":""},{"location":"roadmap/#billing-system-june-2026","title":"\ud83d\udcb0 Billing System \u2014 June 2026","text":"Feature Description Resource Metering CPU, memory, storage, GPU, network Pricing Models Custom tiers, pay-per-use Usage Reports Detailed analytics, export Billing API External system integration Quota Enforcement Automatic limit enforcement"},{"location":"roadmap/#licensing-july-2026","title":"\ud83d\udd10 Licensing \u2014 July 2026","text":"Feature Description License Manager Node-based licensing Feature Gates License-controlled features Usage Tracking Compliance reporting Trial Mode Time-limited evaluations"},{"location":"roadmap/#ui-enhancements-august-2026","title":"\ud83d\udcca UI Enhancements \u2014 August 2026","text":"Feature Description KaaS Console Cluster creation wizard DBaaS Console Database management UI Storage Console S3 bucket management Billing Dashboard Cost visibility and reports"},{"location":"roadmap/#q4-2026-enterprise-integration","title":"Q4 2026: Enterprise Integration","text":""},{"location":"roadmap/#hybrid-cloud-september-2026","title":"\u2601\ufe0f Hybrid Cloud \u2014 September 2026","text":"Feature Description Multi-Cluster Federation Unified management across sites Cloud Bursting Extend to AWS/Azure/GCP Disaster Recovery Cross-site replication Backup Services Automated VM/container backups VMware Migration CDI import, vjailbreak, wizard"},{"location":"roadmap/#advanced-networking-october-2026","title":"\ud83c\udf10 Advanced Networking \u2014 October 2026","text":"Feature Description Network Peering Cross-project connectivity VPN Gateway Site-to-site VPN Security Groups Stateful firewall rules Service Mesh Istio/Linkerd integration DNS Management Custom domains, auto-DNS"},{"location":"roadmap/#2027-roadmap","title":"2027 Roadmap","text":""},{"location":"roadmap/#q1-2027-edge-advanced-automation","title":"Q1 2027: Edge &amp; Advanced Automation","text":""},{"location":"roadmap/#edge-computing-q1-2027","title":"\ud83d\udcf1 Edge Computing \u2014 Q1 2027","text":"Feature Description Edge Clusters Lightweight K3s deployments Edge-to-Core Sync Data synchronization Offline Mode Disconnected operations ARM Support Raspberry Pi, Jetson devices"},{"location":"roadmap/#advanced-automation-q2-2027","title":"\ud83e\udd16 Advanced Automation \u2014 Q2 2027","text":"Feature Description Self-Healing Automated remediation Predictive Scaling AI-driven autoscaling GitOps Native ArgoCD/Flux integration Policy as Code OPA/Kyverno policies"},{"location":"roadmap/#feature-timeline","title":"Feature Timeline","text":"<pre><code>2025 Dec     2026 Jan    Feb    Mar    Apr    May    Jun    Jul    Aug    Sep    Oct    2027 Q1\n  \u2502            \u2502         \u2502      \u2502      \u2502      \u2502      \u2502      \u2502      \u2502      \u2502      \u2502        \u2502\n  \u25bc            \u25bc         \u25bc      \u25bc      \u25bc      \u25bc      \u25bc      \u25bc      \u25bc      \u25bc      \u25bc        \u25bc\nCurrent    Installer  Admin  DBaaS   S3   GPU/AI Billing License  UI   Hybrid Network   Edge\n State        v2      View                                        UX    Cloud\n</code></pre>"},{"location":"roadmap/#success-metrics","title":"Success Metrics","text":"Metric Target Time to First VM &lt; 2 minutes Time to First K8s Cluster &lt; 5 minutes Platform Uptime 99.9% VM Boot Time &lt; 60 seconds API Response Time &lt; 200ms (p95) <p>Document Owner: Kube-DC Product Team Feedback: GitHub Discussions</p>"},{"location":"todo/","title":"Todo List","text":"<ul> <li> Implement default NetworkPolicy creation in the Project controller. The controller should create a 'default-deny-all' NetworkPolicy in the project namespace upon project creation. This requires:</li> <li>Adding a <code>res_network_policy.go</code> file in <code>internal/project</code>.</li> <li>Updating <code>internal/project/project.go</code> to call the new function.</li> <li>Rebuilding and deploying the controller image (<code>make docker-build deploy</code>).</li> <li> <p>Re-enabling the e2e test in <code>tests/e2e/project_test.go</code>.</p> </li> <li> <p> Fix Project Controller Deletion Deadlock</p> </li> <li>Issue: The <code>Project</code> controller gets stuck in a deadlock when deleting a <code>Project</code> that has an empty <code>spec.egressNetworkType</code>. The deletion logic in <code>internal/project/res_vpc.go</code> incorrectly attempts to re-generate the <code>kube-ovn</code> VPC if it's not found, which fails because <code>utils.SelectBestExternalSubnet</code> requires an <code>egressNetworkType</code>.</li> <li>Fix: In <code>internal/project/res_vpc.go</code>, inside the <code>NewProjectVpc</code> function, modify the <code>IsNotFound</code> error handling. Before attempting to regenerate the VPC, add a check to see if the project has a <code>DeletionTimestamp</code>. If it does, the function should return the <code>NotFound</code> error directly, as this is an expected condition during cleanup, and regeneration should not occur.</li> </ul>"},{"location":"tutorial-kubeconfig/","title":"Obtaining and Using Kubeconfig in Your Local Console","text":"<p>This guide explains how to obtain and configure a kubeconfig file for the kube-dc platform to use in your local development environment.</p>"},{"location":"tutorial-kubeconfig/#overview","title":"Overview","text":"<p>The kubeconfig file is essential for authenticating with the Kubernetes API server. In kube-dc, authentication is handled through Keycloak, which provides secure token-based access.</p> <p>This tutorial covers: - Setting up the authentication script - Generating a kubeconfig file - Using kubeconfig with kubectl - Troubleshooting common issues</p>"},{"location":"tutorial-kubeconfig/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Access to a kube-dc organization and project</li> <li>Your Keycloak username and password</li> <li><code>kubectl</code> installed on your local machine</li> <li><code>curl</code> and <code>jq</code> utilities installed (required for token operations)</li> </ul>"},{"location":"tutorial-kubeconfig/#using-the-authentication-helper-script","title":"Using the Authentication Helper Script","text":"<p>kube-dc provides a helper script that simplifies the kubeconfig generation process.</p>"},{"location":"tutorial-kubeconfig/#step-1-download-and-run-the-authentication-script","title":"Step 1: Download and Run the Authentication Script","text":"<p>You can download the authentication script directly from the public repository:</p> <pre><code># Create a directory for the script\nmkdir -p ~/.kube-dc/bin\n\n# Download the script\ncurl -o ~/.kube-dc/bin/kdc_get_kubeconfig.sh https://raw.githubusercontent.com/kube-dc/kube-dc-public/main/hack/auth/kdc_get_kubeconfig.sh\n\n# Make it executable\nchmod +x ~/.kube-dc/bin/kdc_get_kubeconfig.sh\n\n# Run the authentication script with your organization and project name\n~/.kube-dc/bin/kdc_get_kubeconfig.sh your-org/your-project\n</code></pre> <p>Alternatively, if you have the entire repository cloned:</p> <pre><code># If you have the repository already cloned\ncd kube-dc\n./hack/auth/kdc_get_kubeconfig.sh your-org/your-project\n</code></pre> <p>The script will prompt you for the following information: - Keycloak endpoint URL (e.g., <code>https://login.dev.kube-dc.com</code>) - Organization name (your Keycloak realm) - Kubernetes API server URL (e.g., <code>https://kube-api.dev.kube-dc.com:6443</code>) - Cluster name (usually <code>kube-dc</code>) - User name (your Keycloak username) - Context name (usually <code>kube-dc</code>) - CA certificate (you can provide this as a file, paste it directly, or skip for insecure mode)</p>"},{"location":"tutorial-kubeconfig/#step-2-activate-the-generated-configuration","title":"Step 2: Activate the Generated Configuration","text":"<p>After the script completes, activate the configuration:</p> <pre><code>source ~/.kube-dc/your-org-your-project/activate.sh\n</code></pre> <p>This will:</p> <ol> <li>Set the <code>KUBECONFIG</code> environment variable to point to your new configuration</li> <li>Source the environment variables from the <code>.env</code> file</li> <li>Add the <code>kn</code> alias for namespace switching</li> <li>Display instructions for using kubectl</li> </ol> <p>You can now use <code>kubectl</code> commands as usual:</p> <pre><code>kubectl get pods\n</code></pre> <p>On first use, you'll be prompted to enter your Keycloak username and password. The script will obtain tokens and cache them for subsequent commands.</p>"},{"location":"tutorial-kubeconfig/#step-3-test-your-connection","title":"Step 3: Test Your Connection","text":"<p>Test that your kubeconfig works correctly:</p> <pre><code>kubectl get pods\n</code></pre> <p>On first use, you'll be prompted to enter your Keycloak username and password. The script will obtain tokens and cache them for subsequent commands.</p>"},{"location":"tutorial-kubeconfig/#using-the-namespace-switcher","title":"Using the Namespace Switcher","text":"<p>The <code>kn</code> tool is installed automatically during setup and is configured as an alias when you activate the environment. It allows you to easily view and switch between namespaces that your token has permissions to access.</p>"},{"location":"tutorial-kubeconfig/#features","title":"Features","text":"<ul> <li>Intelligent Operation: When used with a kube-dc context, it reads namespace permissions directly from your JWT token</li> <li>Interactive Selection: Run <code>kn</code> without arguments to see a list of available namespaces</li> <li>Direct Selection: Specify a namespace with <code>kn my-namespace</code></li> <li>Fallback Mode: If not in a kube-dc context, falls back to <code>kubens</code> or basic kubectl namespace commands</li> </ul>"},{"location":"tutorial-kubeconfig/#examples","title":"Examples","text":"<pre><code># List available namespaces and select interactively\nkn\n\n# Switch directly to a specific namespace\nkn shalb-demo\n</code></pre>"},{"location":"tutorial-kubeconfig/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorial-kubeconfig/#authentication-issues","title":"Authentication Issues","text":"<p>If you're experiencing authentication problems:</p> <ol> <li> <p>Token expiration: The refresh token may have expired. Delete the <code>.refresh_token</code> file in your kubeconfig directory and try again:    <pre><code>rm ~/.kube-dc/*-*/scripts/.refresh_token\n</code></pre></p> </li> <li> <p>Invalid credentials: Ensure you're using the correct username and password for your Keycloak account.</p> </li> <li> <p>Connection issues: Verify your network can reach the Keycloak and API servers.</p> </li> </ol>"},{"location":"tutorial-kubeconfig/#permission-issues","title":"Permission Issues","text":"<p>If you can authenticate but receive permission errors:</p> <ol> <li> <p>Namespace access: Ensure you're using the correct namespace in your context. Your namespace should be in the format <code>organization-project</code>.</p> </li> <li> <p>Role assignment: Contact your organization administrator to verify you have the appropriate roles assigned in Keycloak.</p> </li> <li> <p>Resource-specific permissions: Check that your role has permissions for the specific resources you're trying to access.</p> </li> </ol>"},{"location":"tutorial-kubeconfig/#security-considerations","title":"Security Considerations","text":"<ul> <li>Keep your kubeconfig file secure (600 permissions)</li> <li>Never share your refresh or access tokens</li> <li>Be cautious when using <code>insecure-skip-tls-verify: true</code> in production environments</li> <li>If your credentials may be compromised, contact your administrator to revoke your tokens</li> </ul>"},{"location":"tutorial-kubeconfig/#next-steps","title":"Next Steps","text":"<ul> <li>User and Group Management: Learn about role-based access control</li> <li>Tutorial: Virtual Machines: Deploy your first VM</li> <li>Examples: Explore example manifests for various resources</li> </ul>"},{"location":"tutorial-networking-external/","title":"Additional External Network Configuration","text":"<p>This guide explains how to add additional external networks to Kube-DC alongside the default cloud network.</p>"},{"location":"tutorial-networking-external/#overview","title":"Overview","text":"<p>The configuration demonstrates how to add a second external network (public) to an existing Kube-DC setup that already has a cloud external network, using multiple VLANs on a single physical interface per node.</p>"},{"location":"tutorial-networking-external/#network-types-explained-by-example","title":"Network Types Explained by Example","text":""},{"location":"tutorial-networking-external/#cloud-network-egressnetworktype-cloud","title":"Cloud Network (<code>egressNetworkType: cloud</code>)","text":"<ul> <li>Purpose: Default external network for most workloads</li> <li>Subnet: <code>ext-cloud</code> (100.65.0.0/16) on VLAN 4013</li> <li>Use Cases: </li> <li>General internet access for applications</li> <li>Standard egress traffic from project workloads</li> <li>Cost-effective external connectivity</li> <li>IP Pool: Large address space (65,000+ IPs available)</li> </ul>"},{"location":"tutorial-networking-external/#public-network-egressnetworktype-public","title":"Public Network (<code>egressNetworkType: public</code>)","text":"<ul> <li>Purpose: Premium external network for specialized workloads</li> <li>Subnet: <code>ext-public</code> (168.119.17.48/28) on VLAN 4011</li> <li> <p>Use Cases:</p> </li> <li> <p>Production services requiring dedicated public IPs</p> </li> <li>Load balancers and ingress controllers</li> <li>Services needing specific public IP ranges or routing</li> <li>IP Pool: Limited address space with real ipv4 addresses (16 IPs total)</li> </ul>"},{"location":"tutorial-networking-external/#architecture","title":"Architecture","text":"<pre><code>Physical Interface (enp0s31f6)\n\u251c\u2500\u2500 VLAN 4013 (Cloud Network) - 100.65.0.0/16 (ext-cloud)\n\u2514\u2500\u2500 VLAN 4011 (Public Network) - 168.119.17.48/28 (ext-public)\n</code></pre>"},{"location":"tutorial-networking-external/#example-cluster-usage","title":"Example Cluster Usage","text":"<ul> <li>shalb-demo project: Uses <code>egressNetworkType: cloud</code> \u2192 EIP: 100.65.0.102 (development/testing)</li> <li>shalb-dev project: Uses <code>egressNetworkType: public</code> \u2192 EIP: 168.119.17.51 (development with public access)</li> <li>shalb-envoy project: Uses <code>egressNetworkType: public</code> \u2192 EIPs: 168.119.17.52, 168.119.17.54 (production load balancer)</li> </ul>"},{"location":"tutorial-networking-external/#choosing-the-right-network","title":"Choosing the Right Network","text":"<p>Use Cloud Network when: - Need basic internet connectivity - Don't require specific public IP ranges</p> <p>Use Public Network when: - Need dedicated public IP addresses - Have specific routing or compliance requirements - Running load balancers or ingress controllers</p>"},{"location":"tutorial-networking-external/#ovsovn-modifications-applied","title":"OVS/OVN Modifications Applied","text":""},{"location":"tutorial-networking-external/#1-ovs-bridge-configuration","title":"1. OVS Bridge Configuration","text":"<p>The system automatically creates the necessary OVS infrastructure:</p> <p>Bridge: <code>br-ext-cloud</code> - Physical interface <code>enp0s31f6</code> attached with VLAN trunking - Trunk VLANs: <code>[0, 4011, 4013]</code> - Patch ports for both external networks:   - <code>patch-localnet.ext-cloud-to-br-int</code> \u2194 <code>patch-br-int-to-localnet.ext-cloud</code>   - <code>patch-localnet.ext-public-to-br-int</code> \u2194 <code>patch-br-int-to-localnet.ext-public</code></p>"},{"location":"tutorial-networking-external/#2-ovn-logical-switches","title":"2. OVN Logical Switches","text":"<p>Two logical switches are created automatically: - <code>ext-cloud</code> (for VLAN 4013) - <code>ext-public</code> (for VLAN 4011)</p>"},{"location":"tutorial-networking-external/#3-providernetwork-status","title":"3. ProviderNetwork Status","text":"<p>The existing ProviderNetwork <code>ext-cloud</code> is updated to include both VLANs: <pre><code>status:\n  vlans: [\"vlan4013\", \"vlan4011\"]\n  ready: true\n  readyNodes:\n  - kube-dc-master-1\n  - kube-dc-worker-1\n</code></pre></p>"},{"location":"tutorial-networking-external/#configuration-steps","title":"Configuration Steps","text":""},{"location":"tutorial-networking-external/#1-apply-vlan-configuration","title":"1. Apply VLAN Configuration","text":"<pre><code>kubectl apply -f examples/networking/additional-external-network.yaml\n</code></pre>"},{"location":"tutorial-networking-external/#2-verify-configuration","title":"2. Verify Configuration","text":"<pre><code># Check ProviderNetwork VLANs\nkubectl get provider-network ext-cloud -o jsonpath='{.status.vlans}'\n# Expected output: [\"vlan4013\",\"vlan4011\"]\n\n# Check external subnets\nkubectl get subnets ext-cloud ext-public\n# Expected: ext-cloud (100.65.0.0/16) and ext-public (168.119.17.48/28)\n\n# Check EIP assignments\nkubectl get eips -A\n# Shows which projects are using which external networks\n\n# Check OVS bridge configuration\nkubectl exec -n kube-system [ovs-pod] -- ovs-vsctl show | grep -A 10 \"br-ext-cloud\"\n\n# Check OVN logical switches\nkubectl exec -n kube-system [ovn-central-pod] -- ovn-nbctl ls-list | grep ext\n</code></pre>"},{"location":"tutorial-networking-external/#3-test-with-project","title":"3. Test with Project","text":"<p>Create projects to test both network types:</p> <p>Project using Cloud Network: <pre><code>apiVersion: kube-dc.com/v1\nkind: Project\nmetadata:\n  name: test-project-cloud\n  namespace: test-org\nspec:\n  cidrBlock: 10.200.0.0/24\n  egressNetworkType: cloud  # Uses ext-cloud subnet (100.65.0.0/16)\n</code></pre></p> <p>Project using Public Network: <pre><code>apiVersion: kube-dc.com/v1\nkind: Project\nmetadata:\n  name: test-project-public\n  namespace: test-org\nspec:\n  cidrBlock: 10.201.0.0/24\n  egressNetworkType: public  # Uses ext-public subnet (168.119.17.48/28)\n</code></pre></p>"},{"location":"tutorial-networking-external/#key-points","title":"Key Points","text":"<ol> <li>Single ProviderNetwork: Use one ProviderNetwork per physical interface with multiple VLANs attached</li> <li>Automatic Configuration: OVS bridges, patch ports, and OVN logical switches are created automatically</li> <li>VLAN Trunking: The physical interface supports multiple VLANs simultaneously</li> <li>No Manual OVS Changes: All OVS/OVN modifications are handled by Kube-DC controllers</li> </ol>"},{"location":"tutorial-networking-external/#prerequisites","title":"Prerequisites","text":"<ul> <li>Physical network infrastructure supporting VLAN trunking</li> <li>vSwitch configured with appropriate VLAN IDs</li> </ul>"},{"location":"tutorial-networking-external/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorial-networking-external/#check-vlan-interface-on-nodes","title":"Check VLAN Interface on Nodes","text":"<pre><code># On cluster nodes\nip link show enp0s31f6.4011\nip addr show enp0s31f6.4011\n</code></pre>"},{"location":"tutorial-networking-external/#check-ovn-resources","title":"Check OVN Resources","text":"<pre><code># Check OVN-EIP resources\nkubectl get ovn-eip | grep ext-public\n\n# Check subnet status\nkubectl get subnet ext-public -o yaml\n</code></pre>"},{"location":"tutorial-networking-external/#test-connectivity","title":"Test Connectivity","text":"<pre><code># Test from pod\nkubectl exec -n [namespace] [pod] -- wget -qO- http://httpbin.org/ip\n</code></pre>"},{"location":"tutorial-service-exposure/","title":"Service Exposure Guide","text":"<p>This guide explains how to expose services in Kube-DC projects. The method you use depends on your project's network type and your requirements.</p>"},{"location":"tutorial-service-exposure/#quick-reference","title":"Quick Reference","text":"Network Type Default EIP Source Best For Recommended Method Cloud <code>ext-cloud</code> subnet Web apps, APIs Gateway Routes (<code>expose-route</code>) Public <code>ext-public</code> subnet VMs, custom protocols EIP + LoadBalancer <p>Note: Both network types support EIPs and LoadBalancers. The difference is where EIPs are allocated from.</p>"},{"location":"tutorial-service-exposure/#understanding-project-network-types","title":"Understanding Project Network Types","text":"<p>When creating a project, you choose an <code>egressNetworkType</code>:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: Project\nmetadata:\n  name: my-project\n  namespace: my-org\nspec:\n  egressNetworkType: cloud  # or \"public\"\n</code></pre>"},{"location":"tutorial-service-exposure/#cloud-network-egressnetworktype-cloud","title":"Cloud Network (<code>egressNetworkType: cloud</code>)","text":"<ul> <li>Default EIPs allocated from <code>ext-cloud</code> subnet (shared/NAT IPs)</li> <li>Outbound traffic goes through a shared NAT gateway</li> <li>Can create public EIPs by specifying <code>externalNetworkType: public</code></li> <li>Gateway Routes provide easy HTTPS exposure with auto-certificates</li> <li>Supports VMs, pods, and all workload types</li> <li>Best for: Web applications, APIs, microservices, cost-optimized workloads</li> <li>Cost: Lower (shared infrastructure, cloud IPs often included)</li> </ul>"},{"location":"tutorial-service-exposure/#public-network-egressnetworktype-public","title":"Public Network (<code>egressNetworkType: public</code>)","text":"<ul> <li>Default EIPs allocated from <code>ext-public</code> subnet (dedicated public IPs)</li> <li>Direct internet connectivity without NAT</li> <li>Each EIP is a dedicated public IP address</li> <li>Supports any TCP/UDP protocol</li> <li>Supports VMs, pods, and all workload types</li> <li>Best for: Game servers, custom protocols, direct IP requirements</li> <li>Cost: Higher (dedicated public IPs)</li> </ul>"},{"location":"tutorial-service-exposure/#feature-comparison","title":"Feature Comparison","text":"Feature Cloud Project Public Project Default EIP source <code>ext-cloud</code> <code>ext-public</code> Can get public EIPs Would be supported (specify <code>externalNetworkType: public</code>) \u2705 Yes (default) Can use Gateway Routes \u2705 Yes \u2705 Yes Can use EIP + LB \u2705 Yes \u2705 Yes Can run VMs \u2705 Yes \u2705 Yes Can run Pods \u2705 Yes \u2705 Yes"},{"location":"tutorial-service-exposure/#part-1-cloud-network-projects","title":"Part 1: Cloud Network Projects","text":"<p>For projects with <code>egressNetworkType: cloud</code>, use Gateway Routes to expose services.</p>"},{"location":"tutorial-service-exposure/#all-service-annotations-reference","title":"All Service Annotations Reference","text":""},{"location":"tutorial-service-exposure/#gateway-route-annotations","title":"Gateway Route Annotations","text":"Annotation Description Example Values <code>expose-route</code> Enable Gateway route <code>http</code>, <code>https</code>, <code>tls-passthrough</code> <code>route-hostname</code> Custom hostname (optional) <code>api.example.com</code> <code>route-port</code> Target port (optional) <code>8080</code>, <code>50051</code> <code>tls-issuer</code> cert-manager Issuer name <code>letsencrypt</code> (default) <code>tls-secret</code> User-provided TLS secret <code>my-tls-secret</code>"},{"location":"tutorial-service-exposure/#eiploadbalancer-annotations","title":"EIP/LoadBalancer Annotations","text":"Annotation Description Example Values <code>bind-on-default-gw-eip</code> Use project's default EIP <code>\"true\"</code> <code>bind-on-eip</code> Use a specific EIP by name <code>my-eip</code> <code>autodelete</code> Auto-delete EIP when service deleted <code>\"true\"</code> <code>create-gateway-backend</code> Create Envoy Gateway backend <code>\"true\"</code> <p>Note: Prefix is <code>service.nlb.kube-dc.com/</code></p>"},{"location":"tutorial-service-exposure/#network-type-annotation","title":"Network Type Annotation","text":"Annotation Description Example Values <code>network.kube-dc.com/external-network-type</code> EIP type for auto-created EIP <code>cloud</code>, <code>public</code> <p>Tip: Use this on a LoadBalancer service to get a public EIP in a cloud project: <pre><code>annotations:\n  network.kube-dc.com/external-network-type: \"public\"\n</code></pre></p>"},{"location":"tutorial-service-exposure/#status-annotations-read-only","title":"Status Annotations (Read-Only)","text":"Annotation Description <code>route-hostname-status</code> Assigned hostname (set by controller) <p>Note: All annotations use prefix <code>service.nlb.kube-dc.com/</code></p>"},{"location":"tutorial-service-exposure/#gateway-route-annotations-details","title":"Gateway Route Annotations (Details)","text":"<p>Add these annotations to your <code>LoadBalancer</code> Service:</p>"},{"location":"tutorial-service-exposure/#route-type-comparison","title":"Route Type Comparison","text":"Route Type Port TLS App Serves Use Case <code>http</code> 80 None HTTP Plain HTTP traffic <code>https</code> 443 Gateway terminates HTTP \u2b50 Recommended - Auto TLS certs <code>tls-passthrough</code> 443 App terminates HTTPS End-to-end encryption"},{"location":"tutorial-service-exposure/#example-https-web-application-recommended","title":"Example: HTTPS Web Application (Recommended)","text":"<p>The simplest way to expose a web app with automatic TLS:</p>"},{"location":"tutorial-service-exposure/#step-1-create-the-issuer-once-per-namespace","title":"Step 1: Create the Issuer (once per namespace)","text":"<pre><code>apiVersion: cert-manager.io/v1\nkind: Issuer\nmetadata:\n  name: letsencrypt\n  namespace: my-project\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: your-email@example.com  # Replace with valid email\n    privateKeySecretRef:\n      name: letsencrypt-account-key\n    solvers:\n    - http01:\n        gatewayHTTPRoute:\n          parentRefs:\n          - group: gateway.networking.k8s.io\n            kind: Gateway\n            name: eg\n            namespace: envoy-gateway-system\n</code></pre>"},{"location":"tutorial-service-exposure/#step-2-deploy-your-application","title":"Step 2: Deploy your application","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  namespace: my-project\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: app\n        image: nginx:alpine\n        ports:\n        - containerPort: 80\n</code></pre>"},{"location":"tutorial-service-exposure/#step-3-create-loadbalancer-service-with-https-route","title":"Step 3: Create LoadBalancer Service with HTTPS route","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\n  namespace: my-project\n  annotations:\n    # Expose via HTTPS with auto-provisioned certificate\n    service.nlb.kube-dc.com/expose-route: \"https\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: my-app\n  ports:\n  - port: 80\n    targetPort: 80\n</code></pre>"},{"location":"tutorial-service-exposure/#step-4-verify-and-access","title":"Step 4: Verify and access","text":"<pre><code># Check assigned hostname\nkubectl get svc my-app -n my-project -o jsonpath='{.metadata.annotations.service\\.nlb\\.kube-dc\\.com/route-hostname-status}'\n# Output: my-app-my-project.stage.kube-dc.com\n\n# Check certificate status\nkubectl get certificate -n my-project\n\n# Test access\ncurl https://my-app-my-project.stage.kube-dc.com\n</code></pre>"},{"location":"tutorial-service-exposure/#example-plain-http","title":"Example: Plain HTTP","text":"<p>For non-TLS HTTP traffic:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\n  namespace: my-project\n  annotations:\n    service.nlb.kube-dc.com/expose-route: \"http\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: my-app\n  ports:\n  - port: 80\n    targetPort: 80\n</code></pre> <p>Access via: <code>http://my-app-my-project.stage.kube-dc.com</code></p>"},{"location":"tutorial-service-exposure/#example-tls-passthrough-kubernetes-api","title":"Example: TLS Passthrough (Kubernetes API)","text":"<p>For services that handle their own TLS (like Kubernetes control planes):</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: cluster-api\n  namespace: my-project\n  annotations:\n    service.nlb.kube-dc.com/expose-route: \"tls-passthrough\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: kube-apiserver\n  ports:\n  - port: 6443\n    targetPort: 6443\n</code></pre> <p>Access via: <code>https://cluster-api-my-project.stage.kube-dc.com:6443</code></p>"},{"location":"tutorial-service-exposure/#example-custom-hostname","title":"Example: Custom Hostname","text":"<p>Override the auto-generated hostname:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\n  namespace: my-project\n  annotations:\n    service.nlb.kube-dc.com/expose-route: \"https\"\n    service.nlb.kube-dc.com/route-hostname: \"api.mycompany.com\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: my-app\n  ports:\n  - port: 80\n    targetPort: 80\n</code></pre> <p>Note: You must configure DNS to point <code>api.mycompany.com</code> to the Gateway IP.</p>"},{"location":"tutorial-service-exposure/#example-user-provided-certificate","title":"Example: User-Provided Certificate","text":"<p>Use your own TLS certificate instead of auto-provisioning:</p> <pre><code># First, create your TLS secret\nkubectl create secret tls my-tls-secret \\\n  --cert=path/to/tls.crt \\\n  --key=path/to/tls.key \\\n  -n my-project\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\n  namespace: my-project\n  annotations:\n    service.nlb.kube-dc.com/expose-route: \"https\"\n    service.nlb.kube-dc.com/tls-secret: \"my-tls-secret\"\n    service.nlb.kube-dc.com/route-hostname: \"secure.mycompany.com\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: my-app\n  ports:\n  - port: 80\n    targetPort: 80\n</code></pre>"},{"location":"tutorial-service-exposure/#example-grpc-service","title":"Example: gRPC Service","text":"<p>gRPC services work with HTTPS routes (HTTP/2):</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: grpc-api\n  namespace: my-project\n  annotations:\n    service.nlb.kube-dc.com/expose-route: \"https\"\n    service.nlb.kube-dc.com/route-port: \"50051\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: grpc-server\n  ports:\n  - name: grpc\n    port: 50051\n    targetPort: 50051\n</code></pre>"},{"location":"tutorial-service-exposure/#part-2-eip-based-exposure-both-project-types","title":"Part 2: EIP-Based Exposure (Both Project Types)","text":"<p>Both cloud and public projects can use EIPs and LoadBalancer services.</p>"},{"location":"tutorial-service-exposure/#default-eip-allocation","title":"Default EIP Allocation","text":"Project Type Default EIP Source Can Request Cloud <code>ext-cloud</code> subnet Both <code>cloud</code> and <code>public</code> EIPs Public <code>ext-public</code> subnet Both <code>cloud</code> and <code>public</code> EIPs <p>When to use EIPs vs Gateway Routes: - Use Gateway Routes for HTTP/HTTPS/gRPC (simpler, auto-TLS) - Use EIPs for TCP/UDP protocols, VMs, or when you need a dedicated IP</p>"},{"location":"tutorial-service-exposure/#understanding-eips","title":"Understanding EIPs","text":"<p>External IPs (EIPs) provide IP addresses for your project from the configured external network.</p>"},{"location":"tutorial-service-exposure/#default-gateway-eip","title":"Default Gateway EIP","text":"<p>Every project automatically gets a default EIP (<code>default-gw</code>) that acts as: - NAT gateway for outbound traffic - Default endpoint for LoadBalancer services</p>"},{"location":"tutorial-service-exposure/#creating-additional-eips","title":"Creating Additional EIPs","text":"<p>For services that need dedicated IPs:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: EIp\nmetadata:\n  name: web-server-eip\n  namespace: my-project\nspec:\n  externalNetworkType: public  # or \"cloud\"\n</code></pre> <p>EIP Types:</p> <code>externalNetworkType</code> Description Use Case <code>cloud</code> Shared/NAT pool IP Cost-effective, outbound NAT <code>public</code> Dedicated public IP Direct access, static IP, VMs <p>Tip: Cloud projects can request public EIPs for services that need dedicated IPs (e.g., game servers, VMs with direct access).</p>"},{"location":"tutorial-service-exposure/#loadbalancer-service-annotations","title":"LoadBalancer Service Annotations","text":"Annotation Description <code>service.nlb.kube-dc.com/bind-on-default-gw-eip: \"true\"</code> Use project's default EIP <code>service.nlb.kube-dc.com/bind-on-eip: \"eip-name\"</code> Use a specific EIP"},{"location":"tutorial-service-exposure/#example-web-server-on-default-eip","title":"Example: Web Server on Default EIP","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-lb\n  namespace: my-project\n  annotations:\n    service.nlb.kube-dc.com/bind-on-default-gw-eip: \"true\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: nginx\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n  - name: https\n    port: 443\n    targetPort: 443\n</code></pre>"},{"location":"tutorial-service-exposure/#example-service-on-dedicated-eip","title":"Example: Service on Dedicated EIP","text":"<pre><code># Step 1: Create dedicated EIP\napiVersion: kube-dc.com/v1\nkind: EIp\nmetadata:\n  name: api-eip\n  namespace: my-project\nspec:\n  externalNetworkType: public\n---\n# Step 2: Bind service to the EIP\napiVersion: v1\nkind: Service\nmetadata:\n  name: api-lb\n  namespace: my-project\n  annotations:\n    service.nlb.kube-dc.com/bind-on-eip: \"api-eip\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: api-server\n  ports:\n  - port: 443\n    targetPort: 443\n</code></pre>"},{"location":"tutorial-service-exposure/#example-vm-ssh-access","title":"Example: VM SSH Access","text":"<p>Expose SSH access to a virtual machine:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: vm-ssh\n  namespace: my-project\n  annotations:\n    service.nlb.kube-dc.com/bind-on-default-gw-eip: \"true\"\nspec:\n  type: LoadBalancer\n  selector:\n    vm.kubevirt.io/name: my-vm  # Target VM name\n  ports:\n  - name: ssh\n    port: 2222      # External port\n    targetPort: 22  # Internal SSH port\n</code></pre>"},{"location":"tutorial-service-exposure/#floating-ips-fips","title":"Floating IPs (FIPs)","text":"<p>Floating IPs map an internal IP directly to an EIP, providing 1:1 NAT.</p>"},{"location":"tutorial-service-exposure/#when-to-use-fips","title":"When to Use FIPs","text":"<ul> <li>Direct IP mapping for VMs</li> <li>Services that need to see their public IP</li> <li>Protocols that don't work behind NAT</li> </ul>"},{"location":"tutorial-service-exposure/#creating-a-fip","title":"Creating a FIP","text":"<pre><code>apiVersion: kube-dc.com/v1\nkind: FIp\nmetadata:\n  name: vm-fip\n  namespace: my-project\nspec:\n  ipAddress: 10.0.10.5    # Internal IP of VM or pod\n  eip: my-eip             # Name of existing EIP\n</code></pre>"},{"location":"tutorial-service-exposure/#part-3-choosing-the-right-approach","title":"Part 3: Choosing the Right Approach","text":""},{"location":"tutorial-service-exposure/#decision-tree","title":"Decision Tree","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  What are you exposing?                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u25bc               \u25bc               \u25bc\n      Web App/API      VM Direct       Custom Protocol\n            \u2502           Access              \u2502\n            \u2502               \u2502               \u2502\n            \u25bc               \u25bc               \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502Cloud Project\u2502   \u2502  Public   \u2502   \u2502    Public     \u2502\n   \u2502expose-route \u2502   \u2502  Project  \u2502   \u2502    Project    \u2502\n   \u2502   : https   \u2502   \u2502  EIP+FIP  \u2502   \u2502   EIP + LB    \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"tutorial-service-exposure/#comparison-table","title":"Comparison Table","text":"Feature Gateway Routes (Cloud) EIP + LoadBalancer (Public) IP Address Shared Gateway IP Dedicated per EIP Protocols HTTP, HTTPS, gRPC Any TCP/UDP TLS Termination Gateway (auto-cert) Application Cost Lower Higher Setup Simple annotation EIP + Service config DNS Auto hostname Manual Best For Web apps, APIs VMs, game servers"},{"location":"tutorial-service-exposure/#part-4-advanced-topics","title":"Part 4: Advanced Topics","text":""},{"location":"tutorial-service-exposure/#envoy-gateway-backend","title":"Envoy Gateway Backend","text":"<p>Use the <code>create-gateway-backend</code> annotation to register a service as an Envoy Gateway Backend for advanced routing scenarios:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-backend\n  namespace: my-project\n  annotations:\n    service.nlb.kube-dc.com/create-gateway-backend: \"true\"\nspec:\n  type: ClusterIP\n  selector:\n    app: my-app\n  ports:\n  - port: 8080\n    targetPort: 8080\n</code></pre> <p>This creates an Envoy Gateway <code>Backend</code> resource, enabling: - Cross-namespace routing from Gateway - Custom backend policies - Advanced load balancing configurations</p>"},{"location":"tutorial-service-exposure/#automatic-external-endpoints","title":"Automatic External Endpoints","text":"<p>For every LoadBalancer service, Kube-DC creates external endpoints for cross-VPC DNS access:</p> <ul> <li>External Service: <code>&lt;service-name&gt;-ext</code></li> <li>DNS: <code>&lt;service&gt;-ext.&lt;namespace&gt;.svc.cluster.local</code></li> </ul> <pre><code># Verify external endpoints\nkubectl get svc,endpoints -n my-project my-app-ext\n</code></pre>"},{"location":"tutorial-service-exposure/#namespace-scoped-ingress-controller","title":"Namespace-Scoped Ingress Controller","text":"<p>For advanced HTTP routing beyond Gateway capabilities, deploy a dedicated ingress-nginx:</p> <pre><code># ingress-values.yaml\ncontroller:\n  ingressClassResource:\n    enabled: false\n  scope:\n    enabled: true\n    namespace: my-project\n  admissionWebhooks:\n    enabled: false\n  service:\n    annotations:\n      service.nlb.kube-dc.com/bind-on-default-gw-eip: \"true\"\nrbac:\n  create: true\n  scope: true\ndefaultBackend:\n  enabled: false\n</code></pre> <pre><code>helm install ingress ingress-nginx/ingress-nginx \\\n  --namespace my-project \\\n  --values ingress-values.yaml\n</code></pre>"},{"location":"tutorial-service-exposure/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorial-service-exposure/#gateway-routes-cloud-projects","title":"Gateway Routes (Cloud Projects)","text":"<pre><code># Check route hostname was assigned\nkubectl get svc my-app -o yaml | grep route-hostname-status\n\n# Check certificate status\nkubectl get certificate -n my-project\nkubectl describe certificate my-app-tls -n my-project\n\n# Check HTTPRoute created\nkubectl get httproute -n my-project\n\n# Check Gateway listener\nkubectl get gateway eg -n envoy-gateway-system -o yaml | grep -A5 \"https-my-app\"\n\n# Controller logs\nkubectl logs -n kube-dc deployment/kube-dc-manager | grep my-app\n</code></pre>"},{"location":"tutorial-service-exposure/#eiploadbalancer-public-projects","title":"EIP/LoadBalancer (Public Projects)","text":"<pre><code># Check EIP status\nkubectl get eip -n my-project\nkubectl describe eip my-eip -n my-project\n\n# Check LoadBalancer external IP\nkubectl get svc -n my-project\n\n# Check service events\nkubectl describe svc my-lb -n my-project\n</code></pre>"},{"location":"tutorial-service-exposure/#common-issues","title":"Common Issues","text":"Issue Cause Solution No hostname assigned Missing <code>expose-route</code> annotation Add annotation Certificate not ready Issuer not created Create Issuer first 503 error Backend not ready Check pod status EIP pending No available IPs Check subnet capacity Connection timeout DNS not configured Point DNS to Gateway/EIP"},{"location":"tutorial-service-exposure/#summary","title":"Summary","text":"Project Type Service Type Annotation Result Cloud LoadBalancer <code>expose-route: https</code> Auto HTTPS with cert Cloud LoadBalancer <code>expose-route: http</code> HTTP only Cloud LoadBalancer <code>expose-route: tls-passthrough</code> App handles TLS Public LoadBalancer <code>bind-on-default-gw-eip: \"true\"</code> Use default EIP Public LoadBalancer <code>bind-on-eip: \"name\"</code> Use specific EIP Public FIp N/A 1:1 NAT mapping"},{"location":"tutorial-sso-google-auth/","title":"Google SSO Authentication Setup","text":"<p>This guide explains how to enable Google OAuth authentication for Kube-DC using a central SSO Keycloak realm.</p>"},{"location":"tutorial-sso-google-auth/#overview","title":"Overview","text":"<p>Kube-DC supports Google OAuth authentication via a central <code>sso</code> Keycloak realm that brokers authentication to organization-specific realms. This allows:</p> <ul> <li>Single Google OAuth configuration - One Google client ID/secret for all organizations</li> <li>Per-organization isolation - Tokens issued by org realms with org-specific permissions</li> <li>Multi-org support - Users can belong to multiple organizations</li> <li>Self-service registration - Users can sign up and create organizations</li> <li>Feature flag - Enable/disable per deployment</li> </ul>"},{"location":"tutorial-sso-google-auth/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              Keycloak Server                                \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502                         Realm: sso                                 \u2502     \u2502\n\u2502  \u2502                                                                    \u2502     \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502     \u2502\n\u2502  \u2502  \u2502 Google IdP      \u2502  \u2502 Console Client  \u2502  \u2502 Broker Client    \u2502    \u2502     \u2502\n\u2502  \u2502  \u2502 (auto-link)     \u2502  \u2502 (kube-dc)       \u2502  \u2502 (sso-broker)     \u2502    \u2502     \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502     \u2502\n\u2502  \u2502                                                                    \u2502     \u2502\n\u2502  \u2502  Registration: Passwordless (email verification required)          \u2502     \u2502\n\u2502  \u2502  Groups: /orgs/shalb, /orgs/acme, ...                              \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                              \u2502                                              \u2502\n\u2502                              \u2502 OIDC IdP Brokering                           \u2502\n\u2502                              \u25bc                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502  \u2502  Realm: shalb    \u2502  \u2502  Realm: acme     \u2502  \u2502  Realm: foo      \u2502           \u2502\n\u2502  \u2502  IdP: sso \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u253c\u2500\u2500\u25ba SSO Realm     \u2502           \u2502\n\u2502  \u2502  Users: admin    \u2502  \u2502  Users: admin    \u2502  \u2502  Users: admin    \u2502           \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"tutorial-sso-google-auth/#user-journey","title":"User Journey","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         SELF-SERVICE REGISTRATION                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  1. SIGN UP                    2. VERIFY EMAIL                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502  \u2502 Enter:              \u2502       \u2502 Check inbox         \u2502                      \u2502\n\u2502  \u2502 \u2022 Email             \u2502 \u2500\u2500\u2500\u25ba  \u2502 Click verify link   \u2502                      \u2502\n\u2502  \u2502 \u2022 First/Last Name   \u2502       \u2502                     \u2502                      \u2502\n\u2502  \u2502 (No password yet!)  \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502                                  \u2502\n\u2502                                          \u25bc                                  \u2502\n\u2502  3. CREATE OR JOIN ORG         4. SET PASSWORD                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502  \u2502 Choose:             \u2502       \u2502 Set password        \u2502                      \u2502\n\u2502  \u2502 \u2022 Create new org    \u2502 \u2500\u2500\u2500\u25ba  \u2502 (only when creating \u2502                      \u2502\n\u2502  \u2502 \u2022 Join existing org \u2502       \u2502  organization)      \u2502                      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2502                                          \u2502                                  \u2502\n\u2502                                          \u25bc                                  \u2502\n\u2502                                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502                                \u2502 \u2713 Organization      \u2502                      \u2502\n\u2502                                \u2502   created!          \u2502                      \u2502\n\u2502                                \u2502 \u2713 Auto-redirected   \u2502                      \u2502\n\u2502                                \u2502   to console        \u2502                      \u2502\n\u2502                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           GOOGLE SSO LOGIN                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  User clicks              Google OAuth              Auto-link by email      \u2502\n\u2502  \"Login with Google\"      authentication            (no extra prompts)      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502   Console   \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502   Google    \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502  Keycloak   \u2502          \u2502\n\u2502  \u2502  (org page) \u2502         \u2502   Sign-in   \u2502           \u2502  SSO Realm  \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                                           \u2502                 \u2502\n\u2502                                                           \u25bc                 \u2502\n\u2502                          Broker to org realm       Token issued             \u2502\n\u2502                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502                          \u2502  Org Realm  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502  Console    \u2502          \u2502\n\u2502                          \u2502  (via SSO)  \u2502           \u2502  (logged in)\u2502          \u2502\n\u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"tutorial-sso-google-auth/#prerequisites","title":"Prerequisites","text":"<ol> <li>Google Cloud Console access to create OAuth credentials</li> <li>Keycloak admin access</li> <li>Kube-DC deployment with controller v0.1.34+</li> </ol>"},{"location":"tutorial-sso-google-auth/#setup-steps","title":"Setup Steps","text":""},{"location":"tutorial-sso-google-auth/#step-1-create-google-oauth-credentials","title":"Step 1: Create Google OAuth Credentials","text":""},{"location":"tutorial-sso-google-auth/#11-create-a-google-cloud-project","title":"1.1 Create a Google Cloud Project","text":"<ol> <li>Go to Google Cloud Console</li> <li>Click the project dropdown \u2192 New Project</li> <li>Enter a project name (e.g., <code>kube-dc-sso</code>)</li> <li>Click Create</li> </ol>"},{"location":"tutorial-sso-google-auth/#12-configure-oauth-consent-screen","title":"1.2 Configure OAuth Consent Screen","text":"<ol> <li>Navigate to APIs &amp; Services \u2192 OAuth consent screen</li> <li>Select External user type (or Internal for Google Workspace)</li> <li>Fill in required fields:</li> <li>App name: <code>Kube-DC</code></li> <li>User support email: Your email</li> <li>Developer contact: Your email</li> <li>Click Save and Continue</li> <li>Add scopes: <code>email</code>, <code>profile</code>, <code>openid</code></li> <li>Click Save and Continue through remaining steps</li> </ol>"},{"location":"tutorial-sso-google-auth/#13-create-oauth-20-client-id","title":"1.3 Create OAuth 2.0 Client ID","text":"<ol> <li>Navigate to APIs &amp; Services \u2192 Credentials</li> <li>Click Create Credentials \u2192 OAuth 2.0 Client ID</li> <li>Select Web application</li> <li>Configure:</li> <li>Name: <code>Kube-DC SSO</code></li> <li>Authorized JavaScript origins: <code>https://&lt;your-keycloak-url&gt;</code></li> <li>Authorized redirect URIs: <pre><code>https://&lt;your-keycloak-url&gt;/realms/sso/broker/google/endpoint\n</code></pre></li> <li>Click Create</li> <li>Copy and save the Client ID and Client Secret</li> </ol> <p>\u26a0\ufe0f Important: Keep the Client Secret secure. You'll need both values for the next step.</p>"},{"location":"tutorial-sso-google-auth/#step-2-bootstrap-sso-realm","title":"Step 2: Bootstrap SSO Realm","text":"<p>Run the bootstrap script to create the central SSO realm with Google IdP:</p> <pre><code># Required environment variables\nexport KEYCLOAK_URL=\"https://login.your-domain.com\"\nexport KEYCLOAK_ADMIN_USER=\"admin\"\nexport KEYCLOAK_ADMIN_PASSWORD=\"&lt;your-admin-password&gt;\"\nexport GOOGLE_CLIENT_ID=\"&lt;your-google-client-id&gt;\"\nexport GOOGLE_CLIENT_SECRET=\"&lt;your-google-client-secret&gt;\"\n\n# Optional\nexport CONSOLE_URL=\"https://console.your-domain.com\"  # Defaults to https://console.kube-dc.com\n\n# Run the bootstrap\n./hack/bootstrap-sso-realm.sh\n</code></pre> <p>Output: The script will generate and display <code>SSO_BROKER_SECRET</code>. Save this securely.</p>"},{"location":"tutorial-sso-google-auth/#what-the-bootstrap-script-configures","title":"What the Bootstrap Script Configures","text":"Component Description SSO Realm Central realm for authentication brokering Passwordless Registration Users sign up without password (set during org creation) Email Verification Required before organization setup Auto-link Flow Automatically links Google accounts by email Google IdP Configured with your OAuth credentials Console Client <code>kube-dc</code> client with PKCE for frontend Broker Client <code>sso-broker</code> for org realm federation Organization Groups <code>/orgs</code> group structure for membership"},{"location":"tutorial-sso-google-auth/#step-3-configure-kube-dc","title":"Step 3: Configure Kube-DC","text":""},{"location":"tutorial-sso-google-auth/#option-a-helm-values-recommended-for-new-deployments","title":"Option A: Helm Values (Recommended for new deployments)","text":"<p>Add SSO configuration to your Helm values:</p> <pre><code>manager:\n  keycloakSecret:\n    ssoEnabled: true\n    ssoBrokerSecret: \"&lt;from-bootstrap-output&gt;\"\n    googleClientId: \"&lt;your-google-client-id&gt;\"\n    googleClientSecret: \"&lt;your-google-client-secret&gt;\"\n</code></pre> <p>Then upgrade the Helm release:</p> <pre><code>helm upgrade kube-dc ./charts/kube-dc -n kube-dc -f values.yaml\n</code></pre>"},{"location":"tutorial-sso-google-auth/#option-b-kubectl-patch-existing-deployments","title":"Option B: kubectl patch (Existing deployments)","text":"<p>Add SSO configuration to the <code>master-config</code> secret:</p> <pre><code>export SSO_BROKER_SECRET=\"&lt;from-bootstrap-output&gt;\"\nexport GOOGLE_CLIENT_ID=\"&lt;your-google-client-id&gt;\"\nexport GOOGLE_CLIENT_SECRET=\"&lt;your-google-client-secret&gt;\"\n\nkubectl patch secret master-config -n kube-dc --type='json' -p=\"[\n  {\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/data/ssoEnabled\\\",\\\"value\\\":\\\"$(echo -n true | base64 -w0)\\\"},\n  {\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/data/ssoBrokerSecret\\\",\\\"value\\\":\\\"$(echo -n $SSO_BROKER_SECRET | base64 -w0)\\\"},\n  {\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/data/googleClientId\\\",\\\"value\\\":\\\"$(echo -n $GOOGLE_CLIENT_ID | base64 -w0)\\\"},\n  {\\\"op\\\":\\\"add\\\",\\\"path\\\":\\\"/data/googleClientSecret\\\",\\\"value\\\":\\\"$(echo -n $GOOGLE_CLIENT_SECRET | base64 -w0)\\\"}\n]\"\n</code></pre>"},{"location":"tutorial-sso-google-auth/#step-4-restart-controller","title":"Step 4: Restart Controller","text":"<pre><code>kubectl rollout restart deployment kube-dc-manager -n kube-dc\n</code></pre> <p>The controller will now automatically configure SSO IdP for all new organizations.</p>"},{"location":"tutorial-sso-google-auth/#step-5-add-existing-organizations-to-sso-optional","title":"Step 5: Add Existing Organizations to SSO (Optional)","text":"<p>For organizations created before SSO was enabled, trigger a reconciliation:</p> <pre><code>kubectl annotate organization &lt;org-name&gt; -n &lt;org-name&gt; reconcile=$(date +%s) --overwrite\n</code></pre> <p>Or use the manual script:</p> <pre><code>export ORG_SLUG=\"&lt;organization-name&gt;\"\n./hack/add-org-to-sso.sh\n</code></pre>"},{"location":"tutorial-sso-google-auth/#configuration-reference","title":"Configuration Reference","text":""},{"location":"tutorial-sso-google-auth/#helm-values","title":"Helm Values","text":"<pre><code>manager:\n  keycloakSecret:\n    ssoEnabled: true                    # Enable Google SSO\n    ssoBrokerSecret: \"&lt;secret&gt;\"         # From bootstrap script output\n    googleClientId: \"&lt;client-id&gt;\"       # Google OAuth Client ID\n    googleClientSecret: \"&lt;secret&gt;\"      # Google OAuth Client Secret\n</code></pre> <p>The Helm chart automatically: - Stores SSO credentials in <code>master-config</code> secret - Configures frontend ConfigMap with <code>ssoEnabled</code> flag - Exposes \"Login with Google\" button when enabled</p>"},{"location":"tutorial-sso-google-auth/#master-config-secret-keys","title":"Master Config Secret Keys","text":"Key Type Description <code>ssoEnabled</code> string <code>\"true\"</code> to enable Google SSO <code>ssoBrokerSecret</code> string Secret for SSO broker client (from bootstrap) <code>googleClientId</code> string Google OAuth Client ID <code>googleClientSecret</code> string Google OAuth Client Secret"},{"location":"tutorial-sso-google-auth/#automatic-configuration-per-organization","title":"Automatic Configuration per Organization","text":"<p>When SSO is enabled, the controller automatically configures each organization realm with:</p> <ol> <li>SSO IdP - OIDC identity provider pointing to the <code>sso</code> realm</li> <li>Auto-link flow - Authentication flow that links existing users by email</li> <li>IdP mappers - Maps email, firstName, lastName from Google</li> <li>Org group - Creates <code>/orgs/&lt;org-slug&gt;</code> group in SSO realm</li> </ol>"},{"location":"tutorial-sso-google-auth/#user-experience","title":"User Experience","text":""},{"location":"tutorial-sso-google-auth/#self-service-registration","title":"Self-Service Registration","text":"<p>New users can sign up and create their own organization:</p> <ol> <li>User clicks \"Sign Up\" on the console login page</li> <li>Enters email, first name, and last name (no password required)</li> <li>Receives verification email and clicks the link</li> <li>After verification, chooses to:</li> <li>Create a new organization - Sets password and becomes org admin</li> <li>Join existing organization - Submits join request for admin approval</li> <li>Redirected to the console, fully authenticated</li> </ol> <p>\ud83d\udca1 Why passwordless registration? Users set their password only when creating an organization. This simplifies the signup flow and ensures passwords are only needed for org-level access.</p>"},{"location":"tutorial-sso-google-auth/#login-flow-existing-users","title":"Login Flow (Existing Users)","text":"<ol> <li>User navigates to the console</li> <li>Enters organization name</li> <li>Clicks \"Login with Google\" or uses username/password</li> <li>Authenticates with Google account (single click, no extra screens)</li> <li>Returns to console, authenticated to the organization</li> </ol>"},{"location":"tutorial-sso-google-auth/#organization-membership","title":"Organization Membership","text":"<p>For self-registered users, membership is automatic when they create an organization. For joining existing organizations:</p> <ol> <li>Log in to Keycloak admin console (<code>/admin/sso/console</code>)</li> <li>Navigate to Groups \u2192 orgs \u2192  <li>Add user to the group</li> <p>Or via API: <pre><code># Get user ID\nUSER_ID=$(curl -s -H \"Authorization: Bearer $TOKEN\" \\\n  \"$KEYCLOAK_URL/admin/realms/sso/users?email=user@example.com\" | jq -r '.[0].id')\n\n# Get group ID\nGROUP_ID=$(curl -s -H \"Authorization: Bearer $TOKEN\" \\\n  \"$KEYCLOAK_URL/admin/realms/sso/groups\" | jq -r '.[] | select(.name==\"orgs\") | .subGroups[] | select(.name==\"&lt;org-slug&gt;\") | .id')\n\n# Add user to group\ncurl -X PUT -H \"Authorization: Bearer $TOKEN\" \\\n  \"$KEYCLOAK_URL/admin/realms/sso/users/$USER_ID/groups/$GROUP_ID\"\n</code></pre></p>"},{"location":"tutorial-sso-google-auth/#verification","title":"Verification","text":"<p>After setup, verify the configuration is correct:</p> <pre><code># Get Keycloak credentials\nKC_URL=$(kubectl get secret -n kube-dc master-config -o jsonpath='{.data.url}' | base64 -d)\nKC_USER=$(kubectl get secret -n kube-dc master-config -o jsonpath='{.data.user}' | base64 -d)\nKC_PASS=$(kubectl get secret -n kube-dc master-config -o jsonpath='{.data.password}' | base64 -d)\n\n# Get admin token\nADMIN_TOKEN=$(curl -s -X POST \"$KC_URL/realms/master/protocol/openid-connect/token\" \\\n  -d \"username=$KC_USER\" -d \"password=$KC_PASS\" \\\n  -d \"grant_type=password\" -d \"client_id=admin-cli\" | jq -r '.access_token')\n\n# Check SSO realm configuration\necho \"Registration Flow:\"\ncurl -s -H \"Authorization: Bearer $ADMIN_TOKEN\" \"$KC_URL/admin/realms/sso\" | jq -r '.registrationFlow'\n# Expected: registration-no-password\n\necho \"Auto-link Flow:\"\ncurl -s -H \"Authorization: Bearer $ADMIN_TOKEN\" \"$KC_URL/admin/realms/sso/authentication/flows\" | \\\n  jq -r '.[] | select(.alias==\"auto-link-broker-login\") | .alias'\n# Expected: auto-link-broker-login\n\necho \"Google IdP Broker Flow:\"\ncurl -s -H \"Authorization: Bearer $ADMIN_TOKEN\" \"$KC_URL/admin/realms/sso/identity-provider/instances/google\" | \\\n  jq -r '.firstBrokerLoginFlowAlias'\n# Expected: auto-link-broker-login\n</code></pre>"},{"location":"tutorial-sso-google-auth/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorial-sso-google-auth/#sso-realm-not-found","title":"SSO realm not found","text":"<p>Error: <code>SSO realm 'sso' does not exist. Run bootstrap-sso-realm.sh first</code></p> <p>Solution: Run the bootstrap script to create the SSO realm.</p>"},{"location":"tutorial-sso-google-auth/#google-login-shows-account-already-exists-prompt","title":"Google login shows \"Account already exists\" prompt","text":"<p>Cause: Auto-link flow not configured on Google IdP.</p> <p>Solution: Verify the Google IdP uses <code>auto-link-broker-login</code> as its first broker login flow: <pre><code>curl -s -X PUT -H \"Authorization: Bearer $ADMIN_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"firstBrokerLoginFlowAlias\": \"auto-link-broker-login\"}' \\\n  \"$KC_URL/admin/realms/sso/identity-provider/instances/google\"\n</code></pre></p>"},{"location":"tutorial-sso-google-auth/#google-login-not-working","title":"Google login not working","text":"<ol> <li>Check Google OAuth redirect URI matches exactly:    <pre><code>https://&lt;your-keycloak-url&gt;/realms/sso/broker/google/endpoint\n</code></pre></li> <li>Verify <code>ssoEnabled</code> is <code>\"true\"</code> in master-config secret</li> <li>Check Google IdP has client secret configured</li> <li>Check controller logs: <code>kubectl logs -n kube-dc -l app.kubernetes.io/name=kube-dc-manager</code></li> </ol>"},{"location":"tutorial-sso-google-auth/#user-not-authorized","title":"User not authorized","text":"<p>Error: User can authenticate but cannot access organization</p> <p>Solution: Add user to <code>/orgs/&lt;org-slug&gt;</code> group in SSO realm.</p>"},{"location":"tutorial-sso-google-auth/#registration-email-not-received","title":"Registration email not received","text":"<ol> <li>Verify SMTP is configured in Keycloak SSO realm</li> <li>Check Keycloak logs for email sending errors</li> <li>Verify the email address is correct</li> </ol>"},{"location":"tutorial-sso-google-auth/#disabling-sso","title":"Disabling SSO","text":"<p>To disable Google SSO:</p> <pre><code>kubectl patch secret master-config -n kube-dc --type='json' -p='[\n  {\"op\":\"replace\",\"path\":\"/data/ssoEnabled\",\"value\":\"'$(echo -n false | base64 -w0)'\"}\n]'\n\nkubectl rollout restart deployment kube-dc-manager -n kube-dc\n</code></pre> <p>Users will fall back to direct organization login with username/password.</p>"},{"location":"tutorial-sso-google-auth/#security-considerations","title":"Security Considerations","text":"<ul> <li>Token isolation - SSO realm tokens are only used for authentication; final tokens come from org realms</li> <li>Org membership verification - Users cannot access organizations they're not members of</li> <li>Secrets management - All credentials stored in Kubernetes secrets, never in code</li> <li>TLS required - All Keycloak endpoints must use HTTPS</li> </ul> <p>See also: - Keycloak Identity Brokering Documentation - Google OAuth Setup Guide</p>"},{"location":"tutorial-user-groups/","title":"User and Group Management","text":"<p>This guide explains how to set up and manage users, groups, and roles in Kube-DC using Kubernetes RBAC and Keycloak integration.</p>"},{"location":"tutorial-user-groups/#overview","title":"Overview","text":"<p>Kube-DC implements a multi-tenant access control system that combines:</p> <ul> <li>Kubernetes RBAC: Handles resource-level permissions within namespaces</li> <li>Organization Groups: Manages project-level access across namespaces</li> <li>Keycloak Integration: Provides user authentication and group management</li> </ul>"},{"location":"tutorial-user-groups/#prerequisites","title":"Prerequisites","text":"<p>This guide assumes you're working from an Organization Admin perspective. You'll need:</p> <ul> <li>Access to the Kube-DC cluster with organization admin privileges</li> <li><code>kubectl</code> configured to access your cluster with organization admin privileges</li> <li>Access to the Keycloak organization admin console</li> </ul> <p>Before You Begin</p> <p>During organization and project creation you will get a namespace with organization name <code>&lt;orgname&gt;</code> created and project namespace with <code>&lt;orgname&gt;-&lt;projectname&gt;</code> pattern.</p>"},{"location":"tutorial-user-groups/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"tutorial-user-groups/#creating-project-roles","title":"Creating Project Roles","text":"<p>Create a Kubernetes Role to define permissions within a project namespace. These roles dictate what actions users can perform on specific resources.</p> <pre><code>apiVersion: rbac.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: shalb-demo  # Replace with your project namespace\n  name: resource-manager\nrules:\n  - apiGroups: [\"\"]  # \"\" indicates the core API group\n    resources: [\"pods\", \"services\"]\n    verbs: [\"get\", \"list\", \"create\", \"watch\", \"delete\"]\n  - apiGroups: [\"apps\"]\n    resources: [\"deployments\", \"daemonsets\", \"replicasets\"]\n    verbs: [\"get\", \"list\", \"create\", \"watch\", \"delete\"]\n</code></pre> <p>Apply the role to your namespace using:</p> <pre><code>kubectl apply -f role.yaml\n</code></pre> <p>Role Scope</p> <p>Remember that Roles are namespace-scoped. If you need permissions across multiple namespaces, you need to create a separate Role in each Project namespace.</p>"},{"location":"tutorial-user-groups/#creating-organization-groups","title":"Creating Organization Groups","text":"<p>Create an OrganizationGroup Custom Resource (CR) to define group permissions across projects.</p> <p>Key Points</p> <ul> <li>The OrganizationGroup CR automatically creates a corresponding group in Keycloak</li> <li>This CR must be created in the organization namespace, not the project namespace</li> <li>Role bindings would be created by this CR</li> </ul> <pre><code>apiVersion: kube-dc.com/v1\nkind: OrganizationGroup\nmetadata:\n  name: \"app-manager\"\n  namespace: shalb  # namespace of the organization (not the project)\nspec:\n  permissions:\n  - project: \"demo\"\n    roles:\n    - resource-manager\n  # Additional projects and roles can be added:\n  # - project: \"prod\"\n  #   roles:\n  #   - resource-manager\n</code></pre> <p>Apply the group configuration:</p> <pre><code>kubectl apply -f organization-group.yaml\n</code></pre>"},{"location":"tutorial-user-groups/#managing-users-in-keycloak","title":"Managing Users in Keycloak","text":""},{"location":"tutorial-user-groups/#access-keycloak-admin-console","title":"Access Keycloak Admin Console","text":"<p>Retrieve Keycloak access credentials from your organization namespace:</p> <pre><code>kubectl get secret realm-access -n shalb -o jsonpath='{.data.url}' | base64 -d\nkubectl get secret realm-access -n shalb -o jsonpath='{.data.user}' | base64 -d\nkubectl get secret realm-access -n shalb -o jsonpath='{.data.password}' | base64 -d\n</code></pre> <p>Remember</p> <p>Replace <code>shalb</code> with your own organization namespace in the commands above.</p>"},{"location":"tutorial-user-groups/#create-and-configure-users","title":"Create and Configure Users","text":"<ol> <li>Log in to the Keycloak admin console using the retrieved credentials</li> <li>Navigate to Users \u2192 Add User </li> <li>Fill in the required user information</li> <li>Set up initial password in the Credentials tab</li> <li>Add the user to the appropriate group (e.g., \"app-manager\") via the Groups tab </li> </ol> <p>User Group Mapping</p> <p>Any groups created via OrganizationGroup CRs will appear automatically in Keycloak. Changes to group membership in Keycloak are synchronized with Kubernetes RBAC.</p>"},{"location":"tutorial-user-groups/#accessing-kube-dc-ui","title":"Accessing Kube-DC UI","text":"<ol> <li>Navigate to the Kube-DC UI login page</li> <li>Log in using the credentials created in Keycloak</li> <li>Verify access to assigned project resources</li> </ol> <p>Permissions Troubleshooting</p> <p>If a user cannot access expected resources: - Verify they're assigned to the correct groups in Keycloak - Check that the OrganizationGroup CR includes the correct projects and roles - Ensure the underlying Kubernetes Roles have appropriate permissions - Examine the Keycloak logs for authentication issues</p> <p>Permission changes may take up to 5 minutes to propagate through the system.</p>"},{"location":"tutorial-virtual-machines/","title":"Deploying VMs &amp; Containers","text":"<p>This tutorial walks you through deploying virtual machines and containers in Kube-DC. You'll learn both the UI-based approach and how to use kubectl with YAML manifests.</p>"},{"location":"tutorial-virtual-machines/#prerequisites","title":"Prerequisites","text":"<p>Before starting this tutorial, ensure you have:</p> <ul> <li>Access to a Kube-DC cluster</li> <li>The <code>kubectl</code> command-line tool installed</li> <li>The <code>virtctl</code> plugin installed for KubeVirt (optional, but recommended)</li> <li>A project with the necessary permissions to create VMs and containers</li> </ul>"},{"location":"tutorial-virtual-machines/#understanding-vm-components-in-kube-dc","title":"Understanding VM Components in Kube-DC","text":"<p>Kube-DC's virtualization is powered by KubeVirt and consists of several components:</p> <ol> <li>VirtualMachine (VM): Defines the VM configuration and lifecycle</li> <li>DataVolume: Manages the VM's disk image(s)</li> <li>VirtualMachineInstance (VMI): Represents a running instance of a VM</li> </ol>"},{"location":"tutorial-virtual-machines/#creating-a-vm-using-the-kube-dc-ui","title":"Creating a VM Using the Kube-DC UI","text":""},{"location":"tutorial-virtual-machines/#step-1-navigate-to-vm-creation","title":"Step 1: Navigate to VM Creation","text":"<ol> <li>Log in to the Kube-DC dashboard</li> <li>Select your project from the dropdown menu (e.g., \"demo\")</li> <li>Navigate to \"Virtual Machines\" in the left sidebar</li> <li>Click the \"+\" button to create a new VM</li> </ol>"},{"location":"tutorial-virtual-machines/#step-2-configure-basic-vm-parameters","title":"Step 2: Configure Basic VM Parameters","text":"<p>In the VM creation wizard, specify the basic parameters:</p> <ol> <li>VM Name: Enter a name for your VM (e.g., \"new-vm-name\")</li> <li>Operation System: Select from the dropdown (e.g., \"Ubuntu 24.04\")</li> <li>Advanced Options: Expand this section if you want to customize the image source</li> </ol> <p></p>"},{"location":"tutorial-virtual-machines/#step-3-configure-vm-resources","title":"Step 3: Configure VM Resources","text":"<p>Continue configuring the VM:</p> <ol> <li>Number of vCPUs: Select the number of virtual CPUs</li> <li>RAM (GB): Specify the amount of memory</li> <li>Subnet: Choose the network for your VM</li> <li>Root Storage Size (GB): Set the disk size</li> <li>Root Storage Type: Select the storage class</li> </ol>"},{"location":"tutorial-virtual-machines/#step-4-review-and-create","title":"Step 4: Review and Create","text":"<ol> <li>Click \"Next\" to proceed to the review page</li> <li>Review the generated VM configuration</li> <li>The UI shows the actual YAML that will be applied</li> <li>Click \"Finish\" to create the VM</li> </ol>"},{"location":"tutorial-virtual-machines/#step-5-monitor-vm-creation","title":"Step 5: Monitor VM Creation","text":"<p>After creation:</p> <ol> <li>You'll be redirected to the VM list</li> <li>Wait for the VM to reach \"Running\" state</li> <li>Note the assigned IP address</li> </ol>"},{"location":"tutorial-virtual-machines/#managing-vms-via-the-ui","title":"Managing VMs via the UI","text":""},{"location":"tutorial-virtual-machines/#viewing-vm-details","title":"Viewing VM Details","text":"<p>Click on a VM name to view its details page, which includes:</p> <ol> <li>Guest OS: Information about the operating system</li> <li>VM Details: Status, VPC subnet, and node placement</li> <li>Performance Metrics: Real-time CPU, memory, and storage usage</li> <li>Conditions: Agent connection and other status indicators</li> </ol> <p></p>"},{"location":"tutorial-virtual-machines/#accessing-vm-console","title":"Accessing VM Console","text":"<p>From the VM details page, you have two options:</p> <ol> <li>Launch Remote Console: Opens a graphical console in your browser</li> <li>Launch SSH Terminal: Opens a web-based SSH terminal</li> </ol> <p>These options provide direct access to your VM without requiring SSH client configuration.</p>"},{"location":"tutorial-virtual-machines/#vm-actions","title":"VM Actions","text":"<p>The UI supports common VM management actions:</p> <ul> <li>Start/Stop: Control the VM power state</li> <li>Restart: Reboot the VM</li> <li>Delete: Remove the VM and its resources</li> <li>Configure: Modify VM settings</li> </ul>"},{"location":"tutorial-virtual-machines/#creating-a-vm-using-kubectl-manifests","title":"Creating a VM Using kubectl Manifests","text":"<p>For automation or GitOps workflows, you can create VMs using kubectl and YAML manifests.</p>"},{"location":"tutorial-virtual-machines/#step-1-create-datavolume","title":"Step 1: Create DataVolume","text":"<p>First, create a DataVolume to serve as the VM's disk:</p> <pre><code>apiVersion: cdi.kubevirt.io/v1beta1\nkind: DataVolume\nmetadata:\n  name: ubuntu-vm-disk\n  namespace: shalb-demo\nspec:\n  pvc:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: 10G\n    storageClassName: local-path\n  source:\n    http:\n      url: https://cloud-images.ubuntu.com/noble/current/noble-server-cloudimg-amd64.img\n</code></pre> <p>Apply this manifest:</p> <pre><code>kubectl apply -f ubuntu-datavolume.yaml\n</code></pre>"},{"location":"tutorial-virtual-machines/#step-2-create-the-vm-definition","title":"Step 2: Create the VM Definition","text":"<p>Create a VM manifest:</p> <pre><code>apiVersion: kubevirt.io/v1\nkind: VirtualMachine\nmetadata:\n  name: ubuntu-vm\n  namespace: shalb-demo\nspec:\n  running: true\n  template:\n    spec:\n      networks:\n      - name: vpc_net_0\n        multus:\n          default: true\n          networkName: shalb-demo/default\n      domain:\n        devices:\n          interfaces:\n            - name: vpc_net_0\n              bridge: {}\n          disks:\n          - disk: \n              bus: virtio\n            name: root-volume\n          - name: cloudinitdisk\n            disk:\n              bus: virtio\n        cpu:\n          cores: 2\n        memory:\n          guest: 4G\n      volumes:\n      - dataVolume:\n          name: ubuntu-vm-disk\n        name: root-volume\n      - name: cloudinitdisk\n        cloudInitNoCloud:\n          userData: |-\n            #cloud-config\n            chpasswd: { expire: False }\n            password: temppassword\n            ssh_pwauth: True\n            package_update: true\n            package_upgrade: true\n            packages:\n            - qemu-guest-agent\n            runcmd:\n            - [ systemctl, enable, qemu-guest-agent ]\n            - [ systemctl, start, qemu-guest-agent ]\n</code></pre> <p>Apply the VM manifest:</p> <pre><code>kubectl apply -f ubuntu-vm.yaml\n</code></pre>"},{"location":"tutorial-virtual-machines/#step-3-monitor-vm-status","title":"Step 3: Monitor VM Status","text":"<p>Check the status of your VM:</p> <pre><code>kubectl get virtualmachines -n shalb-demo\nkubectl get virtualmachineinstances -n shalb-demo\n</code></pre>"},{"location":"tutorial-virtual-machines/#vm-examples-for-different-operating-systems","title":"VM Examples for Different Operating Systems","text":"<p>Kube-DC supports various operating systems. Here are examples for the most common ones:</p>"},{"location":"tutorial-virtual-machines/#debian","title":"Debian","text":"<pre><code>apiVersion: cdi.kubevirt.io/v1beta1\nkind: DataVolume\nmetadata:\n  name: debian-base-img\nspec:\n  pvc:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: 14G\n    storageClassName: local-path\n  source:\n    http:\n      url: https://cloud.debian.org/images/cloud/bookworm/latest/debian-12-generic-amd64.qcow2\n---\napiVersion: kubevirt.io/v1\nkind: VirtualMachine\nmetadata:\n  name: debian-vm\n  namespace: shalb-demo\nspec:\n  running: true\n  template:\n    spec:\n      networks:\n      - name: vpc_net_0\n        multus:\n          default: true\n          networkName: shalb-demo/default\n      domain:\n        devices:\n          interfaces:\n            - name: vpc_net_0\n              bridge: {}\n          disks:\n          - disk: \n              bus: virtio\n            name: root-volume\n          - name: cloudinitdisk\n            disk:\n              bus: virtio\n        cpu:\n          cores: 1\n        memory:\n          guest: 2G\n      volumes:\n      - dataVolume:\n          name: debian-base-img\n        name: root-volume\n      - name: cloudinitdisk\n        cloudInitNoCloud:\n          userData: |-\n            #cloud-config\n            chpasswd: { expire: False }\n            password: temppassword\n            ssh_pwauth: True\n            package_update: true\n            packages:\n            - qemu-guest-agent\n            runcmd:\n            - [ systemctl, start, qemu-guest-agent ]\n</code></pre>"},{"location":"tutorial-virtual-machines/#alpine-linux","title":"Alpine Linux","text":"<pre><code>apiVersion: cdi.kubevirt.io/v1beta1\nkind: DataVolume\nmetadata:\n  name: alpine-base-img\nspec:\n  pvc:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: 2G\n    storageClassName: local-path\n  source:\n    http:\n      url: https://dl-cdn.alpinelinux.org/alpine/v3.19/releases/cloud/nocloud_alpine-3.19.1-x86_64-bios-cloudinit-r0.qcow2\n</code></pre>"},{"location":"tutorial-virtual-machines/#centos-stream-9","title":"CentOS Stream 9","text":"<pre><code>apiVersion: cdi.kubevirt.io/v1beta1\nkind: DataVolume\nmetadata:\n  name: centos-base-img\nspec:\n  pvc:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: 10G\n    storageClassName: local-path\n  source:\n    http:\n      url: https://cloud.centos.org/centos/9-stream/x86_64/images/CentOS-Stream-GenericCloud-9-latest.x86_64.qcow2\n</code></pre> <p>Note: CentOS Stream 9 requires additional SELinux configuration to enable guest agent SSH key injection. The OS configuration includes proper SELinux booleans and contexts to allow guest agent operations. See the CentOS example in <code>examples/virtual-machine/centos-8.yaml</code> for the complete cloud-init configuration with SELinux setup.</p>"},{"location":"tutorial-virtual-machines/#virtual-machine-health-checks","title":"Virtual Machine Health Checks","text":"<p>Kube-DC supports VM health checks to ensure your VMs are running properly:</p> <pre><code>spec:\n  template:\n    spec:\n      readinessProbe:\n        guestAgentPing: {}\n        failureThreshold: 10\n        initialDelaySeconds: 20\n        periodSeconds: 10\n        timeoutSeconds: 5\n      livenessProbe:\n        failureThreshold: 10\n        initialDelaySeconds: 120\n        periodSeconds: 20\n        timeoutSeconds: 5\n        httpGet:\n          port: 80\n</code></pre>"},{"location":"tutorial-virtual-machines/#exposing-vm-services","title":"Exposing VM Services","text":""},{"location":"tutorial-virtual-machines/#creating-a-service-for-vm","title":"Creating a Service for VM","text":"<p>To expose a service running on your VM:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: vm-ssh-service\n  namespace: shalb-demo\n  annotations:\n    service.nlb.kube-dc.com/bind-on-default-gw-eip: \"true\"\nspec:\n  type: LoadBalancer\n  selector:\n    vm.kubevirt.io/name: ubuntu-vm\n  ports:\n    - name: ssh\n      protocol: TCP\n      port: 2222\n      targetPort: 22\n</code></pre> <p>Apply this service:</p> <pre><code>kubectl apply -f vm-service.yaml\n</code></pre>"},{"location":"tutorial-virtual-machines/#using-floating-ips-for-vms","title":"Using Floating IPs for VMs","text":"<p>You can assign a floating IP to your VM for direct external access:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: FIp\nmetadata:\n  name: ubuntu-vm-fip\n  namespace: shalb-demo\nspec:\n  ipAddress: 10.0.10.171\n  eip: vm-eip\n</code></pre> <p>First, ensure you have an EIP:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: EIp\nmetadata:\n  name: vm-eip\n  namespace: shalb-demo\nspec: {}\n</code></pre>"},{"location":"tutorial-virtual-machines/#deploying-containers-alongside-vms","title":"Deploying Containers Alongside VMs","text":"<p>Kube-DC allows you to run containers alongside VMs. Here's how to deploy a simple Nginx container:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  namespace: shalb-demo\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n</code></pre> <p>Create a service for the Nginx deployment:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\n  namespace: shalb-demo\n  annotations:\n    service.nlb.kube-dc.com/bind-on-default-gw-eip: \"true\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: nginx\n  ports:\n  - port: 80\n    targetPort: 80\n</code></pre>"},{"location":"tutorial-virtual-machines/#best-practices-for-vm-management","title":"Best Practices for VM Management","text":""},{"location":"tutorial-virtual-machines/#resource-allocation","title":"Resource Allocation","text":"<ul> <li>Allocate appropriate resources based on the OS and workload requirements</li> <li>Monitor VM performance to adjust resources as needed</li> <li>Use resource quotas to prevent resource exhaustion</li> </ul>"},{"location":"tutorial-virtual-machines/#security","title":"Security","text":"<ul> <li>Change default passwords immediately</li> <li>Use SSH keys instead of passwords when possible</li> <li>Keep guest OS updated with security patches</li> <li>Apply network policies to control VM traffic</li> </ul>"},{"location":"tutorial-virtual-machines/#efficiency","title":"Efficiency","text":"<ul> <li>Use cloud-init for automated VM configuration</li> <li>Create VM templates for standardized deployments</li> <li>Use the smallest OS image that meets your requirements</li> </ul>"},{"location":"tutorial-virtual-machines/#troubleshooting-vms","title":"Troubleshooting VMs","text":""},{"location":"tutorial-virtual-machines/#common-issues","title":"Common Issues","text":"<ol> <li> <p>VM stuck in provisioning: Check DataVolume status and events    <pre><code>kubectl get datavolume -n shalb-demo\nkubectl describe datavolume ubuntu-vm-disk -n shalb-demo\n</code></pre></p> </li> <li> <p>VM not accessible via network: Verify network configuration    <pre><code>kubectl get vmi -n shalb-demo -o jsonpath='{.items[*].status.interfaces[*].ipAddress}'\n</code></pre></p> </li> <li> <p>Cloud-init not running: Check cloud-init logs inside the VM    <pre><code># Inside the VM\nsudo cat /var/log/cloud-init.log\n</code></pre></p> </li> </ol>"},{"location":"tutorial-virtual-machines/#accessing-vm-logs","title":"Accessing VM Logs","text":"<pre><code>kubectl get events -n shalb-demo\nvirtctl console ubuntu-vm -n shalb-demo\nvirtctl logs ubuntu-vm -n shalb-demo\n</code></pre>"},{"location":"tutorial-virtual-machines/#advanced-kubevirt-features","title":"Advanced KubeVirt Features","text":"<p>For more advanced features, refer to the KubeVirt documentation:</p> <ul> <li>VM Snapshots</li> <li>Live Migration</li> <li>GPU Passthrough</li> <li>Storage Management</li> </ul>"},{"location":"tutorial-virtual-machines/#conclusion","title":"Conclusion","text":"<p>You've now learned how to deploy and manage VMs and containers in Kube-DC using both the intuitive UI and kubectl manifests. This hybrid approach allows you to choose the most appropriate method for your workflow, whether you prefer interactive management or automation through GitOps practices.</p>"},{"location":"tutorial-windows-vm/","title":"Windows 11 VM Tutorial - Complete Setup Guide","text":"<p>This comprehensive guide covers the complete process of setting up Windows 11 VMs in KubeVirt, from infrastructure setup to golden image creation and deployment.</p>"},{"location":"tutorial-windows-vm/#overview","title":"Overview","text":"<p>This tutorial provides two deployment methods:</p> <ol> <li>Golden Image Deployment (Recommended) - Deploy pre-configured VMs in 5-10 minutes</li> <li>Fresh Installation - Create custom Windows installations with full control</li> </ol>"},{"location":"tutorial-windows-vm/#prerequisites","title":"Prerequisites","text":"<ul> <li>KubeVirt and CDI installed and running</li> <li>Multus CNI with OVN network configured</li> <li>StorageClass <code>local-path</code> available</li> <li>Ingress controller for HTTP access to ISOs</li> </ul>"},{"location":"tutorial-windows-vm/#step-1-create-iso-hosting-environment","title":"Step 1: Create ISO Hosting Environment","text":""},{"location":"tutorial-windows-vm/#11-create-dedicated-namespace","title":"1.1 Create Dedicated Namespace","text":"<pre><code># hack/windows/iso-namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: iso\n</code></pre>"},{"location":"tutorial-windows-vm/#12-create-storage-for-isos","title":"1.2 Create Storage for ISOs","text":"<pre><code># hack/windows/iso-storage-pvc-iso-ns.yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: iso-storage\n  namespace: iso\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 30Gi  # Increased for Windows ISO + golden images\n  storageClassName: local-path\n</code></pre>"},{"location":"tutorial-windows-vm/#13-http-server-for-isos","title":"1.3 HTTP Server for ISOs","text":"<pre><code># hack/windows/nginx-iso-server-iso-ns.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-iso-server\n  namespace: iso\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx-iso-server\n  template:\n    metadata:\n      labels:\n        app: nginx-iso-server\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.25-alpine\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: iso-storage\n          mountPath: /usr/share/nginx/html\n        - name: nginx-config\n          mountPath: /etc/nginx/conf.d\n      volumes:\n      - name: iso-storage\n        persistentVolumeClaim:\n          claimName: iso-storage\n      - name: nginx-config\n        configMap:\n          name: nginx-iso-config\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nginx-iso-config\n  namespace: iso\ndata:\n  default.conf: |\n    server {\n        listen 80;\n        server_name _;\n        root /usr/share/nginx/html;\n\n        location / {\n            autoindex on;\n            autoindex_exact_size off;\n            autoindex_localtime on;\n        }\n\n        location ~* \\.(iso|img|qcow2)$ {\n            add_header Content-Type application/octet-stream;\n            add_header Cache-Control \"public, max-age=3600\";\n        }\n    }\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-iso-server\n  namespace: iso\nspec:\n  selector:\n    app: nginx-iso-server\n  ports:\n  - port: 80\n    targetPort: 80\n</code></pre>"},{"location":"tutorial-windows-vm/#14-ingress-configuration-with-tls","title":"1.4 Ingress Configuration with TLS","text":"<pre><code># hack/windows/iso-ingress-iso-ns.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: iso-server-ingress\n  namespace: iso\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod-http\n    nginx.ingress.kubernetes.io/proxy-body-size: \"0\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"3600\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"3600\"\n    nginx.ingress.kubernetes.io/proxy-buffering: \"off\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - iso.stage.kube-dc.com\n    secretName: iso-server-tls\n  rules:\n  - host: iso.stage.kube-dc.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: iso-server\n            port:\n              number: 80\n</code></pre>"},{"location":"tutorial-windows-vm/#15-deploy-infrastructure","title":"1.5 Deploy Infrastructure","text":"<pre><code># Deploy all infrastructure components\nkubectl apply -f hack/windows/iso-namespace.yaml\nkubectl apply -f hack/windows/iso-storage-pvc-iso-ns.yaml\nkubectl apply -f hack/windows/nginx-iso-server-iso-ns.yaml\nkubectl apply -f hack/windows/iso-ingress-iso-ns.yaml\n\n# Verify deployment\nkubectl get pods -n iso\nkubectl get ingress -n iso\n</code></pre>"},{"location":"tutorial-windows-vm/#step-2-download-and-upload-windows-iso","title":"Step 2: Download and Upload Windows ISO","text":""},{"location":"tutorial-windows-vm/#21-download-windows-11-enterprise-iso","title":"2.1 Download Windows 11 Enterprise ISO","text":"<ol> <li>Visit: https://www.microsoft.com/en-us/evalcenter/download-windows-11-enterprise</li> <li>Select: ISO \u2013 Enterprise download 64-bit edition (90-day evaluation)  </li> <li>Download the ISO file (approximately 5.4GB)</li> </ol>"},{"location":"tutorial-windows-vm/#22-download-virtio-drivers","title":"2.2 Download VirtIO Drivers","text":"<pre><code># Download latest VirtIO drivers\nwget https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/stable-virtio/virtio-win.iso\n</code></pre>"},{"location":"tutorial-windows-vm/#23-upload-files-to-cluster","title":"2.3 Upload Files to Cluster","text":"<pre><code># Create temporary upload pod\nkubectl apply -f hack/windows/iso-upload-pod.yaml\n\n# Wait for pod to be ready\nkubectl wait --for=condition=Ready pod/iso-upload-pod -n iso --timeout=60s\n\n# Upload Windows 11 ISO (replace with your actual filename)\nkubectl cp ~/Win11_24H2_EnglishInternational_x64.iso iso/iso-upload-pod:/storage/win11-x64.iso\n\n# Upload VirtIO drivers\nkubectl cp ~/virtio-win.iso iso/iso-upload-pod:/storage/virtio-win.iso\n\n# Upload OpenSSH installation script\nkubectl cp hack/windows/install-openssh-windows.ps1 iso/iso-upload-pod:/storage/install-openssh-windows.ps1\n\n# Clean up upload pod\nkubectl delete pod iso-upload-pod -n iso --wait=true\n\n# Verify files are accessible\ncurl -I https://iso.stage.kube-dc.com/win11-x64.iso\ncurl -I https://iso.stage.kube-dc.com/virtio-win.iso\n</code></pre>"},{"location":"tutorial-windows-vm/#step-3-fresh-windows-installation","title":"Step 3: Fresh Windows Installation","text":""},{"location":"tutorial-windows-vm/#31-deploy-installation-vm","title":"3.1 Deploy Installation VM","text":"<p>Use the complete VM manifest that includes all required DataVolumes:</p> <pre><code># Deploy Windows VM with installation ISOs\nkubectl apply -f hack/windows/windows11-vm.yaml\n\n# Monitor DataVolume download progress\nkubectl get dv -n shalb-dev\n\n# Check VM status\nkubectl get vm,vmi -n shalb-dev | grep windows11\n</code></pre>"},{"location":"tutorial-windows-vm/#32-windows-installation-process","title":"3.2 Windows Installation Process","text":"<pre><code># Access VM console via VNC\nvirtctl vnc windows11-vm -n shalb-dev\n\n# Or use VNC proxy\nvirtctl vnc windows11-vm -n shalb-dev --proxy-only --port 5900\n# Then connect VNC client to localhost:5900\n</code></pre> <p>Installation Steps:</p> <ol> <li> <p>Boot from Windows ISO: VM boots from Windows installer (bootOrder: 1)</p> </li> <li> <p>Load VirtIO Drivers: </p> </li> <li>When prompted for disk drivers, click \"Load driver\"</li> <li>Browse to VirtIO drivers CDROM</li> <li>Navigate to <code>/amd64/w11/</code> folder</li> <li>Install VirtIO SCSI controller drivers (for disk access)</li> <li> <p>DO NOT install network drivers yet (to create local account)</p> </li> <li> <p>Install Windows: </p> </li> <li>Select the 60GB VirtIO disk for installation</li> <li> <p>Complete Windows 11 setup with local account</p> </li> <li> <p>Post-Installation:</p> </li> <li> <p>Install remaining VirtIO drivers from CDROM (network, balloon, RNG)</p> </li> <li>Install QEMU Guest Agent from VirtIO drivers CDROM</li> <li>Run Windows Updates</li> </ol>"},{"location":"tutorial-windows-vm/#33-configure-ssh-and-rdp","title":"3.3 Configure SSH and RDP","text":"<p>After Windows installation, configure SSH and RDP access:</p> <pre><code># Method 1: Download and run script\nInvoke-WebRequest -Uri \"https://iso.stage.kube-dc.com/install-openssh-windows.ps1\" -OutFile \"install-openssh-windows.ps1\"\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\n.\\install-openssh-windows.ps1\n\n# Method 2: Direct execution (bypass execution policy)\nPowerShell -ExecutionPolicy Bypass -Command \"Invoke-Expression (Invoke-WebRequest -Uri 'https://iso.stage.kube-dc.com/install-openssh-windows.ps1').Content\"\n</code></pre> <p>Script Features:</p> <ul> <li>\u2705 Installs OpenSSH Server using Windows capabilities</li> <li>\u2705 Configures SSH service for automatic startup  </li> <li>\u2705 Opens SSH port 22 in Windows Firewall (all network profiles)</li> <li>\u2705 Enables Remote Desktop (port 3389)</li> <li>\u2705 Enables ICMP ping (IPv4 and IPv6)</li> <li>\u2705 Provides detailed verification and status reporting</li> </ul>"},{"location":"tutorial-windows-vm/#step-4-create-golden-image","title":"Step 4: Create Golden Image","text":""},{"location":"tutorial-windows-vm/#41-prepare-vm-for-golden-image","title":"4.1 Prepare VM for Golden Image","text":"<pre><code># 1. Inside Windows VM, run Sysprep (optional but recommended)\n# Navigate to: C:\\Windows\\System32\\Sysprep\\sysprep.exe\n# Options: Generalize, Enter System Out-of-Box Experience (OOBE), Shutdown\n\n# 2. Stop the source VM (CRITICAL for export)\nkubectl patch vm windows11-vm -n shalb-dev --type merge -p '{\"spec\":{\"runStrategy\":\"Halted\"}}'\nkubectl wait --for=delete vmi/windows11-vm -n shalb-dev --timeout=300s\n</code></pre>"},{"location":"tutorial-windows-vm/#42-export-to-qcow2-golden-image","title":"4.2 Export to QCOW2 Golden Image","text":"<pre><code># hack/windows/export-golden-image.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: export-golden-image\n  namespace: shalb-dev\nspec:\n  restartPolicy: Never\n  containers:\n    - name: exporter\n      image: ubuntu:22.04\n      command: [\"sh\", \"-c\"]\n      args:\n        - |\n          set -e\n          apt-get update &amp;&amp; apt-get install -y qemu-utils curl\n          cd /pvc\n\n          echo \"=== Disk Information ===\"\n          DISK_SIZE_BYTES=$(qemu-img info --output=json disk.img | grep '\"virtual-size\"' | cut -d: -f2 | tr -d ' ,')\n          DISK_SIZE_GB=$((DISK_SIZE_BYTES / 1024 / 1024 / 1024))\n          echo \"Source disk: ${DISK_SIZE_GB}GB (${DISK_SIZE_BYTES} bytes)\"\n\n          echo \"=== Converting to compressed QCOW2 ===\"\n          qemu-img convert -p -O qcow2 -c disk.img windows11-x64-golden.qcow2\n\n          echo \"=== Final Golden Image ===\"\n          ls -lh windows11-x64-golden.qcow2\n          qemu-img info windows11-x64-golden.qcow2\n\n          echo \"=== Upload to ISO server ===\"\n          # Upload to ISO server storage\n          curl -T windows11-x64-golden.qcow2 http://nginx-iso-server.iso.svc.cluster.local/windows11-x64-golden.qcow2 || echo \"Upload failed, manual copy required\"\n\n          echo \"=== Export completed, sleeping for inspection ===\"\n          sleep 3600\n      volumeMounts:\n        - name: source-disk\n          mountPath: /pvc\n  volumes:\n    - name: source-disk\n      persistentVolumeClaim:\n        claimName: windows11-disk\n</code></pre>"},{"location":"tutorial-windows-vm/#43-export-process","title":"4.3 Export Process","text":"<pre><code># Export golden image\nkubectl apply -f hack/windows/export-golden-image.yaml\nkubectl wait --for=condition=Ready pod/export-golden-image -n shalb-dev --timeout=120s\n\n# Monitor export progress\nkubectl logs -n shalb-dev export-golden-image -f\n\n# Manual copy to ISO server (if curl upload fails)\nkubectl cp shalb-dev/export-golden-image:/pvc/windows11-x64-golden.qcow2 /tmp/\nkubectl cp /tmp/windows11-x64-golden.qcow2 iso/iso-upload-pod:/storage/\n\n# Verify golden image is available\ncurl -I https://iso.stage.kube-dc.com/windows11-x64-golden.qcow2\n\n# Clean up export pod\nkubectl delete pod export-golden-image -n shalb-dev --wait=true\n</code></pre>"},{"location":"tutorial-windows-vm/#step-5-deploy-from-golden-image","title":"Step 5: Deploy from Golden Image","text":""},{"location":"tutorial-windows-vm/#51-golden-image-deployment-recommended","title":"5.1 Golden Image Deployment (Recommended)","text":"<pre><code># Deploy VM from golden image\nkubectl apply -f hack/windows/win11-x64.yaml\n\n# Create SSH key secret for key injection\nkubectl create secret generic authorized-keys-default \\\n  --from-file=key1=~/.ssh/id_rsa.pub \\\n  -n shalb-dev\n\n# Monitor deployment\nkubectl get vm,vmi,dv -n shalb-dev | grep win11-x64\n\n# Get VM IP when ready\nkubectl get vmi win11-x64 -n shalb-dev -o jsonpath='{.status.interfaces[0].ipAddress}'\n\n# SSH to VM (once guest agent is ready)\nssh kube-dc@&lt;vm-ip&gt;\n</code></pre>"},{"location":"tutorial-windows-vm/#52-golden-image-benefits","title":"5.2 Golden Image Benefits","text":"Aspect Golden Image Fresh Install Deployment Time 5-10 minutes 30+ minutes Download Size 21.3GB compressed 5.4GB + drivers Configuration Pre-configured Manual setup required SSH/RDP Ready immediately Requires script execution VirtIO Drivers Pre-installed Manual installation Use Case Production deployment Custom configurations"},{"location":"tutorial-windows-vm/#step-6-troubleshooting","title":"Step 6: Troubleshooting","text":""},{"location":"tutorial-windows-vm/#61-common-issues","title":"6.1 Common Issues","text":"<p>DataVolume stuck in ImportScheduled: <pre><code># Check CDI importer pods\nkubectl get pods -n cdi\nkubectl logs -n cdi &lt;importer-pod&gt;\n\n# Check storage provisioner\nkubectl get pods -n local-path-storage\n</code></pre></p> <p>VM won't start - CPU resources: <pre><code># Check node resources\nkubectl describe nodes | grep -A 10 \"Allocated resources\"\n\n# Reduce VM CPU if needed\nkubectl patch vm &lt;vm-name&gt; -n &lt;namespace&gt; --type merge -p '{\"spec\":{\"template\":{\"spec\":{\"domain\":{\"cpu\":{\"cores\":2}}}}}}'\n</code></pre></p> <p>SSH not working: <pre><code># Check guest agent connection\nkubectl describe vmi &lt;vm-name&gt; -n &lt;namespace&gt; | grep -i agent\n\n# Test network connectivity\nkubectl run test-pod --image=nicolaka/netshoot --rm -it -- ping &lt;vm-ip&gt;\nkubectl run test-pod --image=nicolaka/netshoot --rm -it -- nc -zv &lt;vm-ip&gt; 22\n</code></pre></p> <p>Storage issues with local-path: <pre><code># Check local-path provisioner\nkubectl get pods -n local-path-storage\nkubectl logs -n local-path-storage &lt;provisioner-pod&gt;\n\n# Note: local-path doesn't support Block mode, use Filesystem mode\n</code></pre></p>"},{"location":"tutorial-windows-vm/#62-verification-commands","title":"6.2 Verification Commands","text":"<pre><code># Check all Windows VMs\nkubectl get vm -A | grep -i win\n\n# Check DataVolume progress\nkubectl get dv -n &lt;namespace&gt;\n\n# Access VM console\nvirtctl vnc &lt;vm-name&gt; -n &lt;namespace&gt;\n\n# Check VM resource usage\nkubectl top pods -n &lt;namespace&gt; | grep virt-launcher\n</code></pre>"},{"location":"tutorial-windows-vm/#required-manifests-summary","title":"Required Manifests Summary","text":"<p>Infrastructure (Step 1): - <code>hack/windows/iso-namespace.yaml</code> - ISO namespace - <code>hack/windows/iso-storage-pvc-iso-ns.yaml</code> - Storage for ISOs - <code>hack/windows/nginx-iso-server-iso-ns.yaml</code> - HTTP server - <code>hack/windows/iso-ingress-iso-ns.yaml</code> - Ingress configuration</p> <p>Utilities: - <code>hack/windows/iso-upload-pod.yaml</code> - Upload files to cluster - <code>hack/windows/install-openssh-windows.ps1</code> - SSH/RDP configuration script</p> <p>VM Deployment: - <code>hack/windows/windows11-vm.yaml</code> - Fresh installation VM - <code>hack/windows/win11-x64.yaml</code> - Golden image deployment</p> <p>Golden Image Creation: - <code>hack/windows/export-golden-image.yaml</code> - Export VM to QCOW2 - <code>hack/windows/windows11-enterprise-golden-datasource.yaml</code> - DataSource for cloning</p> <p>Optional: - <code>hack/windows/windows11-from-datasource.yaml</code> - Deploy from DataSource (same namespace) - <code>hack/windows/pvc-init-windows11-disk.yaml</code> - Fix disk size issues if needed</p>"},{"location":"tutorial-windows-vm/#available-resources","title":"Available Resources","text":"<p>Once deployed, the following resources are available:</p> <ul> <li>Windows 11 ISO: <code>https://iso.stage.kube-dc.com/win11-x64.iso</code> (5.4GB)</li> <li>VirtIO Drivers: <code>https://iso.stage.kube-dc.com/virtio-win.iso</code> (700MB)</li> <li>SSH Script: <code>https://iso.stage.kube-dc.com/install-openssh-windows.ps1</code> (5KB)</li> <li>Golden Image: <code>https://iso.stage.kube-dc.com/windows11-x64-golden.qcow2</code> (21.3GB)</li> </ul>"},{"location":"tutorial-windows-vm/#security-considerations","title":"Security Considerations","text":"<ul> <li>SSH Keys: Use KubeVirt accessCredentials for secure key injection {{ ... }}</li> <li>Network Policies: Implement Kubernetes network policies for VM isolation</li> <li>Sysprep: Run before creating golden images to avoid SID conflicts</li> <li>Firewall: Script configures Windows Firewall appropriately for SSH, RDP, and ICMP</li> </ul> <p>\u2705 Complete Windows 11 VM infrastructure with golden image support ready for production use!</p>"},{"location":"user-groups/","title":"User and Group Management","text":"<p>This guide explains how to set up and manage users, groups, and roles in Kube-DC using Kubernetes RBAC and Keycloak integration.</p>"},{"location":"user-groups/#overview","title":"Overview","text":"<p>Kube-DC implements a multi-tenant access control system that combines:</p> <ul> <li>Kubernetes RBAC: Handles resource-level permissions within namespaces</li> <li>Organization Groups: Manages project-level access across namespaces</li> <li>Keycloak Integration: Provides user authentication and group management</li> </ul>"},{"location":"user-groups/#standard-roles","title":"Standard Roles","text":"<p>Kube-DC automatically creates standard roles when organizations and projects are provisioned. These provide a baseline permission structure that can be extended with custom roles.</p>"},{"location":"user-groups/#organization-level-roles","title":"Organization-Level Roles","text":"Role Group Permissions <code>{org}-admin</code> <code>org-admin</code> Full CRUD on organizations, projects, organizationgroups <code>{org}-user</code> <code>user</code> Read-only access to organization and projects list"},{"location":"user-groups/#project-level-roles","title":"Project-Level Roles","text":"Role Description Key Permissions <code>admin</code> Full project access All resources: <code>*</code> verbs, RBAC management <code>developer</code> VM/workload management VMs, pods, services: full CRUD; secrets: read-only; no RBAC <code>project-manager</code> View + console access All resources: get, list, watch; VM console/VNC access <code>user</code> Read-only access All resources: get, list; no console, no secrets"},{"location":"user-groups/#automatic-role-bindings","title":"Automatic Role Bindings","text":"<p>When a project is created, the following bindings are automatically configured:</p> RoleBinding Subject Role Purpose <code>org-admin</code> <code>{org}:org-admin</code> <code>admin</code> Org admins get full project access <code>user</code> <code>{org}:user</code> <code>user</code> All org users get read-only access"},{"location":"user-groups/#assigning-elevated-access","title":"Assigning Elevated Access","text":"<p>To grant users elevated access (developer or project-manager roles), create an OrganizationGroup:</p> <pre><code>apiVersion: kube-dc.com/v1\nkind: OrganizationGroup\nmetadata:\n  name: dev-team\n  namespace: shalb  # organization namespace\nspec:\n  permissions:\n  - project: demo\n    roles:\n    - developer  # grants developer role in shalb-demo project\n</code></pre> <p>This creates a Keycloak group <code>dev-team</code>. Add users to this group in Keycloak to grant them developer access to the specified project.</p>"},{"location":"user-groups/#prerequisites","title":"Prerequisites","text":"<p>This guide assumes you're working from an Organization Admin perspective. You'll need:</p> <ul> <li>Access to the Kube-DC cluster with organization admin privileges</li> <li><code>kubectl</code> configured to access your cluster with organization admin privileges</li> <li>Access to the Keycloak organization admin console</li> </ul> <p>Before You Begin</p> <p>During organization and project creation you will get a namespace with organization name <code>&lt;orgname&gt;</code> created and project namespace with <code>&lt;orgname&gt;-&lt;projectname&gt;</code> pattern.</p>"},{"location":"user-groups/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"user-groups/#creating-custom-project-roles","title":"Creating Custom Project Roles","text":"<p>While Kube-DC provides standard roles (<code>admin</code>, <code>developer</code>, <code>project-manager</code>, <code>user</code>) that cover most use cases, you can create custom Kubernetes Roles for specialized permission requirements.</p> <p>When to Use Custom Roles</p> <p>Custom roles are useful when:</p> <ul> <li>You need permissions not covered by standard roles</li> <li>You want to restrict access to specific resource types</li> <li>You need fine-grained control over particular workloads</li> </ul> <p>Example: Custom role for managing deployments and services</p> <pre><code>apiVersion: rbac.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: shalb-demo  # Replace with your project namespace\n  name: deployment-manager  # Custom role name\nrules:\n  - apiGroups: [\"\"]  # \"\" indicates the core API group\n    resources: [\"pods\", \"services\"]\n    verbs: [\"get\", \"list\", \"create\", \"watch\", \"delete\"]\n  - apiGroups: [\"apps\"]\n    resources: [\"deployments\", \"daemonsets\", \"replicasets\"]\n    verbs: [\"get\", \"list\", \"create\", \"watch\", \"delete\"]\n</code></pre> <p>Apply the custom role:</p> <pre><code>kubectl apply -f custom-role.yaml\n</code></pre> <p>Role Scope</p> <p>Roles are namespace-scoped. If you need permissions across multiple namespaces, create the Role in each project namespace or reference it via OrganizationGroup.</p>"},{"location":"user-groups/#creating-organization-groups","title":"Creating Organization Groups","text":"<p>Create an OrganizationGroup Custom Resource (CR) to define group permissions across projects.</p> <p>Key Points</p> <ul> <li>The OrganizationGroup CR automatically creates a corresponding group in Keycloak</li> <li>This CR must be created in the organization namespace, not the project namespace</li> <li>Role bindings would be created by this CR</li> </ul> <pre><code>apiVersion: kube-dc.com/v1\nkind: OrganizationGroup\nmetadata:\n  name: \"app-manager\"\n  namespace: shalb  # namespace of the organization (not the project)\nspec:\n  permissions:\n  - project: \"demo\"\n    roles:\n    - developer  # standard role, or use custom role name like 'deployment-manager'\n  # Additional projects and roles can be added:\n  # - project: \"prod\"\n  #   roles:\n  #   - project-manager\n</code></pre> <p>Apply the group configuration:</p> <pre><code>kubectl apply -f organization-group.yaml\n</code></pre>"},{"location":"user-groups/#managing-users-in-keycloak","title":"Managing Users in Keycloak","text":""},{"location":"user-groups/#access-keycloak-admin-console","title":"Access Keycloak Admin Console","text":"<p>Retrieve Keycloak access credentials from your organization namespace:</p> <pre><code>kubectl get secret realm-access -n shalb -o jsonpath='{.data.url}' | base64 -d\nkubectl get secret realm-access -n shalb -o jsonpath='{.data.user}' | base64 -d\nkubectl get secret realm-access -n shalb -o jsonpath='{.data.password}' | base64 -d\n</code></pre> <p>Remember</p> <p>Replace <code>shalb</code> with your own organization namespace in the commands above.</p>"},{"location":"user-groups/#create-and-configure-users","title":"Create and Configure Users","text":"<ol> <li>Log in to the Keycloak admin console using the retrieved credentials</li> <li>Navigate to Users \u2192 Add User </li> <li>Fill in the required user information</li> <li>Set up initial password in the Credentials tab</li> <li>Add the user to the appropriate group (e.g., \"app-manager\") via the Groups tab </li> </ol> <p>User Group Mapping</p> <p>Any groups created via OrganizationGroup CRs will appear automatically in Keycloak. Changes to group membership in Keycloak are synchronized with Kubernetes RBAC.</p>"},{"location":"user-groups/#accessing-kube-dc-ui","title":"Accessing Kube-DC UI","text":"<ol> <li>Navigate to the Kube-DC UI login page</li> <li>Log in using the credentials created in Keycloak</li> <li>Verify access to assigned project resources</li> </ol> <p>Permissions Troubleshooting</p> <p>If a user cannot access expected resources: - Verify they're assigned to the correct groups in Keycloak - Check that the OrganizationGroup CR includes the correct projects and roles - Ensure the underlying Kubernetes Roles have appropriate permissions - Examine the Keycloak logs for authentication issues</p> <p>Permission changes may take up to 5 minutes to propagate through the system.</p>"},{"location":"prd/acme_challenge_http_route/","title":"PRD: ACME HTTP-01 Challenge Integration with Envoy Gateway","text":""},{"location":"prd/acme_challenge_http_route/#status","title":"Status","text":"Component Status Gateway Backend auto-creation \u2705 Implemented (commit <code>dac0122</code>) Shared Envoy Gateway \u2705 Deployed (replaces nginx-ingress) HTTPRoute Controller (mutation) \ud83d\udd32 Pending ACME Solver Service detection \ud83d\udd32 Pending Manual test \u2705 Verified"},{"location":"prd/acme_challenge_http_route/#business-context","title":"Business Context","text":"<p>Goal: Minimize IPv4 usage per tenant by using shared gateways for traffic multiplexing.</p> <p>Architecture Vision: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Shared Envoy Gateway: eg (envoy-gateway-system)        \u2502\n\u2502                         88.99.29.250                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  HTTP :80 (ACME + redirect)  \u2502  TLS :6443 (passthrough)            \u2502\n\u2502           \u2193                  \u2502           \u2193                          \u2502\n\u2502  HTTPRoute \u2192 Backend         \u2502  TLSRoute \u2192 Backend                  \u2502\n\u2502  (solver ext-cloud IP)       \u2502  (tenant K8s API ext-cloud IP)       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  HTTPS :443 (per-host TLS termination for platform services)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2193                           \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Customer A (ext-cloud)   \u2502  \u2502  Customer B (ext-cloud)   \u2502\n\u2502  100.65.0.10              \u2502  \u2502  100.65.0.20              \u2502\n\u2502  - Gets cert via ACME     \u2502  \u2502  - Gets cert via ACME     \u2502\n\u2502  - Terminates TLS itself  \u2502  \u2502  - Terminates TLS itself  \u2502\n\u2502  - No public IP needed    \u2502  \u2502  - No public IP needed    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Key Benefits: - 1000 customers, 1-3 public IPs (instead of 1000 public IPs) - No certificate sharing - gateway never sees customer certs (TLS passthrough) - Customer isolation - each customer terminates TLS in their own namespace - Standard Let's Encrypt - customers use HTTP-01 challenge, no DNS API needed</p>"},{"location":"prd/acme_challenge_http_route/#problem-statement","title":"Problem Statement","text":"<p>Customers want to use Let's Encrypt certificates with HTTP-01 challenges in their project namespaces. However, the current network isolation between Envoy Gateway (<code>envoy-gateway-system</code> / <code>ovn-default</code>) and project namespaces (isolated subnets) prevents cert-manager's ACME solver from working with the shared Gateway.</p>"},{"location":"prd/acme_challenge_http_route/#scope-cloud-networking-only","title":"Scope: Cloud Networking Only","text":"<p>This solution applies only to cloud networking (<code>ext-cloud</code> / <code>externalNetworkType: cloud</code>):</p> Network Type Gateway can reach Service? Solution Needed? Public (<code>ext-public</code>) \u2705 Yes - routable public IP \u274c No - standard routing works Cloud (<code>ext-cloud</code>) \u274c No - isolated VPC subnet \u2705 Yes - Backend required <p>For public network, the Gateway can directly route to services via their public IPs - no Backend workaround needed.</p> <p>For cloud network, services get private IPs (e.g., <code>100.65.x.x</code>) that are only reachable via static routes on nodes. The Gateway (in <code>ovn-default</code>) cannot reach these IPs directly, hence the Backend + ext-cloud IP pattern.</p>"},{"location":"prd/acme_challenge_http_route/#current-architecture","title":"Current Architecture","text":""},{"location":"prd/acme_challenge_http_route/#what-works-tls-passthrough-with-backend","title":"What Works: TLS Passthrough with Backend","text":"<pre><code>Gateway \u2192 TLSRoute \u2192 Backend (ext-cloud IP) \u2192 K8s API Service\n</code></pre> <p>We use a Backend resource pointing to an external IP (ext-cloud), which is reachable from the Gateway via static routes on nodes.</p> <pre><code>apiVersion: gateway.envoyproxy.io/v1alpha1\nkind: Backend\nmetadata:\n  name: demo-cluster-api\n  namespace: shalb-demo\nspec:\n  endpoints:\n  - ip:\n      address: 100.65.0.104  # ext-cloud IP - reachable from Gateway\n      port: 6443\n</code></pre>"},{"location":"prd/acme_challenge_http_route/#what-doesnt-work-acme-http-01-challenge","title":"What Doesn't Work: ACME HTTP-01 Challenge","text":"<p>cert-manager's <code>gatewayHTTPRoute</code> solver creates:</p> <pre><code>apiVersion: gateway.networking.k8s.io/v1\nkind: HTTPRoute\nspec:\n  backendRefs:\n  - kind: Service  # \u2190 Points to ClusterIP Service directly\n    name: cm-acme-http-solver-xyz\n    namespace: shalb-demo\n    port: 8089\n</code></pre> <p>Why it fails: 1. Gateway tries to reach ClusterIP (<code>10.x.x.x</code>) in isolated project subnet 2. Gateway (in <code>ovn-default</code>) can't reach project subnet due to network isolation 3. ACME challenge fails with connection timeout</p>"},{"location":"prd/acme_challenge_http_route/#root-cause","title":"Root Cause","text":"Resource Created By Points To Reachable? TLSRoute (K8s CP) User Backend with ext-cloud IP \u2713 Yes HTTPRoute (ACME) cert-manager Service (ClusterIP) \u2717 No <p>The difference: we control Backend creation for K8s CP, but cert-manager hardcodes Service references for ACME challenges.</p>"},{"location":"prd/acme_challenge_http_route/#proposed-solution","title":"Proposed Solution","text":""},{"location":"prd/acme_challenge_http_route/#controller-based-approach-recommended","title":"Controller-Based Approach (Recommended)","text":"<p>Instead of using a Mutating Admission Webhook, we use a controller-based reconciliation pattern. This approach:</p> <ol> <li>Follows Kubernetes best practices - Controllers are the standard way to manage resources</li> <li>No webhook latency - Webhooks add latency to API server requests</li> <li>Simpler deployment - No need for webhook certificates, TLS configuration</li> <li>Idempotent - Controllers naturally handle retries and eventual consistency</li> <li>Easier debugging - Controller logs are easier to trace than webhook calls</li> </ol> <p>Why not Mutating Webhook? - Webhooks intercept requests synchronously, adding latency - Webhook failures can block resource creation entirely - Requires additional TLS certificate management - More complex failure modes</p> <p>Controller Pattern: - Watch HTTPRoutes with ACME solver labels - Reconcile by modifying <code>backendRefs</code> from Service \u2192 Backend - Idempotent updates - if already correct, no change needed</p>"},{"location":"prd/acme_challenge_http_route/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  HTTPRoute Controller                                       \u2502\n\u2502  (existing kube-dc-manager)                                 \u2502\n\u2502                                                             \u2502\n\u2502  Watches:                                                   \u2502\n\u2502  - HTTPRoutes with label acme.cert-manager.io/http-domain   \u2502\n\u2502  - Services with label acme.cert-manager.io/http01-solver   \u2502\n\u2502                                                             \u2502\n\u2502  Actions:                                                   \u2502\n\u2502  1. When ACME solver Service created:                       \u2502\n\u2502     \u2192 Convert to LoadBalancer (bind to default-gw EIP)      \u2502\n\u2502     \u2192 Auto-creates Backend via existing annotation          \u2502\n\u2502                                                             \u2502\n\u2502  2. When ACME HTTPRoute created:                            \u2502\n\u2502     \u2192 Patch backendRef: Service \u2192 Backend                   \u2502\n\u2502     \u2192 Gateway can now route to ext-cloud IP                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/acme_challenge_http_route/#flow-diagram","title":"Flow Diagram","text":"<pre><code>1. Customer creates Certificate resource\n                \u2193\n2. cert-manager creates Challenge\n                \u2193\n3. cert-manager creates Solver Pod + Service (ClusterIP)\n   (label: acme.cert-manager.io/http01-solver=true)\n                \u2193\n4. [CONTROLLER] Detects ACME solver Service\n   \u2192 Patches Service: type=LoadBalancer, annotations for EIP + Backend\n   \u2192 Existing service controller creates:\n     - EIP (externalNetworkType: cloud)\n     - Backend pointing to EIP (via create-gateway-backend annotation)\n                \u2193\n5. cert-manager creates HTTPRoute (pointing to Service)\n   (label: acme.cert-manager.io/http-domain=&lt;domain&gt;)\n                \u2193\n6. [CONTROLLER] Detects ACME HTTPRoute\n   \u2192 Patches backendRef: Service \u2192 Backend\n   \u2192 Uses Backend name: &lt;service-name&gt;-backend\n                \u2193\n7. Gateway routes ACME challenge to Backend (ext-cloud IP)\n                \u2193\n8. ACME challenge succeeds\n                \u2193\n9. Certificate issued\n                \u2193\n10. cert-manager deletes solver resources\n    \u2192 Service deletion cascades to Backend (ownerReference)\n</code></pre>"},{"location":"prd/acme_challenge_http_route/#implementation-details","title":"Implementation Details","text":""},{"location":"prd/acme_challenge_http_route/#implemented-gateway-backend-auto-creation","title":"Implemented: Gateway Backend Auto-Creation","text":"<p>Already implemented in commit <code>dac0122</code>. When a LoadBalancer service has the annotation:</p> <pre><code>annotations:\n  service.nlb.kube-dc.com/create-gateway-backend: \"true\"\n</code></pre> <p>The service controller automatically creates a Backend resource pointing to the service's external IP.</p> <p>Usage: <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\n  annotations:\n    service.nlb.kube-dc.com/bind-on-eip: default-gw\n    service.nlb.kube-dc.com/create-gateway-backend: \"true\"\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8089\n</code></pre></p> <p>This creates: - LoadBalancer with ext-cloud IP (e.g., <code>100.65.0.102</code>) - Backend <code>my-app-backend</code> pointing to <code>100.65.0.102:8089</code></p>"},{"location":"prd/acme_challenge_http_route/#part-1-acme-solver-service-controller","title":"Part 1: ACME Solver Service Controller","text":"<p>Extend the existing service controller to detect ACME solver services and automatically add the required annotations. Only applies to cloud networking.</p> <p>Watch Predicate: <pre><code>func isACMESolverService(obj client.Object) bool {\n    labels := obj.GetLabels()\n    return labels[\"acme.cert-manager.io/http01-solver\"] == \"true\"\n}\n</code></pre></p> <p>Reconcile Logic: <pre><code>func (r *ServiceReconciler) reconcileACMESolver(ctx context.Context, svc *corev1.Service, project *kubedcv1.Project) error {\n    // Check if this is an ACME solver service\n    if svc.Labels[\"acme.cert-manager.io/http01-solver\"] != \"true\" {\n        return nil\n    }\n\n    // Determine network type from:\n    // 1. Service annotation (explicit override)\n    // 2. Project default\n    netType := svc.GetAnnotations()[kubedccomv1.NetworkExternalTypeLabelKey]\n    if netType == \"\" {\n        netType = string(project.Spec.ExternalNetworkType)\n    }\n\n    // Only apply Backend workaround for cloud networking\n    // Public network can route directly - no Backend needed\n    if netType != \"cloud\" {\n        return nil\n    }\n\n    // Check if already patched\n    if svc.Spec.Type == corev1.ServiceTypeLoadBalancer {\n        return nil\n    }\n\n    // Patch service to LoadBalancer with Backend annotation\n    patch := client.MergeFrom(svc.DeepCopy())\n    svc.Spec.Type = corev1.ServiceTypeLoadBalancer\n    if svc.Annotations == nil {\n        svc.Annotations = make(map[string]string)\n    }\n    svc.Annotations[\"service.nlb.kube-dc.com/bind-on-eip\"] = \"default-gw\"\n    svc.Annotations[\"service.nlb.kube-dc.com/create-gateway-backend\"] = \"true\"\n\n    return r.Patch(ctx, svc, patch)\n}\n</code></pre></p> <p>Network Type Annotation: Services can override project's default network type using: <pre><code>annotations:\n  network.kube-dc.com/external-network-type: \"cloud\"  # or \"public\"\n</code></pre></p>"},{"location":"prd/acme_challenge_http_route/#part-2-httproute-controller-not-webhook","title":"Part 2: HTTPRoute Controller (Not Webhook)","text":"<p>Why Controller instead of Mutating Webhook:</p> Aspect Mutating Webhook Controller Timing Synchronous (blocks API) Asynchronous (eventual) Failure mode Blocks resource creation Retries automatically TLS certs Required for webhook Not needed Latency Adds to every request No API latency Debugging Harder to trace Controller logs Best practice For validation/defaults For resource management <p>Controller Implementation: <pre><code>// HTTPRouteReconciler watches HTTPRoutes and patches ACME solver routes\ntype HTTPRouteReconciler struct {\n    client.Client\n    Scheme *runtime.Scheme\n}\n\n// Watch predicate - only ACME HTTPRoutes\nfunc isACMEHTTPRoute(obj client.Object) bool {\n    labels := obj.GetLabels()\n    _, hasACMELabel := labels[\"acme.cert-manager.io/http-domain\"]\n    return hasACMELabel\n}\n\nfunc (r *HTTPRouteReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\n    route := &amp;gatewayv1.HTTPRoute{}\n    if err := r.Get(ctx, req.NamespacedName, route); err != nil {\n        return ctrl.Result{}, client.IgnoreNotFound(err)\n    }\n\n    // Get project to check network type\n    project := r.getProjectForNamespace(ctx, route.Namespace)\n    if project == nil {\n        return ctrl.Result{}, nil\n    }\n\n    // Only apply Backend workaround for cloud networking\n    // Public network routes directly - no patching needed\n    if project.Spec.ExternalNetworkType != \"cloud\" {\n        return ctrl.Result{}, nil\n    }\n\n    // Check if already patched (backendRef is Backend, not Service)\n    if r.isAlreadyPatched(route) {\n        return ctrl.Result{}, nil\n    }\n\n    // Get the solver service name from backendRef\n    serviceName := r.getServiceNameFromRoute(route)\n    if serviceName == \"\" {\n        return ctrl.Result{}, nil\n    }\n\n    // Check if Backend exists\n    backendName := serviceName + \"-backend\"\n    backend := &amp;egv1alpha1.Backend{}\n    if err := r.Get(ctx, types.NamespacedName{\n        Name:      backendName,\n        Namespace: route.Namespace,\n    }, backend); err != nil {\n        // Backend not ready yet, requeue\n        return ctrl.Result{RequeueAfter: 2 * time.Second}, nil\n    }\n\n    // Patch HTTPRoute to use Backend instead of Service\n    patch := client.MergeFrom(route.DeepCopy())\n    r.patchBackendRefs(route, backendName)\n\n    if err := r.Patch(ctx, route, patch); err != nil {\n        return ctrl.Result{}, err\n    }\n\n    return ctrl.Result{}, nil\n}\n\nfunc (r *HTTPRouteReconciler) patchBackendRefs(route *gatewayv1.HTTPRoute, backendName string) {\n    group := gatewayv1.Group(\"gateway.envoyproxy.io\")\n    kind := gatewayv1.Kind(\"Backend\")\n\n    for i, rule := range route.Spec.Rules {\n        for j, ref := range rule.BackendRefs {\n            if ref.Kind == nil || *ref.Kind == \"Service\" {\n                route.Spec.Rules[i].BackendRefs[j].Group = &amp;group\n                route.Spec.Rules[i].BackendRefs[j].Kind = &amp;kind\n                route.Spec.Rules[i].BackendRefs[j].Name = gatewayv1.ObjectName(backendName)\n            }\n        }\n    }\n}\n</code></pre></p> <p>Controller Setup: <pre><code>func (r *HTTPRouteReconciler) SetupWithManager(mgr ctrl.Manager) error {\n    return ctrl.NewControllerManagedBy(mgr).\n        For(&amp;gatewayv1.HTTPRoute{}).\n        WithEventFilter(predicate.Funcs{\n            CreateFunc: func(e event.CreateEvent) bool {\n                return isACMEHTTPRoute(e.Object)\n            },\n            UpdateFunc: func(e event.UpdateEvent) bool {\n                return isACMEHTTPRoute(e.ObjectNew)\n            },\n        }).\n        Complete(r)\n}\n</code></pre></p>"},{"location":"prd/acme_challenge_http_route/#timing-considerations","title":"Timing Considerations","text":"<p>Race Condition: HTTPRoute may be created before Backend exists.</p> <p>Controller Solution: The controller uses <code>RequeueAfter</code> to handle timing:</p> <ol> <li>HTTPRoute created by cert-manager</li> <li>Controller detects HTTPRoute, checks for Backend</li> <li>If Backend doesn't exist yet \u2192 <code>RequeueAfter: 2 * time.Second</code></li> <li>Controller retries until Backend is ready</li> <li>Once Backend exists, controller patches HTTPRoute</li> </ol> <p>This is more robust than webhook approach because: - No blocking of API requests - Automatic retries with exponential backoff - cert-manager doesn't see any errors (HTTPRoute created successfully) - Controller handles the eventual consistency</p>"},{"location":"prd/acme_challenge_http_route/#customer-experience","title":"Customer Experience","text":""},{"location":"prd/acme_challenge_http_route/#before-manual-process","title":"Before (Manual Process)","text":"<ol> <li>Create namespace-scoped Issuer with DNS-01 (requires DNS API access)</li> <li>OR use external certificate provider</li> <li>Manually manage certificate renewal</li> </ol>"},{"location":"prd/acme_challenge_http_route/#after-automated","title":"After (Automated)","text":"<ol> <li>Create namespace-scoped Issuer with HTTP-01 (standard Let's Encrypt)</li> <li>Create Certificate resource</li> <li>Automatic issuance and renewal via shared Gateway</li> </ol>"},{"location":"prd/acme_challenge_http_route/#end-to-end-customer-flow","title":"End-to-End Customer Flow","text":""},{"location":"prd/acme_challenge_http_route/#step-1-initial-setup-one-time","title":"Step 1: Initial Setup (One-time)","text":"<p>Customer creates their application with TLS termination:</p> <pre><code># Application with nginx for TLS termination\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  namespace: customer-project\nspec:\n  template:\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:alpine\n        volumeMounts:\n        - name: tls\n          mountPath: /etc/nginx/ssl\n      volumes:\n      - name: tls\n        secret:\n          secretName: my-app-tls  # Will be created by cert-manager\n---\n# Service with ext-cloud IP (no public IP)\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\n  namespace: customer-project\n  annotations:\n    ovn.kubernetes.io/service_external_ip_from_subnet: ext-cloud\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 443\n    targetPort: 443\n</code></pre>"},{"location":"prd/acme_challenge_http_route/#step-2-certificate-request","title":"Step 2: Certificate Request","text":"<pre><code># Issuer (points to shared gateway for HTTP-01)\napiVersion: cert-manager.io/v1\nkind: Issuer\nmetadata:\n  name: letsencrypt\n  namespace: customer-project\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: admin@customer.com\n    privateKeySecretRef:\n      name: letsencrypt-account-key\n    solvers:\n    - http01:\n        gatewayHTTPRoute:\n          parentRefs:\n          - name: shared-gateway\n            namespace: gateway-system\n---\n# Certificate\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: my-app-tls\n  namespace: customer-project\nspec:\n  secretName: my-app-tls\n  issuerRef:\n    name: letsencrypt\n  dnsNames:\n  - my-app.customer.example.com\n</code></pre>"},{"location":"prd/acme_challenge_http_route/#step-3-automatic-acme-challenge-our-controller","title":"Step 3: Automatic ACME Challenge (Our Controller)","text":"<pre><code>1. cert-manager creates solver pod + service\n2. [Controller] Creates EIP + Backend for solver\n3. [Webhook] Mutates HTTPRoute to use Backend\n4. ACME challenge succeeds\n5. Certificate issued to customer namespace\n6. [Controller] Cleans up solver EIP + Backend\n</code></pre>"},{"location":"prd/acme_challenge_http_route/#step-4-tlsroute-for-production-traffic","title":"Step 4: TLSRoute for Production Traffic","text":"<pre><code># Backend pointing to customer service ext-cloud IP\napiVersion: gateway.envoyproxy.io/v1alpha1\nkind: Backend\nmetadata:\n  name: my-app-backend\n  namespace: customer-project\nspec:\n  endpoints:\n  - ip:\n      address: 100.65.0.50  # Customer's ext-cloud IP\n      port: 443\n---\n# TLSRoute through shared gateway (passthrough)\napiVersion: gateway.networking.k8s.io/v1alpha2\nkind: TLSRoute\nmetadata:\n  name: my-app\n  namespace: customer-project\nspec:\n  parentRefs:\n  - name: shared-gateway\n    namespace: gateway-system\n  hostnames:\n  - \"my-app.customer.example.com\"\n  rules:\n  - backendRefs:\n    - group: gateway.envoyproxy.io\n      kind: Backend\n      name: my-app-backend\n      port: 443\n</code></pre>"},{"location":"prd/acme_challenge_http_route/#result","title":"Result","text":"<pre><code>User browser\n    \u2193\nhttps://my-app.customer.example.com\n    \u2193\nShared Gateway (88.99.29.250:443)\n    \u2193 TLS passthrough (SNI routing)\nCustomer Service (100.65.0.50:443)\n    \u2193 TLS termination with Let's Encrypt cert\nApplication\n</code></pre> <p>Customer uses 0 public IPs, gets valid Let's Encrypt certificate.</p>"},{"location":"prd/acme_challenge_http_route/#example-customer-resources","title":"Example Customer Resources","text":"<pre><code># 1. Issuer (customer creates)\napiVersion: cert-manager.io/v1\nkind: Issuer\nmetadata:\n  name: letsencrypt\n  namespace: my-project\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: admin@example.com\n    privateKeySecretRef:\n      name: letsencrypt-account-key\n    solvers:\n    - http01:\n        gatewayHTTPRoute:\n          parentRefs:\n          - name: shared-gateway\n            namespace: gateway-system\n---\n# 2. Certificate (customer creates)\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: my-app-tls\n  namespace: my-project\nspec:\n  secretName: my-app-tls-secret\n  issuerRef:\n    name: letsencrypt\n  dnsNames:\n  - my-app.example.com\n</code></pre> <p>Everything else (EIP, Backend, HTTPRoute mutation) happens automatically.</p>"},{"location":"prd/acme_challenge_http_route/#complexity-assessment","title":"Complexity Assessment","text":"Component Complexity Effort Status Gateway Backend auto-creation Low 1 day \u2705 Done (commit <code>dac0122</code>) ACME Solver Service detection Low 1 day \ud83d\udd32 Pending HTTPRoute Controller Low 1-2 days \ud83d\udd32 Pending Testing Medium 2-3 days E2E with Let's Encrypt staging Total Remaining 4-6 days"},{"location":"prd/acme_challenge_http_route/#current-gateway-setup","title":"Current Gateway Setup","text":"<p>Shared Envoy Gateway: Single gateway shared across all projects.</p> <pre><code>Gateway: eg (envoy-gateway-system)\nAddress: 88.99.29.250\n</code></pre> <p>Listeners: | Port | Protocol | Purpose | Allowed Routes | |------|----------|---------|----------------| | 80 | HTTP | ACME challenges, HTTP\u2192HTTPS redirect | All namespaces | | 443 | HTTPS | Per-host TLS termination (platform services) | All namespaces | | 6443 | TLS | Passthrough for tenant K8s APIs | All namespaces |</p> <p>Key Design: - Single Gateway - All projects share one gateway IP - All namespaces allowed - Projects can create HTTPRoutes/TLSRoutes in their namespace - HTTP :80 available - ACME HTTP-01 challenges can use this listener - TLS Passthrough :6443 - Tenant clusters use Backend \u2192 ext-cloud IP pattern</p>"},{"location":"prd/acme_challenge_http_route/#prerequisites","title":"Prerequisites","text":"<ol> <li>\u2705 cert-manager installed with Gateway API support</li> <li>\u2705 Shared Gateway with HTTP listener (port 80)</li> <li>\u2705 Gateway allows routes from all namespaces</li> <li>\u2705 Envoy Gateway deployed (replaces nginx-ingress)</li> <li>\u2705 DNS pointing to Gateway IP (88.99.29.250)</li> </ol>"},{"location":"prd/acme_challenge_http_route/#risks-and-mitigations","title":"Risks and Mitigations","text":"Risk Mitigation EIP exhaustion Solver uses project's default-gw EIP (shared, no new EIP) Controller timing RequeueAfter handles eventual consistency cert-manager version changes Watch cert-manager release notes for HTTPRoute changes Stale Backends OwnerReferences ensure cleanup when solver Service deleted"},{"location":"prd/acme_challenge_http_route/#alternatives-considered","title":"Alternatives Considered","text":"Alternative Pros Cons Decision Mutating Webhook Immediate mutation Latency, TLS certs, complex failure modes \u274c Rejected Controller-based Eventual consistency, simpler Slight delay \u2705 Chosen DNS-01 challenge No HTTP routing Requires customer DNS API access For advanced users Per-project Gateway Full isolation More resources, more EIPs Not scalable"},{"location":"prd/acme_challenge_http_route/#success-criteria","title":"Success Criteria","text":"<ol> <li>Customer can issue Let's Encrypt certificates using HTTP-01 challenge</li> <li>Certificates automatically renew without customer intervention</li> <li>No manual EIP/Backend management required</li> <li>Works with shared Gateway across multiple projects</li> <li>Proper cleanup when challenges complete</li> </ol>"},{"location":"prd/acme_challenge_http_route/#implementation-order","title":"Implementation Order","text":"<ol> <li>Replace nginx-ingress with Envoy Gateway (external task)</li> <li>Move HTTP :80 and HTTPS :443 to Envoy Gateway</li> <li>Update DNS records</li> <li> <p>Verify existing routes work</p> </li> <li> <p>Implement ACME Solver Service detection</p> </li> <li>Add predicate for <code>acme.cert-manager.io/http01-solver</code> label</li> <li>Auto-patch ClusterIP \u2192 LoadBalancer with annotations</li> <li> <p>Test with manual Certificate creation</p> </li> <li> <p>Implement HTTPRoute Controller</p> </li> <li>Add HTTPRoute reconciler</li> <li>Watch for ACME HTTPRoutes</li> <li>Patch backendRef Service \u2192 Backend</li> <li> <p>Test end-to-end with Let's Encrypt staging</p> </li> <li> <p>E2E Testing</p> </li> <li>Test with Let's Encrypt staging environment</li> <li>Verify certificate issuance and renewal</li> <li>Test cleanup after challenge completion</li> </ol>"},{"location":"prd/acme_challenge_http_route/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Rate limiting: Limit concurrent ACME challenges per project</li> <li>Metrics: Track challenge success/failure rates</li> <li>Alerts: Notify on certificate expiration</li> <li>ClusterIssuer support: Platform-wide issuer for all projects</li> </ol>"},{"location":"prd/cloud_current_network/","title":"Current OVN Network Architecture","text":""},{"location":"prd/cloud_current_network/#overview","title":"Overview","text":"<p>This document provides a complete view of the current OVN-based network architecture in the kube-dc management cluster, including VPCs, subnets, EIPs, service exposure, and Envoy Gateway integration.</p>"},{"location":"prd/cloud_current_network/#physical-network-layer","title":"Physical Network Layer","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         PHYSICAL NETWORK                                     \u2502\n\u2502                                                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502      VLAN 4011          \u2502              \u2502      VLAN 4013          \u2502       \u2502\n\u2502  \u2502      ext-public         \u2502              \u2502      ext-cloud          \u2502       \u2502\n\u2502  \u2502   168.119.17.48/28      \u2502              \u2502   100.65.0.0/16         \u2502       \u2502\n\u2502  \u2502                         \u2502              \u2502                         \u2502       \u2502\n\u2502  \u2502   Gateway: 168.119.17.49\u2502              \u2502   Gateway: 100.65.0.1   \u2502       \u2502\n\u2502  \u2502   Internet-routable \u2705  \u2502              \u2502   Internal-only \u274c      \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502              \u2502                                        \u2502                      \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2502                               \u2502                                              \u2502\n\u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                    \u2502\n\u2502                     \u2502   Provider Bridge  \u2502                                    \u2502\n\u2502                     \u2502   br-ext-cloud     \u2502                                    \u2502\n\u2502                     \u2502   (on each node)   \u2502                                    \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              OVN NETWORK                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_current_network/#ovn-logical-network-architecture","title":"OVN Logical Network Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                    OVN LOGICAL NETWORK                                           \u2502\n\u2502                                                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                              ovn-cluster VPC (Management)                                   \u2502 \u2502\n\u2502  \u2502                                                                                             \u2502 \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502\n\u2502  \u2502   \u2502   ovn-default   \u2502    \u2502    ext-cloud    \u2502    \u2502   ext-public    \u2502    \u2502     join      \u2502  \u2502 \u2502\n\u2502  \u2502   \u2502  10.100.0.0/16  \u2502    \u2502  100.65.0.0/16  \u2502    \u2502168.119.17.48/28 \u2502    \u2502 172.30.0.0/22 \u2502  \u2502 \u2502\n\u2502  \u2502   \u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502    \u2502               \u2502  \u2502 \u2502\n\u2502  \u2502   \u2502 \u2022 kube-system   \u2502    \u2502 \u2022 LB VIPs       \u2502    \u2502 \u2022 Public LB VIPs\u2502    \u2502 \u2022 Node IPs    \u2502  \u2502 \u2502\n\u2502  \u2502   \u2502 \u2022 kamaji-system \u2502    \u2502 \u2022 Cloud EIPs    \u2502    \u2502 \u2022 Public EIPs   \u2502    \u2502 \u2022 kube-proxy  \u2502  \u2502 \u2502\n\u2502  \u2502   \u2502 \u2022 envoy-gateway \u2502    \u2502                 \u2502    \u2502                 \u2502    \u2502   SNAT        \u2502  \u2502 \u2502\n\u2502  \u2502   \u2502 \u2022 ingress-nginx \u2502    \u2502                 \u2502    \u2502                 \u2502    \u2502               \u2502  \u2502 \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502\n\u2502  \u2502            \u2502                      \u2502                      \u2502                     \u2502          \u2502 \u2502\n\u2502  \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502 \u2502\n\u2502  \u2502                                   \u2502                      \u2502                                \u2502 \u2502\n\u2502  \u2502                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502 \u2502\n\u2502  \u2502                         \u2502         ovn-cluster Router               \u2502                      \u2502 \u2502\n\u2502  \u2502                         \u2502                                          \u2502                      \u2502 \u2502\n\u2502  \u2502                         \u2502  Ports:                                  \u2502                      \u2502 \u2502\n\u2502  \u2502                         \u2502  \u2022 ovn-cluster-ovn-default: 10.100.0.1   \u2502                      \u2502 \u2502\n\u2502  \u2502                         \u2502  \u2022 ovn-cluster-ext-cloud: 100.65.0.101   \u2502                      \u2502 \u2502\n\u2502  \u2502                         \u2502  \u2022 ovn-cluster-join: 172.30.0.1          \u2502                      \u2502 \u2502\n\u2502  \u2502                         \u2502                                          \u2502                      \u2502 \u2502\n\u2502  \u2502                         \u2502  SNAT: 10.100.0.0/16 \u2192 100.65.0.101      \u2502                      \u2502 \u2502\n\u2502  \u2502                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502  \u2502     shalb-demo VPC (Project)    \u2502  \u2502     shalb-dev VPC (Project)     \u2502                       \u2502\n\u2502  \u2502                                 \u2502  \u2502                                 \u2502                       \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502                       \u2502\n\u2502  \u2502   \u2502  shalb-demo-default     \u2502   \u2502  \u2502   \u2502  shalb-dev-default      \u2502   \u2502                       \u2502\n\u2502  \u2502   \u2502     10.0.10.0/24        \u2502   \u2502  \u2502   \u2502     10.1.0.0/16         \u2502   \u2502                       \u2502\n\u2502  \u2502   \u2502                         \u2502   \u2502  \u2502   \u2502                         \u2502   \u2502                       \u2502\n\u2502  \u2502   \u2502  \u2022 Customer pods        \u2502   \u2502  \u2502   \u2502  \u2022 Customer pods        \u2502   \u2502                       \u2502\n\u2502  \u2502   \u2502  \u2022 test-http-app        \u2502   \u2502  \u2502   \u2502  \u2022 Development workloads\u2502   \u2502                       \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502                       \u2502\n\u2502  \u2502               \u2502                 \u2502  \u2502               \u2502                 \u2502                       \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502                       \u2502\n\u2502  \u2502   \u2502  shalb-demo Router      \u2502   \u2502  \u2502   \u2502  shalb-dev Router       \u2502   \u2502                       \u2502\n\u2502  \u2502   \u2502                         \u2502   \u2502  \u2502   \u2502                         \u2502   \u2502                       \u2502\n\u2502  \u2502   \u2502  ext-cloud: 100.65.0.102\u2502   \u2502  \u2502   \u2502  ext-public:168.119.17.51\u2502  \u2502                       \u2502\n\u2502  \u2502   \u2502  SNAT: 10.0.10.0/24     \u2502   \u2502  \u2502   \u2502  ext-cloud: (via extra) \u2502   \u2502                       \u2502\n\u2502  \u2502   \u2502       \u2192 100.65.0.102    \u2502   \u2502  \u2502   \u2502  SNAT: 10.1.0.0/16      \u2502   \u2502                       \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502   \u2502       \u2192 168.119.17.51   \u2502   \u2502                       \u2502\n\u2502  \u2502                                 \u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502                       \u2502\n\u2502  \u2502   extraExternalSubnets: []      \u2502  \u2502   extraExternalSubnets:         \u2502                       \u2502\n\u2502  \u2502   Default GW: ext-cloud         \u2502  \u2502   [ext-cloud, ext-public]       \u2502                       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                                                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                            \u2502\n\u2502  \u2502    shalb-envoy VPC (Project)    \u2502                                                            \u2502\n\u2502  \u2502                                 \u2502                                                            \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502                                                            \u2502\n\u2502  \u2502   \u2502  shalb-envoy-default    \u2502   \u2502                                                            \u2502\n\u2502  \u2502   \u2502     10.0.40.0/24        \u2502   \u2502                                                            \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502                                                            \u2502\n\u2502  \u2502               \u2502                 \u2502                                                            \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502                                                            \u2502\n\u2502  \u2502   \u2502  shalb-envoy Router     \u2502   \u2502                                                            \u2502\n\u2502  \u2502   \u2502                         \u2502   \u2502                                                            \u2502\n\u2502  \u2502   \u2502  ext-public:168.119.17.52\u2502  \u2502                                                            \u2502\n\u2502  \u2502   \u2502  SNAT: 10.0.40.0/24     \u2502   \u2502                                                            \u2502\n\u2502  \u2502   \u2502       \u2192 168.119.17.52   \u2502   \u2502                                                            \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502                                                            \u2502\n\u2502  \u2502                                 \u2502                                                            \u2502\n\u2502  \u2502   extraExternalSubnets:         \u2502                                                            \u2502\n\u2502  \u2502   [ext-public]                  \u2502                                                            \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_current_network/#vpc-and-subnet-summary","title":"VPC and Subnet Summary","text":""},{"location":"prd/cloud_current_network/#vpcs","title":"VPCs","text":"VPC Purpose Namespaces External Subnets Default GW <code>ovn-cluster</code> Management cluster kube-system, kamaji-system, envoy-gateway-system ext-cloud, ext-public N/A <code>shalb-demo</code> Customer project shalb-demo ext-cloud (default) 100.65.0.1 <code>shalb-dev</code> Customer project shalb-dev ext-cloud, ext-public 168.119.17.49 <code>shalb-envoy</code> Customer project shalb-envoy ext-public 168.119.17.49"},{"location":"prd/cloud_current_network/#subnets","title":"Subnets","text":"Subnet VPC CIDR VLAN Purpose <code>ovn-default</code> ovn-cluster 10.100.0.0/16 - Management pods <code>ext-cloud</code> ovn-cluster 100.65.0.0/16 4013 Cloud LB VIPs <code>ext-public</code> ovn-cluster 168.119.17.48/28 4011 Public LB VIPs <code>join</code> ovn-cluster 172.30.0.0/22 - Node-to-OVN connectivity <code>shalb-demo-default</code> shalb-demo 10.0.10.0/24 - Customer pods <code>shalb-dev-default</code> shalb-dev 10.1.0.0/16 - Customer pods <code>shalb-envoy-default</code> shalb-envoy 10.0.40.0/24 - Customer pods"},{"location":"prd/cloud_current_network/#join-subnet-and-node-connectivity","title":"Join Subnet and Node Connectivity","text":"<p>The <code>join</code> subnet (172.30.0.0/22) connects Kubernetes nodes to the OVN network:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           NODE NETWORKING                                 \u2502\n\u2502                                                                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                    kube-dc-worker-1                                  \u2502 \u2502\n\u2502  \u2502                                                                      \u2502 \u2502\n\u2502  \u2502   Physical Interfaces:                                               \u2502 \u2502\n\u2502  \u2502   \u2022 br-ext-cloud: 138.201.132.165/26 (provider bridge)              \u2502 \u2502\n\u2502  \u2502   \u2022 enp0s31f6.4012: 192.168.1.4 (internal VLAN)                     \u2502 \u2502\n\u2502  \u2502                                                                      \u2502 \u2502\n\u2502  \u2502   OVN Interfaces:                                                    \u2502 \u2502\n\u2502  \u2502   \u2022 ovn0: 172.30.0.2/22 (join subnet - node IP)                     \u2502 \u2502\n\u2502  \u2502                                                                      \u2502 \u2502\n\u2502  \u2502   Routes:                                                            \u2502 \u2502\n\u2502  \u2502   \u2022 10.100.0.0/16 via 172.30.0.1 dev ovn0 (pod network)             \u2502 \u2502\n\u2502  \u2502   \u2022 default via 138.201.132.129 dev br-ext-cloud (internet)         \u2502 \u2502\n\u2502  \u2502                                                                      \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                           \u2502\n\u2502              \u2502                                                            \u2502\n\u2502              \u2502 ovn0 (172.30.0.2)                                          \u2502\n\u2502              \u2502                                                            \u2502\n\u2502              \u25bc                                                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                      OVN Join Switch                                 \u2502 \u2502\n\u2502  \u2502                      172.30.0.0/22                                   \u2502 \u2502\n\u2502  \u2502                                                                      \u2502 \u2502\n\u2502  \u2502   Connected to:                                                      \u2502 \u2502\n\u2502  \u2502   \u2022 ovn-cluster router (172.30.0.1) - gateway to OVN network        \u2502 \u2502\n\u2502  \u2502   \u2022 All nodes (172.30.0.x)                                          \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_current_network/#join-subnet-role","title":"Join Subnet Role","text":"<ol> <li>Node Registration: Each node gets an IP on the join subnet (172.30.0.x)</li> <li>Pod Network Access: Nodes route pod traffic (10.100.x.x) via join subnet gateway (172.30.0.1)</li> <li>kube-proxy SNAT: When external traffic arrives via externalIPs, kube-proxy SNATs to 172.30.0.x</li> </ol>"},{"location":"prd/cloud_current_network/#eip-external-ip-resources","title":"EIP (External IP) Resources","text":""},{"location":"prd/cloud_current_network/#eip-types","title":"EIP Types","text":"Type Network Purpose Internet Routable <code>cloud</code> ext-cloud (100.65.x.x) Internal services, Kamaji, etcd \u274c No <code>public</code> ext-public (168.119.x.x) Public-facing services \u2705 Yes"},{"location":"prd/cloud_current_network/#current-eips","title":"Current EIPs","text":"Namespace EIP Name IP Type Usage shalb-demo default-gw 100.65.0.102 cloud SNAT for project shalb-demo slb-test-http-app-bc6y7 100.65.0.112 cloud LoadBalancer service shalb-demo demo-cluster-api-eip 100.65.0.105 cloud Kamaji control plane shalb-demo mt-api-eip 100.65.0.108 cloud MT control plane shalb-dev default-gw 168.119.17.51 public SNAT for project shalb-dev bohdan-prod-eip 168.119.17.57 public FIP shalb-envoy default-gw 168.119.17.52 public SNAT for project"},{"location":"prd/cloud_current_network/#service-loadbalancer-architecture","title":"Service LoadBalancer Architecture","text":""},{"location":"prd/cloud_current_network/#loadbalancer-service-flow","title":"LoadBalancer Service Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     SERVICE LOADBALANCER ARCHITECTURE                                 \u2502\n\u2502                                                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                    LoadBalancer Service Creation                               \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   apiVersion: v1                                                               \u2502  \u2502\n\u2502   \u2502   kind: Service                                                                \u2502  \u2502\n\u2502   \u2502   metadata:                                                                    \u2502  \u2502\n\u2502   \u2502     name: test-http-app                                                        \u2502  \u2502\n\u2502   \u2502     namespace: shalb-demo                                                      \u2502  \u2502\n\u2502   \u2502     annotations:                                                               \u2502  \u2502\n\u2502   \u2502       service.nlb.kube-dc.com/bind-on-eip: default-gw                         \u2502  \u2502\n\u2502   \u2502       gateway.kube-dc.com/create-backend: \"true\"  # Optional: creates Backend \u2502  \u2502\n\u2502   \u2502   spec:                                                                        \u2502  \u2502\n\u2502   \u2502     type: LoadBalancer                                                         \u2502  \u2502\n\u2502   \u2502     ports:                                                                     \u2502  \u2502\n\u2502   \u2502       - port: 80                                                               \u2502  \u2502\n\u2502   \u2502     selector:                                                                  \u2502  \u2502\n\u2502   \u2502       app: test-http-app                                                       \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                        \u2502                                              \u2502\n\u2502                                        \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                    Service Controller (kube-dc)                                \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   1. Allocate EIP (if not exists)                                             \u2502  \u2502\n\u2502   \u2502      \u2192 Creates EIp resource                                                    \u2502  \u2502\n\u2502   \u2502      \u2192 Creates OvnEip resource                                                 \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   2. Create OVN LoadBalancer                                                   \u2502  \u2502\n\u2502   \u2502      \u2192 VIP: 100.65.0.112:80                                                    \u2502  \u2502\n\u2502   \u2502      \u2192 Backends: 10.0.10.28:80 (pod IPs)                                       \u2502  \u2502\n\u2502   \u2502      \u2192 Attach to VPC router                                                    \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   3. Create External Service + Endpoints                                       \u2502  \u2502\n\u2502   \u2502      \u2192 test-http-app-ext (headless)                                            \u2502  \u2502\n\u2502   \u2502      \u2192 Endpoints: 100.65.0.112:80                                              \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   4. Create Gateway Backend (if annotated)                                     \u2502  \u2502\n\u2502   \u2502      \u2192 test-http-app-backend                                                   \u2502  \u2502\n\u2502   \u2502      \u2192 Endpoint: 100.65.0.112:80                                               \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                        \u2502                                              \u2502\n\u2502                                        \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                        Created Resources                                       \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502  \u2502\n\u2502   \u2502   \u2502      EIp        \u2502  \u2502    OvnEip       \u2502  \u2502  OVN LB         \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502                 \u2502  \u2502                 \u2502  \u2502                 \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502 slb-test-http-  \u2502  \u2502 eip-slb-test-   \u2502  \u2502 VIP:            \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502 app-bc6y7       \u2502  \u2502 http-app-bc6y7  \u2502  \u2502 100.65.0.112:80 \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502                 \u2502  \u2502                 \u2502  \u2502                 \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502 IP: 100.65.0.112\u2502  \u2502 V4IP:           \u2502  \u2502 Backends:       \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502 Type: cloud     \u2502  \u2502 100.65.0.112    \u2502  \u2502 10.0.10.28:80   \u2502               \u2502  \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502  \u2502\n\u2502   \u2502   \u2502 Service -ext    \u2502  \u2502  Endpoints -ext \u2502  \u2502 Backend (GW API)\u2502               \u2502  \u2502\n\u2502   \u2502   \u2502                 \u2502  \u2502                 \u2502  \u2502                 \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502 test-http-app-  \u2502  \u2502 test-http-app-  \u2502  \u2502 test-http-app-  \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502 ext             \u2502  \u2502 ext             \u2502  \u2502 backend         \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502                 \u2502  \u2502                 \u2502  \u2502                 \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502 ClusterIP: None \u2502  \u2502 IP:             \u2502  \u2502 Endpoint:       \u2502               \u2502  \u2502\n\u2502   \u2502   \u2502 (headless)      \u2502  \u2502 100.65.0.112    \u2502  \u2502 100.65.0.112:80 \u2502               \u2502  \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_current_network/#-ext-service-purpose","title":"-ext Service Purpose","text":"<p>The <code>-ext</code> suffix services provide a way for other components to discover the external LoadBalancer IP:</p> <pre><code># Original Service\napiVersion: v1\nkind: Service\nmetadata:\n  name: test-http-app\n  namespace: shalb-demo\nspec:\n  type: LoadBalancer\n  clusterIP: 10.101.61.188\n  ports:\n    - port: 80\n  selector:\n    app: test-http-app\nstatus:\n  loadBalancer:\n    ingress:\n      - ip: 100.65.0.112\n\n---\n# Auto-created -ext Service (headless)\napiVersion: v1\nkind: Service\nmetadata:\n  name: test-http-app-ext\n  namespace: shalb-demo\n  labels:\n    kube-dc.com/endpoint-type: external\n    kube-dc.com/managed-by: service-lb-controller\n    kube-dc.com/source-service: test-http-app\nspec:\n  clusterIP: None  # Headless\n  ports:\n    - name: http\n      port: 80\n\n---\n# Auto-created Endpoints\napiVersion: v1\nkind: Endpoints\nmetadata:\n  name: test-http-app-ext\n  namespace: shalb-demo\nsubsets:\n  - addresses:\n      - ip: 100.65.0.112  # External LB IP\n    ports:\n      - name: http\n        port: 80\n</code></pre>"},{"location":"prd/cloud_current_network/#envoy-gateway-architecture","title":"Envoy Gateway Architecture","text":""},{"location":"prd/cloud_current_network/#current-deployment","title":"Current Deployment","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         ENVOY GATEWAY ARCHITECTURE                                    \u2502\n\u2502                                                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                    envoy-gateway-system namespace                              \u2502  \u2502\n\u2502   \u2502                    (in ovn-default subnet: 10.100.0.0/16)                      \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502   \u2502   \u2502  Envoy Gateway         \u2502     \u2502  Envoy Proxy Pod                       \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  Controller            \u2502     \u2502                                        \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502                        \u2502     \u2502  Pod IP: 10.100.0.250                  \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  \u2022 Watches Gateway,    \u2502     \u2502                                        \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502    HTTPRoute, TLSRoute \u2502     \u2502  Listens on:                           \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  \u2022 Configures Envoy    \u2502     \u2502  \u2022 7443 (TLS passthrough)              \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502    proxy               \u2502     \u2502  \u2022 8080 (HTTP)                         \u2502   \u2502  \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502                                        \u2502   \u2502  \u2502\n\u2502   \u2502                                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502   \u2502                                                   \u2502                           \u2502  \u2502\n\u2502   \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502   \u2502   \u2502  Service: envoy-envoy-gateway-system-eg-tls-passthrough-24835ac8      \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502                                                                        \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  Type: ClusterIP                                                       \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  ClusterIP: 10.101.148.184                                             \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  externalIPs: [88.99.29.250]  \u25c4\u2500\u2500 Shared with nginx-ingress            \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502                                                                        \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  Ports:                                                                \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  \u2022 7443 \u2192 7443 (TLS passthrough)                                       \u2502   \u2502  \u2502\n\u2502   \u2502   \u2502  \u2022 8080 \u2192 8080 (HTTP)                                                  \u2502   \u2502  \u2502\n\u2502   \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                                       \u2502\n\u2502                                        \u2502                                              \u2502\n\u2502                                        \u2502 externalIPs: 88.99.29.250                    \u2502\n\u2502                                        \u2502                                              \u2502\n\u2502                                        \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                         EXTERNAL TRAFFIC FLOW                                  \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   Internet Client (88.99.218.47)                                               \u2502  \u2502\n\u2502   \u2502         \u2502                                                                      \u2502  \u2502\n\u2502   \u2502         \u25bc                                                                      \u2502  \u2502\n\u2502   \u2502   Node External IP (88.99.29.250:7443)                                         \u2502  \u2502\n\u2502   \u2502         \u2502                                                                      \u2502  \u2502\n\u2502   \u2502         \u25bc kube-proxy intercepts                                                \u2502  \u2502\n\u2502   \u2502         \u2502 SNAT: src 88.99.218.47 \u2192 172.30.0.2 (join IP) \u25c4\u2500\u2500 CLIENT IP LOST!   \u2502  \u2502\n\u2502   \u2502         \u2502                                                                      \u2502  \u2502\n\u2502   \u2502         \u25bc                                                                      \u2502  \u2502\n\u2502   \u2502   Envoy Pod (10.100.0.250:7443)                                                \u2502  \u2502\n\u2502   \u2502         \u2502 Sees client IP: 172.30.0.2 \u274c                                        \u2502  \u2502\n\u2502   \u2502         \u2502                                                                      \u2502  \u2502\n\u2502   \u2502         \u25bc Routes via HTTPRoute/TLSRoute                                        \u2502  \u2502\n\u2502   \u2502   Backend (via Backend resource or Service)                                    \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_current_network/#gateway-api-resources","title":"Gateway API Resources","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         GATEWAY API RESOURCE HIERARCHY                                \u2502\n\u2502                                                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                    GatewayClass (cluster-scoped)                               \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   name: eg                                                                     \u2502  \u2502\n\u2502   \u2502   controller: gateway.envoyproxy.io/gatewayclass-controller                   \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                        \u2502                                              \u2502\n\u2502                                        \u25bc                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502                    Gateway (envoy-gateway-system/eg-tls-passthrough)           \u2502  \u2502\n\u2502   \u2502                                                                                \u2502  \u2502\n\u2502   \u2502   spec:                                                                        \u2502  \u2502\n\u2502   \u2502     gatewayClassName: eg                                                       \u2502  \u2502\n\u2502   \u2502     listeners:                                                                 \u2502  \u2502\n\u2502   \u2502       - name: tls                                                              \u2502  \u2502\n\u2502   \u2502         port: 7443                                                             \u2502  \u2502\n\u2502   \u2502         protocol: TLS                                                          \u2502  \u2502\n\u2502   \u2502         tls:                                                                   \u2502  \u2502\n\u2502   \u2502           mode: Passthrough                                                    \u2502  \u2502\n\u2502   \u2502       - name: http                                                             \u2502  \u2502\n\u2502   \u2502         port: 8080                                                             \u2502  \u2502\n\u2502   \u2502         protocol: HTTP                                                         \u2502  \u2502\n\u2502   \u2502   status:                                                                      \u2502  \u2502\n\u2502   \u2502     addresses:                                                                 \u2502  \u2502\n\u2502   \u2502       - value: 10.101.148.184                                                  \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                        \u2502                                              \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502                    \u2502                                       \u2502                         \u2502\n\u2502                    \u25bc                                       \u25bc                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502   \u2502  TLSRoute (shalb-demo/demo-    \u2502   \u2502  HTTPRoute (shalb-demo/test-   \u2502            \u2502\n\u2502   \u2502  cluster)                      \u2502   \u2502  http-app)                     \u2502            \u2502\n\u2502   \u2502                                \u2502   \u2502                                \u2502            \u2502\n\u2502   \u2502  hostnames:                    \u2502   \u2502  hostnames:                    \u2502            \u2502\n\u2502   \u2502  - demo-cluster.stage.kube-   \u2502   \u2502  - test-http-app.stage.kube-  \u2502            \u2502\n\u2502   \u2502    dc.com                      \u2502   \u2502    dc.com                      \u2502            \u2502\n\u2502   \u2502                                \u2502   \u2502                                \u2502            \u2502\n\u2502   \u2502  backendRefs:                  \u2502   \u2502  backendRefs:                  \u2502            \u2502\n\u2502   \u2502  - name: demo-cluster-backend  \u2502   \u2502  - name: test-http-app-backend \u2502            \u2502\n\u2502   \u2502    kind: Backend               \u2502   \u2502    kind: Backend               \u2502            \u2502\n\u2502   \u2502    group: gateway.envoyproxy.io\u2502   \u2502    group: gateway.envoyproxy.io\u2502            \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                    \u2502                                       \u2502                         \u2502\n\u2502                    \u25bc                                       \u25bc                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502   \u2502  Backend (shalb-demo/demo-     \u2502   \u2502  Backend (shalb-demo/test-     \u2502            \u2502\n\u2502   \u2502  cluster-backend)              \u2502   \u2502  http-app-backend)             \u2502            \u2502\n\u2502   \u2502                                \u2502   \u2502                                \u2502            \u2502\n\u2502   \u2502  spec:                         \u2502   \u2502  spec:                         \u2502            \u2502\n\u2502   \u2502    endpoints:                  \u2502   \u2502    endpoints:                  \u2502            \u2502\n\u2502   \u2502    - ip:                       \u2502   \u2502    - ip:                       \u2502            \u2502\n\u2502   \u2502        address: 100.65.0.105   \u2502   \u2502        address: 100.65.0.112   \u2502            \u2502\n\u2502   \u2502        port: 6443              \u2502   \u2502        port: 80                \u2502            \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                    \u2502                                       \u2502                         \u2502\n\u2502                    \u25bc                                       \u25bc                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502   \u2502  OVN LoadBalancer (cloud)      \u2502   \u2502  OVN LoadBalancer (cloud)      \u2502            \u2502\n\u2502   \u2502                                \u2502   \u2502                                \u2502            \u2502\n\u2502   \u2502  VIP: 100.65.0.105:6443        \u2502   \u2502  VIP: 100.65.0.112:80          \u2502            \u2502\n\u2502   \u2502  Backends: 10.0.10.x:6443      \u2502   \u2502  Backends: 10.0.10.28:80       \u2502            \u2502\n\u2502   \u2502  (Kamaji control plane pods)   \u2502   \u2502  (test-http-app pod)           \u2502            \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_current_network/#complete-traffic-flow-examples","title":"Complete Traffic Flow Examples","text":""},{"location":"prd/cloud_current_network/#example-1-tls-passthrough-to-kamaji-control-plane","title":"Example 1: TLS Passthrough to Kamaji Control Plane","text":"<pre><code>Internet Client\n      \u2502\n      \u2502 https://demo-cluster.stage.kube-dc.com:7443\n      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Node (88.99.29.250:7443)                                                \u2502\n\u2502      \u2502                                                                   \u2502\n\u2502      \u25bc kube-proxy                                                        \u2502\n\u2502      \u2502 SNAT: client IP \u2192 172.30.0.x                                      \u2502\n\u2502      \u25bc                                                                   \u2502\n\u2502  Envoy Pod (10.100.0.250:7443)                                           \u2502\n\u2502      \u2502                                                                   \u2502\n\u2502      \u2502 TLSRoute matches SNI: demo-cluster.stage.kube-dc.com              \u2502\n\u2502      \u2502 Backend: demo-cluster-backend                                     \u2502\n\u2502      \u25bc                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502 OVN Network (ovn-default \u2192 ext-cloud)                                \u2502\u2502\n\u2502  \u2502                                                                      \u2502\u2502\n\u2502  \u2502 Envoy \u2192 100.65.0.105:6443 (Backend IP endpoint)                     \u2502\u2502\n\u2502  \u2502           \u2502                                                          \u2502\u2502\n\u2502  \u2502           \u25bc OVN LoadBalancer DNAT                                    \u2502\u2502\n\u2502  \u2502       10.0.10.x:6443 (Kamaji pod in shalb-demo VPC)                  \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_current_network/#example-2-http-route-to-test-app","title":"Example 2: HTTP Route to Test App","text":"<pre><code>Internet Client\n      \u2502\n      \u2502 http://test-http-app.stage.kube-dc.com:8080\n      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Node (88.99.29.250:8080)                                                \u2502\n\u2502      \u2502                                                                   \u2502\n\u2502      \u25bc kube-proxy                                                        \u2502\n\u2502      \u2502 SNAT: client IP \u2192 172.30.0.x                                      \u2502\n\u2502      \u25bc                                                                   \u2502\n\u2502  Envoy Pod (10.100.0.250:8080)                                           \u2502\n\u2502      \u2502                                                                   \u2502\n\u2502      \u2502 HTTPRoute matches Host: test-http-app.stage.kube-dc.com           \u2502\n\u2502      \u2502 Backend: test-http-app-backend                                    \u2502\n\u2502      \u25bc                                                                   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502 OVN Network (ovn-default \u2192 ext-cloud)                                \u2502\u2502\n\u2502  \u2502                                                                      \u2502\u2502\n\u2502  \u2502 Envoy \u2192 100.65.0.112:80 (Backend IP endpoint)                       \u2502\u2502\n\u2502  \u2502           \u2502                                                          \u2502\u2502\n\u2502  \u2502           \u25bc OVN LoadBalancer DNAT                                    \u2502\u2502\n\u2502  \u2502       10.0.10.28:80 (test-http-app pod in shalb-demo VPC)            \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_current_network/#nginx-ingress-comparison","title":"Nginx Ingress (Comparison)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     NGINX INGRESS CONFIGURATION                           \u2502\n\u2502                                                                           \u2502\n\u2502   Namespace: ingress-nginx                                                \u2502\n\u2502                                                                           \u2502\n\u2502   Service: ingress-nginx-controller                                       \u2502\n\u2502   Type: LoadBalancer                                                      \u2502\n\u2502   ClusterIP: 10.101.151.121                                               \u2502\n\u2502   externalIPs: [88.99.29.250]  \u25c4\u2500\u2500 Same IP as Envoy!                     \u2502\n\u2502                                                                           \u2502\n\u2502   Ports:                                                                  \u2502\n\u2502   \u2022 80:31928 (HTTP)                                                       \u2502\n\u2502   \u2022 443:31891 (HTTPS)                                                     \u2502\n\u2502   \u2022 6443:30504 (TCP - for Kamaji?)                                        \u2502\n\u2502                                                                           \u2502\n\u2502   Note: nginx-ingress uses pod networking (10.100.0.153)                  \u2502\n\u2502         NOT hostNetwork                                                   \u2502\n\u2502         Same SNAT issue as Envoy - client IP lost                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_current_network/#known-issues","title":"Known Issues","text":""},{"location":"prd/cloud_current_network/#1-client-ip-preservation","title":"1. Client IP Preservation","text":"<p>Problem: kube-proxy SNATs incoming traffic through the join subnet (172.30.0.x), losing the real client IP.</p> <p>Impact: SecurityPolicy IP-based filtering doesn't work correctly.</p> <p>Current Workaround: None implemented.</p> <p>Proposed Solutions: - Cloud Bridge Router (see <code>cloud_bridge_network_routing_ingress.md</code>) - <code>externalTrafficPolicy: Local</code> - Proxy Protocol</p>"},{"location":"prd/cloud_current_network/#2-cross-vpc-communication","title":"2. Cross-VPC Communication","text":"<p>Problem: Pods in different VPCs (e.g., ovn-default vs shalb-demo) cannot communicate directly.</p> <p>Solution: Use OVN LoadBalancer VIPs on ext-cloud network as intermediary. The Backend resource points to the LB VIP (100.65.x.x), which DNATs to the actual pod IPs.</p>"},{"location":"prd/cloud_current_network/#3-shared-externalip","title":"3. Shared externalIP","text":"<p>Problem: Both nginx-ingress and Envoy Gateway share 88.99.29.250. Port conflicts are managed by using different ports: - nginx: 80, 443, 6443 - Envoy: 7443, 8080</p>"},{"location":"prd/cloud_current_network/#resource-summary","title":"Resource Summary","text":"Resource Type Count Purpose VPCs 5 Network isolation per project Subnets 8 IP allocation for pods and LBs EIps 14 External IP management OvnEips 14 OVN external IP binding OvnSnatRules 5 Outbound NAT for VPCs Backends 3 Gateway API backend endpoints HTTPRoutes 1 HTTP routing rules TLSRoutes 2 TLS passthrough routing Gateways 1 Envoy Gateway listener"},{"location":"prd/cloud_current_network/#references","title":"References","text":"<ul> <li>Kube-OVN VPC Documentation</li> <li>Envoy Gateway Documentation</li> <li>Gateway API Specification</li> <li>Cloud Bridge PRD: <code>cloud_bridge_network_routing_ingress.md</code></li> <li>Cloud Network Enable: <code>cloud_network_enable_cluster.md</code></li> <li>Gateway Primitives: <code>gateway_primitives.md</code></li> </ul>"},{"location":"prd/cloud_network_enable_cluster/","title":"Enabling Cloud Network Access for Management Cluster Components","text":""},{"location":"prd/cloud_network_enable_cluster/#problem-statement","title":"Problem Statement","text":"<p>The management cluster has two external networks available: - ext-public (<code>168.119.17.48/28</code>) - Public internet-facing IPs on VLAN 4011 - ext-cloud (<code>100.65.0.0/16</code>) - Private cloud network on VLAN 4013</p> <p>By default, pods running in the <code>ovn-default</code> subnet (e.g., <code>kamaji-system</code>, <code>kube-system</code>) cannot reach services exposed on the <code>ext-cloud</code> network, even though both subnets are within the same <code>ovn-cluster</code> VPC.</p> <p>This causes issues when: - Kamaji controller needs to connect to dedicated etcd datastores exposed via LoadBalancer on ext-cloud - Any management component needs to access services on the cloud network</p>"},{"location":"prd/cloud_network_enable_cluster/#root-cause","title":"Root Cause","text":"<p>The <code>ovn-default</code> subnet has <code>natOutgoing: true</code>, which means outbound traffic is NAT'd through the node's external interface (join network). However:</p> <ol> <li>Traffic to <code>ext-cloud</code> (100.65.0.x) is routed via the physical VLAN 4013</li> <li>Return traffic from ext-cloud doesn't know how to reach the OVN internal network (10.100.0.0/16)</li> <li>No SNAT is configured for traffic from <code>ovn-default</code> to <code>ext-cloud</code></li> </ol>"},{"location":"prd/cloud_network_enable_cluster/#solution","title":"Solution","text":"<p>Three configurations were required on the <code>ovn-cluster</code> VPC:</p>"},{"location":"prd/cloud_network_enable_cluster/#1-static-route-to-ext-cloud-gateway","title":"1. Static Route to ext-cloud Gateway","text":"<pre><code># Added to vpc/ovn-cluster spec.staticRoutes\n- cidr: 100.65.0.0/16\n  nextHopIP: 100.65.0.1  # ext-cloud gateway\n  policy: policyDst\n</code></pre> <p>This tells the OVN router where to send traffic destined for ext-cloud.</p>"},{"location":"prd/cloud_network_enable_cluster/#2-policy-route-to-allow-traffic","title":"2. Policy Route to Allow Traffic","text":"<pre><code># Added to vpc/ovn-cluster spec.policyRoutes  \n- action: allow\n  match: ip4.dst == 100.65.0.0/16\n  priority: 31000\n</code></pre> <p>Without this, traffic to ext-cloud would be dropped by default policies that only allow traffic to known internal subnets.</p>"},{"location":"prd/cloud_network_enable_cluster/#3-snat-rule-for-return-traffic","title":"3. SNAT Rule for Return Traffic","text":"<pre><code>apiVersion: kubeovn.io/v1\nkind: OvnSnatRule\nmetadata:\n  name: ovn-cluster-to-ext-cloud\nspec:\n  ovnEip: ovn-cluster-ext-cloud  # Uses 100.65.0.101\n  vpcSubnet: ovn-default\n</code></pre> <p>This NATs traffic from <code>10.100.0.0/16</code> to <code>100.65.0.101</code>, allowing return traffic to find its way back.</p>"},{"location":"prd/cloud_network_enable_cluster/#current-configuration","title":"Current Configuration","text":""},{"location":"prd/cloud_network_enable_cluster/#vpc-ovn-cluster","title":"VPC ovn-cluster","text":"<pre><code>apiVersion: kubeovn.io/v1\nkind: Vpc\nmetadata:\n  name: ovn-cluster\nspec:\n  enableExternal: true\n  staticRoutes:\n  - cidr: 100.65.0.0/16\n    nextHopIP: 100.65.0.1\n    policy: policyDst\n  policyRoutes:\n  - action: allow\n    match: ip4.dst == 100.65.0.0/16\n    priority: 31000\n</code></pre>"},{"location":"prd/cloud_network_enable_cluster/#ovnsnatrule","title":"OvnSnatRule","text":"<pre><code>apiVersion: kubeovn.io/v1\nkind: OvnSnatRule\nmetadata:\n  name: ovn-cluster-to-ext-cloud\nspec:\n  ovnEip: ovn-cluster-ext-cloud\n  vpcSubnet: ovn-default\nstatus:\n  ready: true\n  v4Eip: 100.65.0.101\n  v4IpCidr: 10.100.0.0/16\n  vpc: ovn-cluster\n</code></pre>"},{"location":"prd/cloud_network_enable_cluster/#verification","title":"Verification","text":"<p>Test connectivity from kamaji-system to ext-cloud:</p> <pre><code># Create test service on ext-cloud\nkubectl -n shalb-demo run nginx-test --image=nginx:alpine\nkubectl -n shalb-demo expose pod nginx-test --port=8080 --target-port=80 --type=LoadBalancer \\\n  --dry-run=client -o yaml | \\\n  kubectl annotate -f - service.nlb.kube-dc.com/bind-on-eip=default-gw --local -o yaml | \\\n  kubectl apply -f -\n\n# Test from kamaji-system\nkubectl -n kamaji-system run test --image=busybox --rm -it --restart=Never -- \\\n  wget -qO- --timeout=5 http://100.65.0.102:8080\n\n# Cleanup\nkubectl -n shalb-demo delete pod nginx-test svc nginx-test\n</code></pre>"},{"location":"prd/cloud_network_enable_cluster/#ovn-commands-for-debugging","title":"OVN Commands for Debugging","text":"<pre><code># View routes on ovn-cluster router\nkubectl ko nbctl lr-route-list ovn-cluster\n\n# View policy routes\nkubectl ko nbctl lr-policy-list ovn-cluster\n\n# View NAT rules\nkubectl ko nbctl lr-nat-list ovn-cluster\n\n# Trace packet path\nkubectl ko trace &lt;namespace&gt;/&lt;pod&gt; &lt;dest-ip&gt; tcp &lt;port&gt;\n\n# View router ports\nkubectl ko nbctl show ovn-cluster\n</code></pre>"},{"location":"prd/cloud_network_enable_cluster/#project-vpcs-and-ext-cloud-access","title":"Project VPCs and ext-cloud Access","text":""},{"location":"prd/cloud_network_enable_cluster/#existing-project-vpcs","title":"Existing Project VPCs","text":"<p>Project VPCs (like <code>shalb-demo</code>, <code>shalb-dev</code>) are isolated from <code>ovn-cluster</code> VPC. They have their own configuration:</p> VPC ext-cloud Access Configuration <code>shalb-dev</code> \u2705 Yes <code>extraExternalSubnets: [\"ext-cloud\", \"ext-public\"]</code> <code>shalb-demo</code> \u2705 Yes Default gateway on ext-cloud (<code>100.65.0.1</code>) <code>shalb-envoy</code> \u274c No (public only) <code>extraExternalSubnets: [\"ext-public\"]</code>"},{"location":"prd/cloud_network_enable_cluster/#creating-new-vpcs-with-ext-cloud-access","title":"Creating New VPCs with ext-cloud Access","text":"<p>When creating a new project VPC that needs ext-cloud access:</p>"},{"location":"prd/cloud_network_enable_cluster/#option-1-set-ext-cloud-as-default-gateway-recommended","title":"Option 1: Set ext-cloud as Default Gateway (Recommended)","text":"<pre><code>apiVersion: kubeovn.io/v1\nkind: Vpc\nmetadata:\n  name: my-project\n  annotations:\n    network.kube-dc.com/default-gw-subnet-name: ext-cloud\nspec:\n  enableExternal: true\n  namespaces:\n  - my-project\n  staticRoutes:\n  - cidr: 0.0.0.0/0\n    nextHopIP: 100.65.0.1  # ext-cloud gateway\n    policy: policyDst\n</code></pre> <p>This routes all external traffic through ext-cloud.</p>"},{"location":"prd/cloud_network_enable_cluster/#option-2-add-ext-cloud-as-extra-external-subnet","title":"Option 2: Add ext-cloud as Extra External Subnet","text":"<pre><code>apiVersion: kubeovn.io/v1\nkind: Vpc\nmetadata:\n  name: my-project\nspec:\n  enableExternal: true\n  extraExternalSubnets:\n  - ext-cloud\n  - ext-public  # Optional: include both\n  namespaces:\n  - my-project\n</code></pre> <p>This allows the VPC to use both networks.</p>"},{"location":"prd/cloud_network_enable_cluster/#key-points-for-new-vpcs","title":"Key Points for New VPCs","text":"<ol> <li>No changes needed to ovn-cluster VPC - The configuration above is global and allows <code>ovn-default</code> pods to reach ext-cloud</li> <li>Project VPCs are independent - Each project VPC needs its own routing configuration</li> <li>SNAT is automatic - When using EIP resources, SNAT is configured automatically</li> <li>extraExternalSubnets - This setting allows the VPC to connect to external subnets on physical VLANs</li> </ol>"},{"location":"prd/cloud_network_enable_cluster/#network-architecture-diagram","title":"Network Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Physical Network                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502   VLAN 4011      \u2502                 \u2502   VLAN 4013      \u2502      \u2502\n\u2502  \u2502   ext-public     \u2502                 \u2502   ext-cloud      \u2502      \u2502\n\u2502  \u2502 168.119.17.48/28 \u2502                 \u2502 100.65.0.0/16    \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502                                     \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       OVN Logical Network                        \u2502\n\u2502                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                    ovn-cluster VPC                          \u2502 \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502\n\u2502  \u2502  \u2502  ovn-default \u2502    \u2502   ext-cloud  \u2502    \u2502  ext-public  \u2502  \u2502 \u2502\n\u2502  \u2502  \u250210.100.0.0/16 \u2502\u2500\u2500\u2500\u25b6\u2502100.65.0.0/16 \u2502    \u2502168.119.17/28 \u2502  \u2502 \u2502\n\u2502  \u2502  \u2502              \u2502    \u2502              \u2502    \u2502              \u2502  \u2502 \u2502\n\u2502  \u2502  \u2502 kamaji-sys   \u2502    \u2502  SNAT via    \u2502    \u2502              \u2502  \u2502 \u2502\n\u2502  \u2502  \u2502 kube-system  \u2502    \u2502 100.65.0.101 \u2502    \u2502              \u2502  \u2502 \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  shalb-dev VPC  \u2502  \u2502 shalb-demo VPC  \u2502  \u2502 shalb-envoy VPC \u2502  \u2502\n\u2502  \u2502  10.1.0.0/16    \u2502  \u2502  10.0.10.0/24   \u2502  \u2502  10.0.40.0/24   \u2502  \u2502\n\u2502  \u2502                 \u2502  \u2502                 \u2502  \u2502                 \u2502  \u2502\n\u2502  \u2502 ext-cloud: \u2705   \u2502  \u2502 ext-cloud: \u2705   \u2502  \u2502 ext-cloud: \u274c   \u2502  \u2502\n\u2502  \u2502 ext-public: \u2705  \u2502  \u2502 ext-public: \u274c  \u2502  \u2502 ext-public: \u2705  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/cloud_network_enable_cluster/#troubleshooting","title":"Troubleshooting","text":""},{"location":"prd/cloud_network_enable_cluster/#symptom-timeout-when-accessing-ext-cloud-from-kamaji-system","title":"Symptom: Timeout when accessing ext-cloud from kamaji-system","text":"<ol> <li> <p>Check static route exists: <pre><code>kubectl ko nbctl lr-route-list ovn-cluster | grep 100.65\n</code></pre></p> </li> <li> <p>Check policy route allows traffic: <pre><code>kubectl ko nbctl lr-policy-list ovn-cluster | grep 100.65\n</code></pre></p> </li> <li> <p>Check SNAT rule exists: <pre><code>kubectl ko nbctl lr-nat-list ovn-cluster\nkubectl get ovn-snat-rules ovn-cluster-to-ext-cloud\n</code></pre></p> </li> <li> <p>Trace the packet: <pre><code>kubectl ko trace kamaji-system/&lt;pod-name&gt; 100.65.0.102 tcp 8080\n</code></pre></p> </li> </ol>"},{"location":"prd/cloud_network_enable_cluster/#symptom-project-vpc-cannot-reach-ext-cloud","title":"Symptom: Project VPC cannot reach ext-cloud","text":"<ol> <li> <p>Check VPC has extraExternalSubnets or staticRoute: <pre><code>kubectl get vpc &lt;vpc-name&gt; -o yaml\n</code></pre></p> </li> <li> <p>Verify EIP and SNAT are configured: <pre><code>kubectl get ovn-eip,ovn-snat-rules | grep &lt;vpc-name&gt;\n</code></pre></p> </li> </ol>"},{"location":"prd/cloud_network_enable_cluster/#references","title":"References","text":"<ul> <li>Kube-OVN VPC Documentation</li> <li>Kube-OVN External Gateway</li> </ul>"},{"location":"prd/components-inventory/","title":"Kube-DC Components Inventory","text":""},{"location":"prd/components-inventory/#kube-dc-product-components","title":"Kube-DC Product Components","text":"Component Description Kube-DC Manager (Controller) Core Kubernetes operator managing custom resources (Organizations, Projects, EIp, FIp, etc.), implementing multi-tenancy, networking policies, and resource lifecycle management UI Frontend React-based web console built with PatternFly UI framework, providing dashboard for managing organizations, projects, virtual machines, and monitoring UI Backend (API Server) Node.js/Express API server handling authentication, Kubernetes API proxying, metrics collection (Prometheus), VM management, and cloud shell access Authentication Service JWT-based authentication integration with Keycloak, managing user sessions, organization/project access tokens, and RBAC mapping Virtual Machine Management KubeVirt integration providing VM lifecycle management, live migration, snapshots, cloud-init configuration, and performance monitoring Networking Service Kube-OVN integration managing VPCs, subnets, external IPs (EIp/FIp), SNAT rules, load balancers, and multi-network connectivity Organization &amp; Project Management Multi-tenant resource isolation, namespace provisioning, Keycloak realm/group synchronization, and hierarchical RBAC Monitoring &amp; Metrics Service Prometheus integration for real-time and historical metrics collection, VM performance tracking, cluster observability Billing Integration Resource usage tracking, cost allocation per organization/project, usage reporting and quota management Kube-DC K8s Manager Kamaji-based multi-tenant Kubernetes control plane manager, enabling creation of isolated tenant Kubernetes clusters with dedicated/shared etcd Cluster API Provider CloudSigma Infrastructure provider for Cluster API enabling declarative Kubernetes cluster management on CloudSigma cloud platform CloudSigma Cloud Controller Manager (CCM) Kubernetes cloud-provider implementation for CloudSigma, providing node registration with metadata, LoadBalancer service support, and node lifecycle management CloudSigma CSI Driver Container Storage Interface driver enabling dynamic volume provisioning, attachment, expansion (offline), snapshots, and persistent storage management on CloudSigma infrastructure Kubernetes Image Builder Packer-based automation for building Ubuntu 24.04 images with pre-installed Kubernetes components (kubelet, kubeadm, kubectl, containerd) for CloudSigma worker nodes"},{"location":"prd/components-inventory/#open-source-components","title":"Open Source Components","text":"Component Open Source License Open Source Link Features/Purpose Kubernetes Apache 2.0 https://github.com/kubernetes/kubernetes Container orchestration platform, base for all Kube-DC operations Kube-OVN Apache 2.0 https://github.com/kubeovn/kube-ovn Software-defined networking with VPC, subnet, VLAN support, SNAT/DNAT, load balancing Multus CNI Apache 2.0 https://github.com/k8snetworkplumbingwg/multus-cni Multi-network plugin enabling multiple network interfaces for pods KubeVirt Apache 2.0 https://github.com/kubevirt/kubevirt Virtual machine management on Kubernetes, enabling VM workloads alongside containers CDI (Containerized Data Importer) Apache 2.0 https://github.com/kubevirt/containerized-data-importer Persistent storage management for KubeVirt VMs, image import/upload, DataVolumes Cert-Manager Apache 2.0 https://github.com/cert-manager/cert-manager Automatic TLS certificate provisioning and management, Let's Encrypt integration Envoy Gateway Apache 2.0 https://github.com/envoyproxy/gateway Kubernetes Gateway API implementation for advanced ingress, routing, and TLS passthrough Keycloak Apache 2.0 https://github.com/keycloak/keycloak Identity and access management, SSO, OIDC/SAML provider for multi-tenant authentication Prometheus Operator Apache 2.0 https://github.com/prometheus-operator/prometheus-operator Kubernetes-native Prometheus deployment, ServiceMonitors, alerting rules management Grafana AGPL-3.0 https://github.com/grafana/grafana Observability dashboards, metrics visualization, alerting UI Grafana Loki AGPL-3.0 https://github.com/grafana/loki Log aggregation system optimized for Kubernetes, stores and queries logs Grafana Alloy Apache 2.0 https://github.com/grafana/alloy OpenTelemetry collector for metrics, logs, and traces, Kubernetes events collection Kamaji Apache 2.0 https://github.com/clastix/kamaji Multi-tenant Kubernetes control plane manager, runs tenant API servers as pods Kamaji-etcd Apache 2.0 https://github.com/clastix/kamaji-etcd Shared or dedicated etcd datastore management for Kamaji tenant clusters Cluster API Apache 2.0 https://github.com/kubernetes-sigs/cluster-api Declarative Kubernetes cluster lifecycle management, infrastructure abstraction CAPI Provider KubeVirt Apache 2.0 https://github.com/kubernetes-sigs/cluster-api-provider-kubevirt KubeVirt infrastructure provider for Cluster API, enables VM-based worker nodes CAPI Provider K3s Apache 2.0 https://github.com/cluster-api-provider-k3s K3s bootstrap and control plane provider for lightweight Kubernetes clusters Sveltos Apache 2.0 https://github.com/projectsveltos/sveltos Kubernetes addon controller for automated application deployment across clusters Kyverno Apache 2.0 https://github.com/kyverno/kyverno Kubernetes policy engine for security, compliance, and resource management policies Local Path Provisioner Apache 2.0 https://github.com/rancher/local-path-provisioner Dynamic local storage provisioner, default StorageClass for persistent volumes noVNC MPL 2.0 https://github.com/novnc/noVNC Browser-based VNC client for VM console access via WebSocket CloudSigma Cloud Controller Manager Apache 2.0 https://github.com/kube-dc/cluster-api-provider-cloudsigma/tree/main/ccm Cloud provider implementation for CloudSigma infrastructure, node initialization, LoadBalancer services CloudSigma CSI Driver Apache 2.0 https://github.com/kube-dc/cluster-api-provider-cloudsigma/tree/main/csi Container Storage Interface driver for CloudSigma persistent storage, dynamic volume provisioning, snapshots CloudSigma Go SDK Apache 2.0 https://github.com/cloudsigma/cloudsigma-sdk-go Official CloudSigma API client library for Go, used by CAPCS, CCM, and CSI Packer MPL 2.0 https://github.com/hashicorp/packer HashiCorp image builder tool for creating Kubernetes node images"},{"location":"prd/components-inventory/#frontend-dependencies-ui-stack","title":"Frontend Dependencies (UI Stack)","text":"Component License Purpose React MIT UI framework for building interactive user interfaces PatternFly React MIT Enterprise UI component library with accessible, responsive design React Router MIT Client-side routing for single-page application navigation Victory Charts MIT Data visualization library for performance and metrics charts Keycloak-js Apache 2.0 JavaScript adapter for Keycloak authentication Webpack MIT Module bundler for frontend assets and code optimization TypeScript Apache 2.0 Type-safe JavaScript for improved developer experience"},{"location":"prd/components-inventory/#backend-dependencies-api-stack","title":"Backend Dependencies (API Stack)","text":"Component License Purpose Node.js + Express MIT JavaScript runtime and web framework for REST API server @kubernetes/client-node Apache 2.0 Official Kubernetes JavaScript client library @kubevirt-ui/kubevirt-api Apache 2.0 KubeVirt API TypeScript definitions and utilities openid-client MIT OpenID Connect relying party implementation for OIDC authentication jose MIT JavaScript Object Signing and Encryption, JWT handling axios MIT HTTP client for REST API requests to Kubernetes and external services express-ws BSD-2-Clause WebSocket support for Express, enables VM console streaming http-proxy-middleware MIT Proxy middleware for routing requests to Kubernetes API js-yaml MIT YAML parser for Kubernetes manifests and configuration mustache MIT Template engine for dynamic resource generation moment MIT Date/time manipulation for metrics and timestamps swagger-jsdoc MIT OpenAPI documentation generation from JSDoc comments swagger-ui-express MIT Interactive API documentation UI"},{"location":"prd/components-inventory/#version-information-as-of-latest-installer","title":"Version Information (as of latest installer)","text":"Component Version Kube-OVN v1.14.10 Multus CNI v4.1.0 KubeVirt v1.6.0 CDI v1.59.0 Cert-Manager v1.14.4 Envoy Gateway v1.2.6 Keycloak 24.3.0 Prometheus Operator (kube-prometheus-stack) 67.4.0 Grafana Loki 6.11.0 Grafana Alloy 0.10.1 Kamaji 1.0.0 Kamaji-etcd 0.14.0 Cluster API v1.8.1 CAPI K3s Provider v1.2.2 Kyverno v1.15.2 Sveltos v0.57.3 Local Path Provisioner v0.0.31"},{"location":"prd/components-inventory/#architecture-overview","title":"Architecture Overview","text":""},{"location":"prd/components-inventory/#component-interaction-flow","title":"Component Interaction Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         User Interface Layer                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502 Web Browser  \u2502\u2500\u2500\u2500\u25b6\u2502 UI Frontend  \u2502\u2500\u2500\u2500\u25b6\u2502  UI Backend  \u2502          \u2502\n\u2502  \u2502  (React)     \u2502    \u2502 (PatternFly) \u2502    \u2502  (Node.js)   \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                     \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Authentication Layer            \u2502                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502                 \u2502\n\u2502  \u2502  Keycloak    \u2502\u25c0\u2500\u2500\u2500\u2502 Auth Service \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502  \u2502   (OIDC)     \u2502    \u2502   (JWT)      \u2502                               \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Kubernetes API Layer (Management Cluster)               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502   Kube-DC    \u2502    \u2502    Kamaji    \u2502    \u2502 Cluster API  \u2502          \u2502\n\u2502  \u2502  Controller  \u2502    \u2502  Controller  \u2502    \u2502 Controllers  \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502                   \u2502                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          \u2502   Infrastructure &amp; Platform Layer     \u2502                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502  Kube-OVN    \u2502    \u2502  KubeVirt  \u2502    \u2502   Prometheus   \u2502          \u2502\n\u2502  \u2502 (Networking) \u2502    \u2502   (VMs)    \u2502    \u2502  (Monitoring)  \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/components-inventory/#cloudsigma-integration-components","title":"CloudSigma Integration Components","text":"<p>The cluster-api-provider-cloudsigma repository includes three key components for CloudSigma cloud integration:</p>"},{"location":"prd/components-inventory/#1-cloudsigma-cloud-controller-manager-ccm","title":"1. CloudSigma Cloud Controller Manager (CCM)","text":"<p>Location: <code>/ccm</code></p> <p>Purpose: Implements the Kubernetes cloud-provider interface for CloudSigma infrastructure</p> <p>Features: - Node Controller: Automatic node registration with CloudSigma metadata, providerID assignment, topology labels - Service Controller: LoadBalancer service type support with CloudSigma load balancer API integration - Route Controller: Optional pod network route management (typically disabled with CNI)</p> <p>Deployment: DaemonSet on control plane nodes with external cloud provider configuration</p> <p>Key Capabilities: - Initializes nodes with <code>providerID: cloudsigma://server-uuid</code> - Adds topology labels: <code>topology.kubernetes.io/region</code>, <code>node.kubernetes.io/instance-type</code> - Creates CloudSigma load balancers for <code>type: LoadBalancer</code> services - Updates service status with external IPs</p>"},{"location":"prd/components-inventory/#2-cloudsigma-csi-driver","title":"2. CloudSigma CSI Driver","text":"<p>Location: <code>/csi</code></p> <p>Purpose: Container Storage Interface driver for persistent volume management on CloudSigma</p> <p>Features: - Dynamic Volume Provisioning: Automatically create CloudSigma drives for PersistentVolumeClaims - Volume Attachment: Hot-plug/unplug volumes to running nodes with detachment verification - Volume Expansion: Offline resize support (CloudSigma platform limitation) - Volume Snapshots: Create and restore volume snapshots via CloudSigma API - Battle-proof Device Discovery: Stable <code>/dev/disk/by-path/</code> detection with mutex serialization - Storage Classes: Support for DSSD (Distributed SSD) storage type</p> <p>Architecture: - Controller Plugin: Deployment handling volume lifecycle operations (create, delete, attach, detach, expand, snapshot) - Node Plugin: DaemonSet on each node for volume staging, publishing, and filesystem operations</p> <p>Performance: Sequential R/W 200-500 MB/s, Random IOPS 5k-15k (varies by VM size)</p> <p>Current Version: v1.2.7 with offline expansion and detachment verification</p>"},{"location":"prd/components-inventory/#3-kubernetes-image-builder","title":"3. Kubernetes Image Builder","text":"<p>Location: <code>/images/ubuntu-k8s</code></p> <p>Purpose: Packer-based automation for building Kubernetes-ready Ubuntu images for CloudSigma</p> <p>Build Methods: - CloudSigma Build (Recommended): Builds directly on CloudSigma infrastructure, no upload required - Local QEMU Build: Builds locally, requires manual upload via CloudSigma Web UI</p> <p>What's Included: - Ubuntu 24.04 LTS base image - Containerd container runtime - Kubernetes components: kubelet, kubeadm, kubectl (version configurable) - CNI plugins pre-installed - Kernel modules and sysctl configuration - Cloud-init configured for CAPI bootstrap - Common Kubernetes images pre-pulled for faster node startup</p> <p>Build Configuration: <pre><code># Build on CloudSigma (recommended)\nmake build-on-cloudsigma K8S_VERSION=1.34.1\n\n# Build locally with QEMU\nmake build K8S_VERSION=1.34.1 UBUNTU_VERSION=24.04\n</code></pre></p> <p>Provisioning Scripts: 1. Base packages installation 2. Containerd installation and configuration 3. Kubernetes component installation 4. System configuration (kernel modules, sysctl) 5. Cleanup and image preparation</p>"},{"location":"prd/components-inventory/#multi-repository-structure","title":"Multi-Repository Structure","text":"<ol> <li>kube-dc (Main Repository)</li> <li>Core controller managing Organizations, Projects, EIp, FIp</li> <li>UI Frontend and Backend</li> <li>Multi-tenancy and networking logic</li> <li> <p>Installation templates (cdev/helm)</p> </li> <li> <p>kube-dc-k8-manager (Tenant Cluster Manager)</p> </li> <li>Manages tenant Kubernetes control planes via Kamaji</li> <li>Cluster API integration for worker node provisioning</li> <li>Datastore management (shared/dedicated etcd)</li> <li> <p>CloudSigma and KubeVirt infrastructure support</p> </li> <li> <p>cluster-api-provider-cloudsigma (Cloud Provider)</p> </li> <li>CAPI infrastructure provider for CloudSigma</li> <li>CloudSigma SDK integration</li> <li>Worker node provisioning on CloudSigma platform</li> <li>CCM (<code>/ccm</code>): Cloud Controller Manager for node initialization and LoadBalancer services</li> <li>CSI (<code>/csi</code>): Container Storage Interface driver for persistent volume management</li> <li>Image Builder (<code>/images/ubuntu-k8s</code>): Packer-based Kubernetes node image automation</li> </ol>"},{"location":"prd/components-inventory/#integration-points","title":"Integration Points","text":""},{"location":"prd/components-inventory/#external-systems-integration","title":"External Systems Integration","text":"System Integration Method Purpose Keycloak OIDC/OAuth2 User authentication, organization realms, group management Kubernetes API client-go, @kubernetes/client-node Resource management, RBAC, CRD operations Prometheus HTTP API Metrics collection, VM performance data, alerting CloudSigma API Go SDK Infrastructure provisioning for CAPI clusters OVN Database ovn-nbctl/ovs-vsctl Network configuration, VPC management, routing"},{"location":"prd/components-inventory/#component-communication","title":"Component Communication","text":"<ul> <li>UI Frontend \u2194 UI Backend: REST API (HTTP/HTTPS), WebSocket (VM console)</li> <li>UI Backend \u2194 Kubernetes API: Kubernetes API client, token-based auth</li> <li>Kube-DC Controller \u2194 Kube-OVN: Custom Resource updates, OVN database queries</li> <li>Kamaji \u2194 Tenant Clusters: TCP/6443 (Kubernetes API), etcd connection</li> <li>CAPI \u2194 Infrastructure Providers: Infrastructure machine creation, health checks</li> </ul>"},{"location":"prd/components-inventory/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"prd/components-inventory/#installation-method","title":"Installation Method","text":"<ul> <li>Primary: cdev (Cloud Development Environment) with Helm charts</li> <li>Templates: YAML-based templating with variable substitution</li> <li>Namespace Organization: </li> <li><code>kube-system</code>: Kube-OVN, Multus</li> <li><code>kube-dc</code>: Main controller, UI</li> <li><code>kubevirt</code>: VM management</li> <li><code>monitoring</code>: Prometheus, Grafana, Loki</li> <li><code>keycloak</code>: Identity management</li> <li><code>cert-manager</code>: Certificate automation</li> <li><code>kamaji-system</code>: Tenant control plane manager</li> <li><code>projectsveltos</code>: Addon controller</li> <li>Organization namespaces: <code>&lt;org-name&gt;</code></li> <li>Project namespaces: <code>&lt;org-name&gt;-&lt;project-name&gt;</code></li> </ul>"},{"location":"prd/components-inventory/#high-availability-considerations","title":"High Availability Considerations","text":"<ul> <li>Multi-replica controller deployments</li> <li>Kamaji etcd cluster (3+ replicas)</li> <li>Kube-OVN OVN database HA</li> <li>LoadBalancer services for critical components</li> <li>StatefulSet for stateful components (etcd, Loki)</li> </ul> <p>Last Updated: January 2025 Document Version: 1.0</p>"},{"location":"prd/dynamic_https_listeners/","title":"PRD: Dynamic HTTPS Listeners - Gateway-Terminated TLS","text":""},{"location":"prd/dynamic_https_listeners/#executive-summary","title":"Executive Summary","text":"<p>This PRD defines the automatic HTTPS listener creation mechanism for services that want the Gateway to terminate TLS. When a Service is annotated with <code>expose-route: https</code>, the controller automatically creates: 1. A TLS Certificate (via cert-manager) 2. A dedicated Gateway listener for the hostname 3. An HTTPRoute pointing to the service's Backend</p> <p>This enables users to expose services over HTTPS without handling TLS in their application.</p>"},{"location":"prd/dynamic_https_listeners/#problem-statement","title":"Problem Statement","text":"<p>Currently, there are two options for HTTPS exposure:</p>"},{"location":"prd/dynamic_https_listeners/#option-1-tls-passthrough-current","title":"Option 1: TLS Passthrough (Current)","text":"<p><pre><code>service.nlb.kube-dc.com/expose-route: \"tls-passthrough\"\n</code></pre> - \u2705 Works today - \u274c App must terminate TLS (configure nginx/app with certificates) - \u274c More complex application setup</p>"},{"location":"prd/dynamic_https_listeners/#option-2-platform-style-https-manual","title":"Option 2: Platform-Style HTTPS (Manual)","text":"<p><pre><code># Requires manual Gateway listener configuration by admin\n# Only available for platform services (console, keycloak, etc.)\n</code></pre> - \u2705 App serves plain HTTP - \u274c Requires admin intervention - \u274c Not self-service for users</p>"},{"location":"prd/dynamic_https_listeners/#desired-state","title":"Desired State","text":"<p><pre><code>service.nlb.kube-dc.com/expose-route: \"https\"\n</code></pre> - \u2705 App serves plain HTTP (no TLS handling needed) - \u2705 Gateway terminates TLS automatically - \u2705 Certificate auto-provisioned via cert-manager - \u2705 Self-service for project users</p>"},{"location":"prd/dynamic_https_listeners/#solution-dynamic-listener-creation","title":"Solution: Dynamic Listener Creation","text":""},{"location":"prd/dynamic_https_listeners/#user-experience","title":"User Experience","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-web-app\n  annotations:\n    # Single annotation for full HTTPS automation\n    service.nlb.kube-dc.com/expose-route: \"https\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: my-web-app\n  ports:\n  - port: 80        # App serves plain HTTP\n    targetPort: 8080\n</code></pre> <p>Result: - \u2705 Certificate requested via cert-manager (ACME HTTP-01) - \u2705 Gateway listener created for <code>my-web-app-{namespace}.{base_domain}</code> - \u2705 HTTPRoute created pointing to Backend - \u2705 User accesses <code>https://my-web-app-demo.stage.kube-dc.com</code></p>"},{"location":"prd/dynamic_https_listeners/#traffic-flow","title":"Traffic Flow","text":"<pre><code>User Browser\n    \u2502\n    \u2502 HTTPS (encrypted)\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Envoy Gateway               \u2502\n\u2502  Listener: https-my-web-app-demo    \u2502\n\u2502  Port: 443                          \u2502\n\u2502  TLS: Terminate (uses certificate)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\n    \u2502 HTTP (plain, internal)\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Backend                     \u2502\n\u2502  Target: 100.65.x.x:80              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502\n    \u2502 HTTP\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         User Application            \u2502\n\u2502  Listens on: 0.0.0.0:8080           \u2502\n\u2502  No TLS configuration needed        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/dynamic_https_listeners/#annotation-schema","title":"Annotation Schema","text":""},{"location":"prd/dynamic_https_listeners/#route-types-extended","title":"Route Types (Extended)","text":"Annotation Value Description App Requirements <code>http</code> Plain HTTP on port 80 Serves HTTP <code>tls-passthrough</code> TLS passthrough on port 443 Serves HTTPS (app terminates TLS) <code>https</code> NEW Gateway-terminated TLS on port 443 Serves HTTP (gateway terminates TLS)"},{"location":"prd/dynamic_https_listeners/#additional-annotations","title":"Additional Annotations","text":"Annotation Values Default Description <code>service.nlb.kube-dc.com/expose-route</code> <code>http</code>, <code>tls-passthrough</code>, <code>https</code> - Route type <code>service.nlb.kube-dc.com/route-hostname</code> string auto-generated Custom hostname <code>service.nlb.kube-dc.com/route-port</code> number first port Backend port <code>service.nlb.kube-dc.com/tls-issuer</code> string <code>letsencrypt</code> cert-manager Issuer name"},{"location":"prd/dynamic_https_listeners/#architecture","title":"Architecture","text":""},{"location":"prd/dynamic_https_listeners/#resources-created-for-expose-route-https","title":"Resources Created for <code>expose-route: https</code>","text":"<pre><code>Service (user creates)\n    \u2502\n    \u251c\u2500\u2500 EIP (auto-created)\n    \u2502\n    \u251c\u2500\u2500 Backend (auto-created)\n    \u2502\n    \u251c\u2500\u2500 Certificate (auto-created)\n    \u2502       \u2502\n    \u2502       \u2514\u2500\u2500 Secret (cert-manager creates)\n    \u2502\n    \u251c\u2500\u2500 Gateway Listener (auto-created via patch)\n    \u2502       \u2502\n    \u2502       \u2514\u2500\u2500 References Certificate Secret\n    \u2502\n    \u251c\u2500\u2500 ReferenceGrant (auto-created)\n    \u2502       \u2502\n    \u2502       \u2514\u2500\u2500 Allows Gateway to access Certificate Secret\n    \u2502\n    \u2514\u2500\u2500 HTTPRoute (auto-created)\n            \u2502\n            \u2514\u2500\u2500 References Gateway Listener and Backend\n</code></pre>"},{"location":"prd/dynamic_https_listeners/#controller-flow","title":"Controller Flow","text":"<pre><code>func (m *GatewayRouteManager) syncHTTPSRoute(ctx context.Context, hostname string, port int32) error {\n    // 1. Ensure Issuer exists (or use default)\n    issuer := m.getIssuer()\n\n    // 2. Create Certificate\n    cert := m.createCertificate(hostname, issuer)\n\n    // 3. Wait for Certificate to be ready\n    if !m.isCertificateReady(cert) {\n        return requeueAfter(30 * time.Second)\n    }\n\n    // 4. Create ReferenceGrant (allows Gateway to access cert secret)\n    m.createReferenceGrant(hostname)\n\n    // 5. Patch Gateway to add listener\n    m.patchGatewayAddListener(hostname, cert.Spec.SecretName)\n\n    // 6. Create HTTPRoute\n    m.createHTTPRoute(hostname, port)\n\n    return nil\n}\n</code></pre>"},{"location":"prd/dynamic_https_listeners/#implementation-details","title":"Implementation Details","text":""},{"location":"prd/dynamic_https_listeners/#1-certificate-creation","title":"1. Certificate Creation","text":"<pre><code>apiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: my-web-app-tls\n  namespace: shalb-demo\n  ownerReferences:\n  - apiVersion: v1\n    kind: Service\n    name: my-web-app\n    uid: &lt;service-uid&gt;\nspec:\n  secretName: my-web-app-tls-secret\n  issuerRef:\n    name: letsencrypt\n    kind: Issuer\n  dnsNames:\n  - my-web-app-demo.stage.kube-dc.com\n</code></pre>"},{"location":"prd/dynamic_https_listeners/#2-referencegrant","title":"2. ReferenceGrant","text":"<p>Allows the Gateway in <code>envoy-gateway-system</code> to reference the certificate Secret in the user's namespace:</p> <pre><code>apiVersion: gateway.networking.k8s.io/v1beta1\nkind: ReferenceGrant\nmetadata:\n  name: allow-gateway-cert-my-web-app\n  namespace: shalb-demo\n  ownerReferences:\n  - apiVersion: v1\n    kind: Service\n    name: my-web-app\nspec:\n  from:\n  - group: gateway.networking.k8s.io\n    kind: Gateway\n    namespace: envoy-gateway-system\n  to:\n  - group: \"\"\n    kind: Secret\n    name: my-web-app-tls-secret\n</code></pre>"},{"location":"prd/dynamic_https_listeners/#3-gateway-listener-patch","title":"3. Gateway Listener Patch","text":"<pre><code># Controller patches Gateway to add:\n- name: https-my-web-app-shalb-demo\n  hostname: my-web-app-demo.stage.kube-dc.com\n  port: 443\n  protocol: HTTPS\n  tls:\n    mode: Terminate\n    certificateRefs:\n    - group: \"\"\n      kind: Secret\n      name: my-web-app-tls-secret\n      namespace: shalb-demo\n  allowedRoutes:\n    namespaces:\n      from: Same\n</code></pre>"},{"location":"prd/dynamic_https_listeners/#4-httproute","title":"4. HTTPRoute","text":"<pre><code>apiVersion: gateway.networking.k8s.io/v1\nkind: HTTPRoute\nmetadata:\n  name: my-web-app-route\n  namespace: shalb-demo\n  ownerReferences:\n  - apiVersion: v1\n    kind: Service\n    name: my-web-app\nspec:\n  parentRefs:\n  - group: gateway.networking.k8s.io\n    kind: Gateway\n    name: eg\n    namespace: envoy-gateway-system\n    sectionName: https-my-web-app-shalb-demo\n  hostnames:\n  - my-web-app-demo.stage.kube-dc.com\n  rules:\n  - backendRefs:\n    - group: gateway.envoyproxy.io\n      kind: Backend\n      name: my-web-app-backend\n      port: 80\n</code></pre>"},{"location":"prd/dynamic_https_listeners/#rbac-requirements","title":"RBAC Requirements","text":""},{"location":"prd/dynamic_https_listeners/#controller-permissions-new","title":"Controller Permissions (New)","text":"<pre><code># +kubebuilder:rbac:groups=gateway.networking.k8s.io,resources=gateways,verbs=get;list;watch;patch\n# +kubebuilder:rbac:groups=gateway.networking.k8s.io,resources=referencegrants,verbs=get;list;watch;create;update;patch;delete\n# +kubebuilder:rbac:groups=cert-manager.io,resources=certificates,verbs=get;list;watch;create;update;patch;delete\n</code></pre>"},{"location":"prd/dynamic_https_listeners/#security-considerations","title":"Security Considerations","text":"Concern Mitigation Controller can modify Gateway Limited to adding/removing listeners, not core config Certificate in user namespace ReferenceGrant scoped to specific secret Listener naming conflicts Use <code>https-{service}-{namespace}</code> pattern Orphaned listeners OwnerReference on Service triggers cleanup"},{"location":"prd/dynamic_https_listeners/#cleanup","title":"Cleanup","text":"<p>When Service is deleted:</p> <ol> <li>OwnerReferences automatically delete:</li> <li>Certificate</li> <li>ReferenceGrant</li> <li>HTTPRoute</li> <li>Backend</li> <li> <p>EIP</p> </li> <li> <p>Controller explicitly removes:</p> </li> <li>Gateway listener (via patch)</li> </ol> <pre><code>func (m *GatewayRouteManager) deleteHTTPSRoute(ctx context.Context) error {\n    hostname := m.getHostname()\n    listenerName := m.getListenerName(hostname)\n\n    // Remove listener from Gateway\n    m.patchGatewayRemoveListener(listenerName)\n\n    // Other resources cleaned up by OwnerReferences\n    return nil\n}\n</code></pre>"},{"location":"prd/dynamic_https_listeners/#comparison-route-types","title":"Comparison: Route Types","text":"Feature <code>http</code> <code>tls-passthrough</code> <code>https</code> Gateway Port 80 443 443 TLS Termination None App Gateway App Complexity Low High Low Certificate Not needed App manages Auto-provisioned Gateway Listener Shared Shared wildcard Per-service Gateway Modification No No Yes"},{"location":"prd/dynamic_https_listeners/#example-usage","title":"Example Usage","text":""},{"location":"prd/dynamic_https_listeners/#simple-web-application","title":"Simple Web Application","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-web-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: my-web-app\n  template:\n    metadata:\n      labels:\n        app: my-web-app\n    spec:\n      containers:\n      - name: app\n        image: nginx:alpine\n        ports:\n        - containerPort: 80  # Plain HTTP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-web-app\n  annotations:\n    service.nlb.kube-dc.com/expose-route: \"https\"\nspec:\n  type: LoadBalancer\n  selector:\n    app: my-web-app\n  ports:\n  - port: 80\n    targetPort: 80\n</code></pre> <p>Access: <code>https://my-web-app-{namespace}.{base_domain}</code></p>"},{"location":"prd/dynamic_https_listeners/#custom-hostname","title":"Custom Hostname","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-web-app\n  annotations:\n    service.nlb.kube-dc.com/expose-route: \"https\"\n    service.nlb.kube-dc.com/route-hostname: \"app.example.com\"\nspec:\n  type: LoadBalancer\n  ...\n</code></pre> <p>Note: Custom hostname requires: 1. DNS pointing to Gateway IP 2. Issuer that can validate that domain (may need DNS-01)</p>"},{"location":"prd/dynamic_https_listeners/#prerequisites","title":"Prerequisites","text":""},{"location":"prd/dynamic_https_listeners/#existing-infrastructure","title":"Existing Infrastructure","text":"Component Status Notes cert-manager \u2705 Installed Handles certificate lifecycle Issuer (letsencrypt) \u2705 Available HTTP-01 challenge via Gateway Gateway API CRDs \u2705 Installed ReferenceGrant, HTTPRoute Envoy Gateway \u2705 Running Supports dynamic listeners"},{"location":"prd/dynamic_https_listeners/#new-requirements","title":"New Requirements","text":"Component Action Priority Controller RBAC Add Gateway patch permission High Controller Logic Implement HTTPS route sync High Default Issuer Configure in master-config Medium Listener cleanup Implement deletion logic High"},{"location":"prd/dynamic_https_listeners/#testing-plan","title":"Testing Plan","text":""},{"location":"prd/dynamic_https_listeners/#unit-tests","title":"Unit Tests","text":"<ul> <li> Certificate name generation</li> <li> Listener name generation (avoid conflicts)</li> <li> ReferenceGrant creation</li> <li> Gateway patch logic</li> </ul>"},{"location":"prd/dynamic_https_listeners/#integration-tests","title":"Integration Tests","text":"<ul> <li> Certificate issuance flow</li> <li> Gateway listener addition/removal</li> <li> HTTPRoute attachment to listener</li> <li> End-to-end HTTPS access</li> </ul>"},{"location":"prd/dynamic_https_listeners/#e2e-tests","title":"E2E Tests","text":"<ul> <li> Create service with <code>expose-route: https</code></li> <li> Verify certificate issued</li> <li> Verify HTTPS access works</li> <li> Verify cleanup on service deletion</li> </ul>"},{"location":"prd/dynamic_https_listeners/#rollout-plan","title":"Rollout Plan","text":""},{"location":"prd/dynamic_https_listeners/#phase-1-implementation","title":"Phase 1: Implementation","text":"<ul> <li>Implement controller logic</li> <li>Add RBAC permissions</li> <li>Unit tests</li> </ul>"},{"location":"prd/dynamic_https_listeners/#phase-2-testing","title":"Phase 2: Testing","text":"<ul> <li>Integration tests in dev cluster</li> <li>E2E tests</li> </ul>"},{"location":"prd/dynamic_https_listeners/#phase-3-documentation","title":"Phase 3: Documentation","text":"<ul> <li>Update examples</li> <li>Update README</li> </ul>"},{"location":"prd/dynamic_https_listeners/#phase-4-release","title":"Phase 4: Release","text":"<ul> <li>Deploy to staging</li> <li>User acceptance testing</li> <li>Production rollout</li> </ul>"},{"location":"prd/dynamic_https_listeners/#open-questions","title":"Open Questions","text":"<ol> <li>Issuer Configuration: Should we require an Issuer per namespace or use a ClusterIssuer?</li> <li> <p>Recommendation: Support both, default to namespace Issuer named <code>letsencrypt</code></p> </li> <li> <p>Certificate Renewal: How to handle certificate renewal with listener?</p> </li> <li> <p>cert-manager handles renewal automatically, secret is updated in place</p> </li> <li> <p>Listener Limits: Is there a max number of listeners on Gateway?</p> </li> <li> <p>Envoy Gateway: No hard limit, but monitor performance</p> </li> <li> <p>Custom Domains: How to handle DNS validation for non-base-domain hostnames?</p> </li> <li>Recommendation: Require DNS-01 capable Issuer for custom domains</li> </ol>"},{"location":"prd/dynamic_https_listeners/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Wildcard Certificate Option: Single <code>*.{base_domain}</code> cert for simpler setup</li> <li>mTLS Support: Client certificate verification</li> <li>HTTP\u2192HTTPS Redirect: Automatic redirect from HTTP to HTTPS</li> <li>HSTS Headers: Automatic HSTS header injection</li> </ol>"},{"location":"prd/endpoint_for_lb/","title":"PRD: Automatic External Endpoints for LoadBalancer Services","text":"<p>Status: \u2705 Implemented Version: v0.1.34-dev1 Date: 2025-11-19  </p>"},{"location":"prd/endpoint_for_lb/#problem-statement","title":"Problem Statement","text":"<p>When using LoadBalancer services in kube-dc multi-tenant VPC environments, external clients (such as Kamaji controllers, CI/CD systems, or other tenants) need stable DNS-based access to these services. Currently, users must:</p> <ol> <li>Manually discover the LoadBalancer's external IP address</li> <li>Hardcode IPs in configurations, certificates, and kubeconfigs</li> <li>Manually create and maintain Service/Endpoints pairs for external access</li> <li>Track and update these endpoints whenever LoadBalancer IPs change</li> </ol> <p>This creates operational burden and increases the risk of configuration drift, especially in multi-tenant scenarios where LoadBalancers are frequently created, updated, or recreated.</p>"},{"location":"prd/endpoint_for_lb/#real-world-impact","title":"Real-World Impact","text":"<p>Scenario: Kamaji Multi-Tenant Setup - Kamaji controller runs in <code>kamaji-system</code> namespace - Tenant control planes run in tenant VPC namespaces (e.g., <code>shalb-envoy</code>) - etcd cluster exposed via LoadBalancer with external IP <code>168.119.17.55</code> - Kamaji cannot reach <code>etcd.shalb-envoy.svc.cluster.local</code> (internal ClusterIP) due to network isolation - Must use external IP <code>168.119.17.55:2379</code> in DataStore configuration - When LoadBalancer is recreated, IP changes, breaking all references</p> <p>Current Workaround: <pre><code># Manual Service + Endpoints creation\napiVersion: v1\nkind: Service\nmetadata:\n  name: etcd-lb-ext\n  namespace: shalb-envoy\nspec:\n  type: ClusterIP\n  clusterIP: None\n  ports:\n  - port: 2379\n---\napiVersion: v1\nkind: Endpoints\nmetadata:\n  name: etcd-lb-ext\n  namespace: shalb-envoy\nsubsets:\n  - addresses:\n      - ip: 168.119.17.55  # Must be manually updated!\n    ports:\n      - port: 2379\n</code></pre></p> <p>Then Kamaji can use: <code>etcd-lb-ext.shalb-envoy.svc.cluster.local:2379</code></p>"},{"location":"prd/endpoint_for_lb/#implemented-solution","title":"Implemented Solution","text":"<p>Automatically create and manage external endpoints for every LoadBalancer service managed by kube-dc. The service controller:</p> <ol> <li>Creates a headless Service + Endpoints pair when a LoadBalancer is created</li> <li>Updates the Endpoints IP when the LoadBalancer's external IP changes</li> <li>Deletes the external endpoint pair when the LoadBalancer is deleted</li> <li>Supports multiple endpoints if a LoadBalancer has multiple external IPs</li> </ol>"},{"location":"prd/endpoint_for_lb/#naming-convention","title":"Naming Convention","text":"<p>For a LoadBalancer service named <code>&lt;service-name&gt;</code>, create: - Service: <code>&lt;service-name&gt;-ext</code> (headless ClusterIP: None) - Endpoints: <code>&lt;service-name&gt;-ext</code> (pointing to LoadBalancer external IP)</p> <p>Examples: - <code>etcd-lb</code> \u2192 <code>etcd-lb-ext.shalb-envoy.svc.cluster.local</code> - <code>cluster-a-cp</code> \u2192 <code>cluster-a-cp-ext.shalb-envoy.svc.cluster.local</code> - <code>api-gateway</code> \u2192 <code>api-gateway-ext.tenant-ns.svc.cluster.local</code></p>"},{"location":"prd/endpoint_for_lb/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 kube-dc Service Controller (internal/controller/core/service_controller.go) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u251c\u2500 Reconcile LoadBalancer Service\n                              \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502                              \u2502\n                \u25bc                              \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 EIP Management     \u2502        \u2502 External Endpoint Mgmt \u2502\n    \u2502 (existing)         \u2502        \u2502 (NEW)                  \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 - Create EIP       \u2502        \u2502 - Create Service-ext   \u2502\n    \u2502 - Bind to LB       \u2502        \u2502 - Create Endpoints     \u2502\n    \u2502 - Update status    \u2502        \u2502 - Update on IP change  \u2502\n    \u2502 - Delete on remove \u2502        \u2502 - Delete on LB delete  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502                              \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u25bc\n                    LoadBalancer gets external IP\n                               \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u25bc                             \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Service: etcd-lb    \u2502      \u2502 Service: etcd-lb-ext\u2502\n    \u2502 Type: LoadBalancer  \u2502      \u2502 Type: ClusterIP     \u2502\n    \u2502 ExternalIP:         \u2502      \u2502 ClusterIP: None     \u2502\n    \u2502   168.119.17.55     \u2502      \u2502                     \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                           \u2502\n                                           \u25bc\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 Endpoints: etcd-lb-ext   \u2502\n                              \u2502 IP: 168.119.17.55        \u2502\n                              \u2502 Port: 2379               \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/endpoint_for_lb/#technical-specification","title":"Technical Specification","text":""},{"location":"prd/endpoint_for_lb/#1-service-resource-structure","title":"1. Service Resource Structure","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: &lt;service-name&gt;-ext\n  namespace: &lt;service-namespace&gt;\n  labels:\n    kube-dc.com/managed-by: service-lb-controller\n    kube-dc.com/source-service: &lt;service-name&gt;\n    kube-dc.com/endpoint-type: external\n  ownerReferences:\n  - apiVersion: v1\n    kind: Service\n    name: &lt;service-name&gt;\n    uid: &lt;service-uid&gt;\n    controller: true\n    blockOwnerDeletion: true\nspec:\n  type: ClusterIP\n  clusterIP: None  # Headless service\n  ports:\n  - name: &lt;port-name&gt;\n    port: &lt;port&gt;\n    protocol: &lt;protocol&gt;\n  # Copy all ports from source LoadBalancer service\n</code></pre>"},{"location":"prd/endpoint_for_lb/#2-endpoints-resource-structure","title":"2. Endpoints Resource Structure","text":"<pre><code>apiVersion: v1\nkind: Endpoints\nmetadata:\n  name: &lt;service-name&gt;-ext\n  namespace: &lt;service-namespace&gt;\n  labels:\n    kube-dc.com/managed-by: service-lb-controller\n    kube-dc.com/source-service: &lt;service-name&gt;\n    kube-dc.com/endpoint-type: external\n  ownerReferences:\n  - apiVersion: v1\n    kind: Service\n    name: &lt;service-name&gt;-ext\n    uid: &lt;service-ext-uid&gt;\n    controller: true\n    blockOwnerDeletion: true\nsubsets:\n  - addresses:\n      - ip: &lt;loadbalancer-external-ip-1&gt;\n      - ip: &lt;loadbalancer-external-ip-2&gt;  # If multiple IPs\n    ports:\n      - name: &lt;port-name&gt;\n        port: &lt;port&gt;\n        protocol: &lt;protocol&gt;\n</code></pre>"},{"location":"prd/endpoint_for_lb/#3-controller-logic-implemented","title":"3. Controller Logic (Implemented)","text":""},{"location":"prd/endpoint_for_lb/#file-internalservice_lbexternal_endpointgo","title":"File: <code>internal/service_lb/external_endpoint.go</code>","text":"<pre><code>package servicelb\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    corev1 \"k8s.io/api/core/v1\"\n    metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n    \"sigs.k8s.io/controller-runtime/pkg/client\"\n    \"sigs.k8s.io/controller-runtime/pkg/controller/controllerutil\"\n)\n\nconst (\n    ExternalEndpointSuffix = \"-ext\"\n    ManagedByLabel         = \"kube-dc.com/managed-by\"\n    SourceServiceLabel     = \"kube-dc.com/source-service\"\n    EndpointTypeLabel      = \"kube-dc.com/endpoint-type\"\n    ControllerName         = \"service-lb-controller\"\n)\n\n// ExternalEndpointManager manages external endpoint resources for LoadBalancer services\ntype ExternalEndpointManager struct {\n    client.Client\n    Service *corev1.Service\n}\n\n// Sync creates or updates external Service and Endpoints\nfunc (m *ExternalEndpointManager) Sync(ctx context.Context) error {\n    if m.Service.Spec.Type != corev1.ServiceTypeLoadBalancer {\n        return nil // Only for LoadBalancer services\n    }\n\n    externalIPs := m.getExternalIPs()\n    if len(externalIPs) == 0 {\n        // LoadBalancer not ready yet, skip\n        return nil\n    }\n\n    // Create or update external Service\n    if err := m.syncExternalService(ctx); err != nil {\n        return fmt.Errorf(\"failed to sync external service: %w\", err)\n    }\n\n    // Create or update Endpoints\n    if err := m.syncEndpoints(ctx, externalIPs); err != nil {\n        return fmt.Errorf(\"failed to sync endpoints: %w\", err)\n    }\n\n    return nil\n}\n\n// Delete removes external Service and Endpoints\nfunc (m *ExternalEndpointManager) Delete(ctx context.Context) error {\n    extSvcName := m.getExternalServiceName()\n\n    // Delete external Service (Endpoints will be cascaded via ownerReference)\n    extSvc := &amp;corev1.Service{\n        ObjectMeta: metav1.ObjectMeta{\n            Name:      extSvcName,\n            Namespace: m.Service.Namespace,\n        },\n    }\n\n    if err := m.Client.Delete(ctx, extSvc); client.IgnoreNotFound(err) != nil {\n        return fmt.Errorf(\"failed to delete external service: %w\", err)\n    }\n\n    return nil\n}\n\nfunc (m *ExternalEndpointManager) getExternalServiceName() string {\n    return m.Service.Name + ExternalEndpointSuffix\n}\n\nfunc (m *ExternalEndpointManager) getExternalIPs() []string {\n    ips := []string{}\n    for _, ingress := range m.Service.Status.LoadBalancer.Ingress {\n        if ingress.IP != \"\" {\n            ips = append(ips, ingress.IP)\n        }\n    }\n    return ips\n}\n\nfunc (m *ExternalEndpointManager) syncExternalService(ctx context.Context) error {\n    extSvcName := m.getExternalServiceName()\n    extSvc := &amp;corev1.Service{\n        ObjectMeta: metav1.ObjectMeta{\n            Name:      extSvcName,\n            Namespace: m.Service.Namespace,\n        },\n    }\n\n    _, err := controllerutil.CreateOrUpdate(ctx, m.Client, extSvc, func() error {\n        // Set labels\n        if extSvc.Labels == nil {\n            extSvc.Labels = make(map[string]string)\n        }\n        extSvc.Labels[ManagedByLabel] = ControllerName\n        extSvc.Labels[SourceServiceLabel] = m.Service.Name\n        extSvc.Labels[EndpointTypeLabel] = \"external\"\n\n        // Set controller reference (ensures garbage collection)\n        if err := controllerutil.SetControllerReference(m.Service, extSvc, m.Scheme()); err != nil {\n            return err\n        }\n\n        // Configure as headless service\n        extSvc.Spec.Type = corev1.ServiceTypeClusterIP\n        extSvc.Spec.ClusterIP = corev1.ClusterIPNone\n\n        // Copy ports from source service\n        extSvc.Spec.Ports = []corev1.ServicePort{}\n        for _, port := range m.Service.Spec.Ports {\n            extSvc.Spec.Ports = append(extSvc.Spec.Ports, corev1.ServicePort{\n                Name:     port.Name,\n                Port:     port.Port,\n                Protocol: port.Protocol,\n            })\n        }\n\n        return nil\n    })\n\n    return err\n}\n\nfunc (m *ExternalEndpointManager) syncEndpoints(ctx context.Context, externalIPs []string) error {\n    extSvcName := m.getExternalServiceName()\n    endpoints := &amp;corev1.Endpoints{\n        ObjectMeta: metav1.ObjectMeta{\n            Name:      extSvcName,\n            Namespace: m.Service.Namespace,\n        },\n    }\n\n    _, err := controllerutil.CreateOrUpdate(ctx, m.Client, endpoints, func() error {\n        // Set labels\n        if endpoints.Labels == nil {\n            endpoints.Labels = make(map[string]string)\n        }\n        endpoints.Labels[ManagedByLabel] = ControllerName\n        endpoints.Labels[SourceServiceLabel] = m.Service.Name\n        endpoints.Labels[EndpointTypeLabel] = \"external\"\n\n        // Get external service for owner reference\n        extSvc := &amp;corev1.Service{}\n        if err := m.Client.Get(ctx, client.ObjectKey{\n            Name:      extSvcName,\n            Namespace: m.Service.Namespace,\n        }, extSvc); err != nil {\n            return fmt.Errorf(\"failed to get external service: %w\", err)\n        }\n\n        // Set controller reference to external service\n        if err := controllerutil.SetControllerReference(extSvc, endpoints, m.Scheme()); err != nil {\n            return err\n        }\n\n        // Build addresses\n        addresses := []corev1.EndpointAddress{}\n        for _, ip := range externalIPs {\n            addresses = append(addresses, corev1.EndpointAddress{\n                IP: ip,\n            })\n        }\n\n        // Build ports\n        ports := []corev1.EndpointPort{}\n        for _, port := range m.Service.Spec.Ports {\n            ports = append(ports, corev1.EndpointPort{\n                Name:     port.Name,\n                Port:     port.Port,\n                Protocol: port.Protocol,\n            })\n        }\n\n        // Set subsets\n        endpoints.Subsets = []corev1.EndpointSubset{\n            {\n                Addresses: addresses,\n                Ports:     ports,\n            },\n        }\n\n        return nil\n    })\n\n    return err\n}\n</code></pre>"},{"location":"prd/endpoint_for_lb/#integration-in-service_controllergo","title":"Integration in <code>service_controller.go</code>","text":"<pre><code>// In reconcileSync function, after EIP and LoadBalancer sync:\n\nfunc (r *ServiceReconciler) reconcileSync(ctx context.Context, req ctrl.Request, svc *corev1.Service, endpoints *corev1.Endpoints, project *kubedccomv1.Project) (ctrl.Result, error) {\n    log := log.FromContext(ctx).WithName(\"Sync:\").WithValues(\"ServiceLoadBalancer\", req.Name)\n\n    // ... existing EIP sync ...\n\n    // ... existing LoadBalancer sync ...\n\n    // ... existing external IP status update ...\n\n    // NEW: Sync external endpoints for cross-VPC access\n    extEndpointMgr := &amp;serviceLb.ExternalEndpointManager{\n        Client:  r.Client,\n        Service: svc,\n    }\n    if err := extEndpointMgr.Sync(ctx); err != nil {\n        log.Error(err, \"Failed to sync external endpoints\")\n        // Don't fail the reconciliation, just log the error\n    }\n\n    return ctrl.Result{}, nil\n}\n\n// In reconcileDelete function:\n\nfunc (r *ServiceReconciler) reconcileDelete(ctx context.Context, req ctrl.Request, svc *corev1.Service, endpoints *corev1.Endpoints, project *kubedccomv1.Project) (ctrl.Result, error) {\n    log := log.FromContext(ctx).WithName(\"Delete:\").WithValues(\"ServiceLoadBalancer\", req.Name)\n\n    // NEW: Delete external endpoints first\n    extEndpointMgr := &amp;serviceLb.ExternalEndpointManager{\n        Client:  r.Client,\n        Service: svc,\n    }\n    if err := extEndpointMgr.Delete(ctx); err != nil {\n        log.Error(err, \"Failed to delete external endpoints\")\n    }\n\n    // ... existing EIP and LoadBalancer delete logic ...\n\n    return ctrl.Result{}, nil\n}\n</code></pre>"},{"location":"prd/endpoint_for_lb/#4-rbac-permissions","title":"4. RBAC Permissions","text":"<p>Add to <code>config/rbac/role.yaml</code>:</p> <pre><code>- apiGroups: [\"\"]\n  resources: [\"services\", \"endpoints\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n</code></pre>"},{"location":"prd/endpoint_for_lb/#benefits","title":"Benefits","text":""},{"location":"prd/endpoint_for_lb/#1-operational-simplicity","title":"1. Operational Simplicity","text":"<ul> <li>Zero manual intervention: Endpoints created/updated automatically</li> <li>Self-healing: Endpoints always reflect current LoadBalancer IPs</li> <li>Consistent naming: Predictable <code>-ext</code> suffix convention</li> </ul>"},{"location":"prd/endpoint_for_lb/#2-multi-tenant-support","title":"2. Multi-Tenant Support","text":"<ul> <li>Cross-VPC access: External endpoints work across network boundaries</li> <li>Stable DNS: Use <code>&lt;service&gt;-ext.namespace.svc.cluster.local</code> in all configs</li> <li>No IP hardcoding: Certificates, kubeconfigs, and DataStores use DNS names</li> </ul>"},{"location":"prd/endpoint_for_lb/#3-resilience","title":"3. Resilience","text":"<ul> <li>Owner references: Automatic cleanup when services are deleted</li> <li>Reconciliation: Controller ensures consistency even after disruptions</li> <li>Multiple IPs: Supports LoadBalancers with multiple external IPs</li> </ul>"},{"location":"prd/endpoint_for_lb/#use-cases","title":"Use Cases","text":""},{"location":"prd/endpoint_for_lb/#1-kamaji-multi-tenant-control-planes-primary-use-case","title":"1. Kamaji Multi-Tenant Control Planes \u2b50 PRIMARY USE CASE","text":"<p>Problem: Kamaji controller in <code>kamaji-system</code> cannot reach etcd in tenant VPC via ClusterIP.</p> <p>Current (manual): <pre><code>apiVersion: kamaji.clastix.io/v1alpha1\nkind: DataStore\nmetadata:\n  name: shalb-envoy-etcd\nspec:\n  driver: etcd\n  endpoints:\n  - 168.119.17.55:2379  # \u274c Hardcoded IP - breaks when service recreated\n</code></pre></p> <p>With auto-managed endpoints: <pre><code>apiVersion: kamaji.clastix.io/v1alpha1\nkind: DataStore\nmetadata:\n  name: shalb-envoy-etcd\nspec:\n  driver: etcd\n  endpoints:\n  - etcd-lb-ext.shalb-envoy.svc.cluster.local:2379  # \u2705 Stable DNS name\n  tlsConfig:\n    # ... certificates with DNS SANs (not IP SANs)\n</code></pre></p> <p>How it works: 1. LoadBalancer <code>etcd-lb</code> gets external IP <code>168.119.17.55</code> 2. Controller auto-creates Service <code>etcd-lb-ext</code> (headless) 3. Controller auto-creates Endpoints <code>etcd-lb-ext</code> pointing to <code>168.119.17.55</code> 4. Kamaji resolves <code>etcd-lb-ext.shalb-envoy.svc.cluster.local</code> \u2192 <code>168.119.17.55</code> 5. When IP changes, controller updates Endpoints automatically 6. No DataStore configuration change needed!</p>"},{"location":"prd/endpoint_for_lb/#2-cross-tenant-api-access","title":"2. Cross-Tenant API Access","text":"<pre><code># Tenant A accessing Tenant B's API\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: tenant-b-access\n  namespace: tenant-a\ndata:\n  api-endpoint: https://api-gateway-ext.tenant-b.svc.cluster.local:8443\n</code></pre>"},{"location":"prd/endpoint_for_lb/#3-cicd-integration","title":"3. CI/CD Integration","text":"<pre><code># CI pipeline can use stable DNS names\nkubectl --kubeconfig=/tmp/kubeconfig \\\n  --server=https://cluster-ext.tenant-prod.svc.cluster.local:6443 \\\n  get nodes\n</code></pre>"},{"location":"prd/endpoint_for_lb/#testing-strategy","title":"Testing Strategy","text":""},{"location":"prd/endpoint_for_lb/#unit-tests","title":"Unit Tests","text":"<ul> <li>Test Service creation with correct naming and labels</li> <li>Test Endpoints creation with correct IPs and ports</li> <li>Test update when LoadBalancer IP changes</li> <li>Test deletion and cleanup</li> <li>Test multiple external IPs</li> </ul>"},{"location":"prd/endpoint_for_lb/#integration-tests","title":"Integration Tests","text":"<ol> <li>Create LoadBalancer service</li> <li>Verify <code>-ext</code> Service and Endpoints are created</li> <li>Verify DNS resolves to external IP</li> <li>Update LoadBalancer (trigger IP change)</li> <li>Verify Endpoints updated with new IP</li> <li>Delete LoadBalancer</li> <li>Verify <code>-ext</code> resources cleaned up</li> </ol>"},{"location":"prd/endpoint_for_lb/#e2e-tests","title":"E2E Tests","text":"<ul> <li>Deploy Kamaji with multi-tenant setup</li> <li>Verify etcd DataStore works with <code>-ext</code> endpoint</li> <li>Verify TenantControlPlane can access etcd</li> <li>Simulate IP change and verify automatic reconciliation</li> </ul>"},{"location":"prd/endpoint_for_lb/#implementation-status","title":"Implementation Status","text":""},{"location":"prd/endpoint_for_lb/#phase-1-core-implementation-complete","title":"Phase 1: Core Implementation \u2705 Complete","text":"<ul> <li> Create <code>external_endpoint.go</code> with manager logic</li> <li> Integrate into <code>service_controller.go</code></li> <li> Add RBAC permissions for endpoints</li> <li> Documentation in <code>docs/tutorial-ip-and-lb.md</code></li> <li> Documentation in <code>docs/architecture-networking.md</code></li> </ul>"},{"location":"prd/endpoint_for_lb/#phase-2-deployment-testing-complete","title":"Phase 2: Deployment &amp; Testing \u2705 Complete","text":"<ul> <li> Deploy to staging environment (v0.1.34-dev1)</li> <li> Verified 10+ LoadBalancer services automatically got external endpoints</li> <li> DNS resolution tested and working</li> </ul>"},{"location":"prd/endpoint_for_lb/#test-results-2025-11-19","title":"Test Results (2025-11-19)","text":"<pre><code># All LoadBalancer services automatically got -ext endpoints:\n$ kubectl get endpoints -A --selector=kube-dc.com/managed-by=service-lb-controller\nNAMESPACE     NAME                                     ENDPOINTS\nshalb-dev     etcd-lb-ext                              168.119.17.51:2379\nshalb-dev     kamaji-demo-cp-ext                       168.119.17.59:6443\nshalb-dev     debug-net-lb-ext                         168.119.17.51:80,168.119.17.51:443\nshalb-envoy   cluster-a-cp-ext                         168.119.17.53:6443\nshalb-envoy   etcd-lb-ext                              168.119.17.55:2379,168.119.17.55:6443\n...\n\n# DNS resolution verified:\n$ kubectl run -it --rm debug --image=busybox -- nslookup etcd-lb-ext.shalb-dev.svc.cluster.local\nName:   etcd-lb-ext.shalb-dev.svc.cluster.local\nAddress: 168.119.17.51\n</code></pre>"},{"location":"prd/endpoint_for_lb/#backwards-compatibility","title":"Backwards Compatibility","text":"<p>This feature is fully backwards compatible: - Existing LoadBalancer services continue to work unchanged - External endpoints are additive (new resources only) - No breaking changes to existing APIs or configurations - Users can opt-out by deleting the <code>-ext</code> resources (controller will recreate, but won't affect original service)</p>"},{"location":"prd/endpoint_for_lb/#success-metrics","title":"Success Metrics","text":"<ul> <li>Automation rate: 100% of LoadBalancer services have external endpoints</li> <li>Manual interventions: Reduce IP update operations to zero</li> <li>Reconciliation time: External endpoints updated within 10 seconds of IP change</li> <li>Error rate: &lt; 0.1% endpoint sync failures</li> </ul>"},{"location":"prd/endpoint_for_lb/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Configurable naming: Annotation to customize <code>-ext</code> suffix</li> <li>Selective enablement: Annotation to opt-in/opt-out per service</li> <li>External DNS integration: Automatically create DNS records</li> <li>Metrics: Prometheus metrics for endpoint sync operations</li> <li>Webhook validation: Prevent manual modification of managed resources</li> <li>Kamaji DataStore CRD enhancement: Add <code>externalNetworkType</code> field to Kamaji DataStore CRD to allow users to specify which external network type (<code>cloud</code> or <code>public</code>) to use when connecting via external endpoints. This ensures proper network routing and IP allocation matching the infrastructure requirements</li> </ol>"},{"location":"prd/endpoint_for_lb/#related-files","title":"Related Files","text":"<ul> <li><code>internal/service_lb/external_endpoint.go</code> - External endpoint manager implementation</li> <li><code>internal/controller/core/service_controller.go</code> - Service controller integration</li> <li><code>docs/tutorial-ip-and-lb.md</code> - User documentation</li> <li><code>docs/architecture-networking.md</code> - Architecture documentation</li> </ul>"},{"location":"prd/endpoint_for_lb/#related-documentation","title":"Related Documentation","text":"<ul> <li>Kamaji Multi-Tenant Architecture: <code>/examples/kamaji-capi/mt/README.md</code></li> <li>Service LoadBalancer Architecture: <code>/docs/prd/svc_lb_architecture.md</code></li> <li>EIP Management: <code>/internal/eip/</code></li> </ul>"},{"location":"prd/gateway_sharding/","title":"PRD: Gateway Sharding for Scale","text":""},{"location":"prd/gateway_sharding/#overview","title":"Overview","text":"<p>This document outlines enhancement options for scaling the Gateway infrastructure to support thousands of tenants and services in Kube-DC.</p>"},{"location":"prd/gateway_sharding/#problem-statement","title":"Problem Statement","text":"<p>The current implementation creates a per-service HTTPS listener on a single shared Gateway. This approach has scaling limitations:</p> Constraint Limit Impact Envoy listeners per Gateway ~100-1000 Hard limit on services with <code>expose-route: https</code> Gateway memory Proportional to listeners Memory pressure with many listeners Configuration reload time Increases with listeners Slower route updates Single point of failure 1 Gateway All tenants affected by Gateway issues"},{"location":"prd/gateway_sharding/#current-architecture","title":"Current Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Single Gateway \"eg\"                               \u2502\n\u2502                 (envoy-gateway-system)                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Listeners:                                                          \u2502\n\u2502  - http :80 (shared)                                                \u2502\n\u2502  - tls-passthrough :443 (wildcard)                                  \u2502\n\u2502  - https-svc1-ns1 :443 (per-service)  \u2190\u2500\u2510                          \u2502\n\u2502  - https-svc2-ns1 :443 (per-service)    \u2502 N listeners              \u2502\n\u2502  - https-svc3-ns2 :443 (per-service)    \u2502 (scales linearly)        \u2502\n\u2502  - ...                                \u2190\u2500\u2518                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u25bc               \u25bc               \u25bc\n         Org A (N svcs)  Org B (N svcs)  Org C (N svcs)\n</code></pre>"},{"location":"prd/gateway_sharding/#proposed-solutions","title":"Proposed Solutions","text":""},{"location":"prd/gateway_sharding/#option-1-wildcard-listeners-per-organization","title":"Option 1: Wildcard Listeners per Organization","text":"<p>Concept: Replace per-service listeners with wildcard listeners per organization.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Single Gateway \"eg\"                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Listeners:                                                          \u2502\n\u2502  - http :80                                                         \u2502\n\u2502  - tls-passthrough :443                                             \u2502\n\u2502  - https-org-a :443 (*.org-a.kube-dc.com)  \u2190\u2500\u2510                     \u2502\n\u2502  - https-org-b :443 (*.org-b.kube-dc.com)    \u2502 M listeners         \u2502\n\u2502  - https-org-c :443 (*.org-c.kube-dc.com)  \u2190\u2500\u2518 (M = # of orgs)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits: - Reduces listeners from N (services) to M (organizations) - Single wildcard certificate per organization - SNI routing handles service selection within listener</p> <p>Requirements: - Wildcard certificate issuance per organization - DNS wildcard records per organization - Organization controller creates listener when org is created</p> <p>Implementation Complexity: Medium</p>"},{"location":"prd/gateway_sharding/#option-2-gateway-per-organization","title":"Option 2: Gateway per Organization","text":"<p>Concept: Each organization gets its own dedicated Gateway instance.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Gateway \"gw-org-a\" \u2502  \u2502  Gateway \"gw-org-b\" \u2502  \u2502  Gateway \"gw-org-c\" \u2502\n\u2502  IP: 88.99.29.250   \u2502  \u2502  IP: 88.99.29.251   \u2502  \u2502  IP: 88.99.29.252   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  *.org-a.kube-dc.com\u2502  \u2502  *.org-b.kube-dc.com\u2502  \u2502  *.org-c.kube-dc.com\u2502\n\u2502  - All org A routes \u2502  \u2502  - All org B routes \u2502  \u2502  - All org C routes \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits: - Complete isolation between organizations - No listener limits per org (own Gateway) - Independent scaling and upgrades - Failure isolation</p> <p>Requirements: - EIP allocation per organization Gateway - GatewayClass configuration for multi-Gateway - Organization controller provisions Gateway</p> <p>Implementation Complexity: High</p>"},{"location":"prd/gateway_sharding/#option-3-hash-based-gateway-sharding","title":"Option 3: Hash-Based Gateway Sharding","text":"<p>Concept: Distribute services across N Gateway instances using consistent hashing.</p> <pre><code>                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                         \u2502   Hash Function  \u2502\n                         \u2502  hash(hostname)  \u2502\n                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u25bc                   \u25bc                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Gateway \"gw-0\"    \u2502 \u2502   Gateway \"gw-1\"    \u2502 \u2502   Gateway \"gw-2\"    \u2502\n\u2502   hash % 3 == 0     \u2502 \u2502   hash % 3 == 1     \u2502 \u2502   hash % 3 == 2     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits: - Even distribution across Gateways - Scales horizontally by adding Gateways - No org-specific infrastructure</p> <p>Requirements: - DNS-based load balancing or L4 load balancer - Consistent hashing for stable assignments - Gateway selector in route controller</p> <p>Implementation Complexity: High</p>"},{"location":"prd/gateway_sharding/#option-4-hybrid-approach-recommended","title":"Option 4: Hybrid Approach (Recommended)","text":"<p>Concept: Combine wildcard listeners with optional Gateway sharding.</p> <p>Phase 1 (Quick Win): - Convert per-service listeners to per-organization wildcard listeners - Single Gateway, wildcard cert per org - Reduces N services \u2192 M orgs listeners</p> <p>Phase 2 (Scale Out): - Add Gateway per org for large organizations - Small orgs share \"default\" Gateway - Org annotation controls Gateway assignment</p> <pre><code># Organization with dedicated Gateway\napiVersion: kube-dc.com/v1\nkind: Organization\nmetadata:\n  name: large-enterprise\nspec:\n  gateway:\n    dedicated: true  # Gets its own Gateway\n\n# Small org uses shared Gateway\napiVersion: kube-dc.com/v1\nkind: Organization\nmetadata:\n  name: small-startup\nspec:\n  gateway:\n    dedicated: false  # Uses shared Gateway (default)\n</code></pre>"},{"location":"prd/gateway_sharding/#comparison-matrix","title":"Comparison Matrix","text":"Aspect Current Option 1 Option 2 Option 3 Option 4 Max Services ~1000 ~100K Unlimited Unlimited Unlimited Isolation None Partial Full None Configurable IP Usage 1 1 N (per org) K (shards) 1 + N (large orgs) Complexity Low Medium High High Medium Cert Management Per-service Per-org wildcard Per-org wildcard Per-service Per-org wildcard Failure Domain All tenants All tenants Per org Per shard Configurable"},{"location":"prd/gateway_sharding/#recommended-approach","title":"Recommended Approach","text":""},{"location":"prd/gateway_sharding/#short-term-option-1","title":"Short Term (Option 1)","text":"<ol> <li>Implement wildcard listeners per organization</li> <li>Use wildcard certificates (<code>*.{org}.{base_domain}</code>)</li> <li>SNI routing within listener for service selection</li> <li>Keep single Gateway</li> </ol>"},{"location":"prd/gateway_sharding/#medium-term-option-4-phase-2","title":"Medium Term (Option 4 - Phase 2)","text":"<ol> <li>Add <code>spec.gateway.dedicated</code> to Organization CRD</li> <li>Organization controller provisions Gateway for dedicated orgs</li> <li>Small orgs continue using shared Gateway</li> <li>Automatic EIP allocation for dedicated Gateways</li> </ol>"},{"location":"prd/gateway_sharding/#implementation-details","title":"Implementation Details","text":""},{"location":"prd/gateway_sharding/#wildcard-listener-creation-option-1","title":"Wildcard Listener Creation (Option 1)","text":"<pre><code>// In organization controller\nfunc (r *OrganizationReconciler) syncGatewayListener(ctx context.Context, org *Organization) error {\n    listenerName := fmt.Sprintf(\"https-%s\", org.Name)\n    hostname := fmt.Sprintf(\"*.%s.%s\", org.Name, baseDomain)\n\n    // Create wildcard certificate\n    cert := &amp;certmanagerv1.Certificate{\n        Spec: certmanagerv1.CertificateSpec{\n            SecretName: fmt.Sprintf(\"%s-wildcard-tls\", org.Name),\n            DNSNames:   []string{hostname},\n            IssuerRef:  cmmeta.ObjectReference{Name: \"letsencrypt\", Kind: \"ClusterIssuer\"},\n        },\n    }\n\n    // Patch Gateway with new listener\n    return patchGatewayAddListener(ctx, listenerName, hostname, cert.Spec.SecretName)\n}\n</code></pre>"},{"location":"prd/gateway_sharding/#service-route-changes","title":"Service Route Changes","text":"<pre><code>// In service_lb/gateway_route.go\nfunc (m *GatewayRouteManager) syncHTTPSRoute(ctx context.Context, hostname string, port int32) error {\n    // With wildcard listeners, we DON'T create per-service listeners\n    // Just create HTTPRoute pointing to org's wildcard listener\n\n    org := m.getOrganization()\n    listenerName := fmt.Sprintf(\"https-%s\", org)\n\n    // Create HTTPRoute (no listener creation needed)\n    return m.syncHTTPSHTTPRoute(ctx, hostname, port, listenerName)\n}\n</code></pre>"},{"location":"prd/gateway_sharding/#dns-requirements","title":"DNS Requirements","text":""},{"location":"prd/gateway_sharding/#current-per-service","title":"Current (Per-Service)","text":"<pre><code>svc1-ns1.stage.kube-dc.com  \u2192 Gateway IP\nsvc2-ns1.stage.kube-dc.com  \u2192 Gateway IP\nsvc3-ns2.stage.kube-dc.com  \u2192 Gateway IP\n</code></pre>"},{"location":"prd/gateway_sharding/#with-wildcard-per-organization","title":"With Wildcard (Per-Organization)","text":"<pre><code>*.org-a.stage.kube-dc.com   \u2192 Gateway IP (wildcard record)\n*.org-b.stage.kube-dc.com   \u2192 Gateway IP (wildcard record)\n</code></pre>"},{"location":"prd/gateway_sharding/#certificate-requirements","title":"Certificate Requirements","text":""},{"location":"prd/gateway_sharding/#current","title":"Current","text":"<ul> <li>Per-service certificate via HTTP-01 challenge</li> <li>Certificate per hostname</li> </ul>"},{"location":"prd/gateway_sharding/#with-wildcard","title":"With Wildcard","text":"<ul> <li>Per-organization wildcard certificate</li> <li>Requires DNS-01 challenge (not HTTP-01)</li> <li>Issuer must support DNS-01 (e.g., with Cloudflare, Route53, etc.)</li> </ul> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-dns\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: admin@kube-dc.com\n    privateKeySecretRef:\n      name: letsencrypt-dns-key\n    solvers:\n    - dns01:\n        cloudflare:\n          email: admin@kube-dc.com\n          apiKeySecretRef:\n            name: cloudflare-api-key\n            key: api-key\n</code></pre>"},{"location":"prd/gateway_sharding/#migration-path","title":"Migration Path","text":""},{"location":"prd/gateway_sharding/#phase-1-parallel-operation","title":"Phase 1: Parallel Operation","text":"<ol> <li>Keep existing per-service listeners working</li> <li>Add wildcard listener for new organizations</li> <li>New services use wildcard listener</li> </ol>"},{"location":"prd/gateway_sharding/#phase-2-migration","title":"Phase 2: Migration","text":"<ol> <li>Migrate existing services to wildcard listeners</li> <li>Update HTTPRoutes to point to org listener</li> <li>Remove old per-service listeners</li> </ol>"},{"location":"prd/gateway_sharding/#phase-3-cleanup","title":"Phase 3: Cleanup","text":"<ol> <li>Remove per-service listener code path</li> <li>Update documentation</li> <li>Deprecate old annotation behavior</li> </ol>"},{"location":"prd/gateway_sharding/#metrics-monitoring","title":"Metrics &amp; Monitoring","text":""},{"location":"prd/gateway_sharding/#key-metrics-to-track","title":"Key Metrics to Track","text":"<ul> <li>Listeners per Gateway</li> <li>Gateway memory usage</li> <li>Route update latency</li> <li>Certificate expiration by org</li> </ul>"},{"location":"prd/gateway_sharding/#alerts","title":"Alerts","text":"<ul> <li>Gateway listener count &gt; 80% limit</li> <li>Certificate renewal failures</li> <li>Gateway pod restarts</li> </ul>"},{"location":"prd/gateway_sharding/#timeline-estimate","title":"Timeline Estimate","text":"Phase Effort Duration Option 1 (Wildcard Listeners) Medium 2-3 weeks Option 4 Phase 2 (Dedicated Gateways) High 4-6 weeks Migration of existing services Medium 2-3 weeks"},{"location":"prd/gateway_sharding/#decision-required","title":"Decision Required","text":"<ul> <li> Approve Option 1 (Wildcard Listeners) for immediate scale improvement</li> <li> Approve Option 4 (Hybrid) for long-term architecture</li> <li> DNS-01 solver configuration (requires DNS provider API access)</li> <li> Organization subdomain structure (<code>{service}.{org}.{domain}</code> vs <code>{service}-{org}.{domain}</code>)</li> </ul>"},{"location":"prd/gateway_sharding/#references","title":"References","text":"<ul> <li>Envoy Gateway Scaling Guide</li> <li>Gateway API Multi-Gateway</li> <li>cert-manager DNS-01 Solvers</li> </ul>"},{"location":"prd/infrastructure-requirements/","title":"Kube-DC Infrastructure Requirements","text":"<p>This document outlines the resource requirements for deploying and operating a Kube-DC platform.</p>"},{"location":"prd/infrastructure-requirements/#architecture-overview","title":"Architecture Overview","text":""},{"location":"prd/infrastructure-requirements/#management-platform-provider-infrastructure","title":"Management Platform (Provider Infrastructure)","text":"<p>The Kube-DC management platform runs on 3 VMs that host: - Kubernetes control plane (RKE2/K3s) - All Kube-DC platform components (controllers, UI, monitoring) - Kamaji controller for managing tenant control planes - Tenant control plane pods (scaled on-demand)</p> <p>Key Principle: Tenant control planes run as pods on the management cluster and scale flexibly by adding more VMs to the management cluster as tenant count grows.</p>"},{"location":"prd/infrastructure-requirements/#tenant-infrastructure-customer-infrastructure","title":"Tenant Infrastructure (Customer Infrastructure)","text":"<ul> <li>Worker VMs: Run on customer's CloudSigma account</li> <li>Storage (Disks): Provisioned on customer's CloudSigma account via CSI driver</li> <li>Networking: Customer's CloudSigma network resources (IPs, VLANs)</li> </ul> <p>Key Principle: Customer workloads and data remain on customer infrastructure. Only the control plane is managed centrally.</p>"},{"location":"prd/infrastructure-requirements/#management-cluster-base-requirements","title":"Management Cluster Base Requirements","text":""},{"location":"prd/infrastructure-requirements/#production-setup-3-vm-architecture","title":"Production Setup: 3-VM Architecture","text":"VM Role Nb VMs CPU Cores CPU (GHz) RAM (GB) DISK (GB) Purpose Control Plane + Tenant CP Host 3 8 16-24 64 200+ K8s control plane, platform components, tenant control planes <p>Scaling Model: - Start with 3 VMs for HA and base capacity - Add VMs horizontally as tenant cluster count grows - Each additional VM can host ~10-20 tenant control planes - No distinction between \"master\" and \"worker\" - all nodes can host tenant control planes</p>"},{"location":"prd/infrastructure-requirements/#management-cluster-components-shared-infrastructure","title":"Management Cluster Components (Shared Infrastructure)","text":"<p>These components run once in the management cluster and serve all tenant clusters.</p>"},{"location":"prd/infrastructure-requirements/#core-platform-components","title":"Core Platform Components","text":"Component Nb Instances CPU (cores) CPU (MHz) RAM per Instance (GB) DISK per Instance (GB) Unmounted Drives (GB) Type Notes Kube-DC Manager 1 0.5 1000 0.5 - - Pod Core controller managing CRDs UI Frontend 1 0.2 400 0.5 - - Pod React application UI Backend 1 0.5 1000 1 - - Pod Node.js API server Keycloak 1 0.25 500 0.5 - - Pod Identity and access management Keycloak PostgreSQL 1 0.25 500 0.25 5 - Pod Keycloak database Kamaji Controller 1 0.5 1000 0.25 - - Pod Tenant control plane manager Kamaji etcd 3 0.5 1000 0.5 - 10 StatefulSet Shared etcd for all tenant control planes (default) Cert-Manager 1 0.2 400 0.25 - - Pod Certificate automation Envoy Gateway 2 0.5 1000 0.5 - - Deployment Ingress controller noVNC 1 0.1 200 0.25 - - Pod VM console access <p>Subtotal (Core Platform): ~5 CPU cores, ~5 GB RAM, ~15 GB storage</p>"},{"location":"prd/infrastructure-requirements/#monitoring-stack-shared","title":"Monitoring Stack (Shared)","text":"Component Nb Instances CPU (cores) CPU (MHz) RAM per Instance (GB) DISK per Instance (GB) Unmounted Drives (GB) Type Notes Prometheus 1 1 2000 2 - 20 StatefulSet Metrics storage and alerting Prometheus Operator 1 0.5 1000 0.25 - - Pod Prometheus lifecycle manager Alertmanager 1 0.5 1000 0.25 - - Pod Alert routing and notification Grafana 1 0.5 1000 0.5 - - Pod Visualization dashboards Loki Backend 1 0.5 1000 1 - - Pod Log aggregation backend Loki Read 1 0.5 1000 0.5 - - Pod Log query service Loki Write 1 0.5 1000 0.5 - - Pod Log ingestion service Loki Minio 1 0.5 1000 0.25 - 10 StatefulSet Object storage for logs (2 drives) Grafana Alloy 1+ 0.2 400 0.25 - - DaemonSet Metrics/logs collector (per node) Node Exporter 1+ 0.1 200 0.06 - - DaemonSet Node metrics (per node) Kube State Metrics 1 0.2 400 0.12 - - Pod Kubernetes metrics <p>Subtotal (Monitoring): ~5 CPU cores, ~6 GB RAM, ~30 GB storage</p>"},{"location":"prd/infrastructure-requirements/#networking-stack-shared","title":"Networking Stack (Shared)","text":"Component Nb Instances CPU (cores) CPU (MHz) RAM per Instance (GB) DISK per Instance (GB) Unmounted Drives (GB) Type Notes Kube-OVN Controller 1 1 2000 1 - - Pod OVN network controller Kube-OVN CNI 1+ 0.5 1000 0.5 - - DaemonSet CNI plugin (per node) OVN Central 3 0.5 1000 1 - - StatefulSet OVN database cluster Multus CNI 1+ 0.1 200 0.25 - - DaemonSet Multi-network support (per node) <p>Subtotal (Networking): ~4 CPU cores, ~5 GB RAM</p>"},{"location":"prd/infrastructure-requirements/#virtualization-stack-shared","title":"Virtualization Stack (Shared)","text":"Component Nb Instances CPU (cores) CPU (MHz) RAM per Instance (GB) DISK per Instance (GB) Unmounted Drives (GB) Type Notes KubeVirt Operator 1 0.5 1000 0.5 - - Pod VM lifecycle manager KubeVirt Handler 1+ 0.2 400 0.25 - - DaemonSet VM runtime (per node) CDI Operator 1 0.5 1000 0.5 - - Pod DataVolume manager CDI Controller 1 0.2 400 0.25 - - Pod Import/upload controller <p>Subtotal (Virtualization): ~2 CPU cores, ~2 GB RAM</p>"},{"location":"prd/infrastructure-requirements/#cluster-api-stack-shared","title":"Cluster API Stack (Shared)","text":"Component Nb Instances CPU (cores) CPU (MHz) RAM per Instance (GB) DISK per Instance (GB) Unmounted Drives (GB) Type Notes CAPI Controller 1 0.5 1000 0.5 - - Pod Cluster API core CAPI KubeVirt Provider 1 0.2 400 0.25 - - Pod KubeVirt infrastructure provider CAPI K3s Provider 1 0.2 400 0.25 - - Pod K3s bootstrap/control plane Sveltos 1 0.2 400 0.25 - - Pod Addon deployment controller Kyverno 3 0.2 400 0.25 - - Deployment Policy engine <p>Subtotal (Cluster API): ~2 CPU cores, ~2 GB RAM</p>"},{"location":"prd/infrastructure-requirements/#management-cluster-total-base-infrastructure","title":"Management Cluster Total (Base Infrastructure)","text":"Category CPU Cores RAM (GB) Storage (GB) Core Platform ~5 ~5 ~15 Monitoring ~5 ~6 ~30 Networking ~4 ~5 - Virtualization ~2 ~2 - Cluster API ~2 ~2 - TOTAL ~18 ~20 ~45 <p>Note: This excludes: - OS and system processes overhead (~2 CPU, ~4 GB RAM) - etcd for Kubernetes control plane (~1 CPU, ~2 GB RAM, ~20 GB storage) - RKE2/K3s components (~2 CPU, ~4 GB RAM)</p> <p>Recommended Management Cluster Minimum: 24 CPU cores, 32 GB RAM, 100 GB storage per node</p>"},{"location":"prd/infrastructure-requirements/#per-tenant-cluster-components-multiply-by-number-of-clusters","title":"Per-Tenant Cluster Components (Multiply by Number of Clusters)","text":"<p>These components are deployed for EACH tenant Kubernetes cluster created via KdcCluster.</p>"},{"location":"prd/infrastructure-requirements/#control-plane-kamaji-tenantcontrolplane","title":"Control Plane (Kamaji TenantControlPlane)","text":"Component Nb Instances CPU (cores) CPU (MHz) RAM per Instance (GB) DISK per Instance (GB) Unmounted Drives (GB) Type Notes kube-apiserver 2 0.5 1000 1 - - Pod Kubernetes API server (HA) kube-controller-manager 2 0.5 1000 0.5 - - Pod K8s controller manager kube-scheduler 2 0.2 400 0.25 - - Pod K8s scheduler <p>Subtotal per Cluster (Control Plane with shared etcd): ~2.4 CPU cores, ~3.5 GB RAM</p>"},{"location":"prd/infrastructure-requirements/#dedicated-etcd-optional-per-cluster","title":"Dedicated etcd (Optional, per Cluster)","text":"Component Nb Instances CPU (cores) CPU (MHz) RAM per Instance (GB) DISK per Instance (GB) Unmounted Drives (GB) Type Notes etcd 3 0.5 1000 0.5 - 10 StatefulSet Dedicated etcd cluster (if not using shared) <p>Subtotal (Dedicated etcd): ~1.5 CPU cores, ~1.5 GB RAM, ~30 GB storage</p>"},{"location":"prd/infrastructure-requirements/#worker-nodes-configurable-per-cluster","title":"Worker Nodes (Configurable per Cluster)","text":"<p>Worker nodes are provisioned as VMs via Cluster API. Resources depend on tenant requirements.</p>"},{"location":"prd/infrastructure-requirements/#example-worker-configurations","title":"Example Worker Configurations","text":"<p>Minimal Worker: - CPU: 1 core (2000 MHz) - RAM: 1 GB - Disk: 20 GB</p> <p>Standard Worker: - CPU: 2 cores (4000 MHz) - RAM: 4 GB - Disk: 40 GB</p> <p>High-Memory Worker: - CPU: 4 cores (8000 MHz) - RAM: 16 GB - Disk: 80 GB</p>"},{"location":"prd/infrastructure-requirements/#cloudsigma-specific-components-per-cluster-using-cloudsigma","title":"CloudSigma-Specific Components (Per Cluster using CloudSigma)","text":"Component Nb Instances CPU (cores) CPU (MHz) RAM per Instance (GB) DISK per Instance (GB) Unmounted Drives (GB) Type Notes CloudSigma CCM 1 0.2 400 0.1 - - DaemonSet Cloud controller manager (on control plane) CloudSigma CSI Controller 1 0.5 1000 0.25 - - Deployment Storage provisioner controller CloudSigma CSI Node 1+ 0.5 1000 0.25 - - DaemonSet CSI node plugin (per worker) <p>Subtotal (CloudSigma integration per cluster): ~1.2 CPU cores, ~0.6 GB RAM</p>"},{"location":"prd/infrastructure-requirements/#cninetworking-per-cluster-if-using-cilium","title":"CNI/Networking (Per Cluster - if using Cilium)","text":"Component Nb Instances CPU (cores) CPU (MHz) RAM per Instance (GB) DISK per Instance (GB) Unmounted Drives (GB) Type Notes Cilium Agent 1+ 0.1 200 0.5 - - DaemonSet CNI agent (per node) Cilium Operator 1 0.1 200 0.12 - - Deployment Cilium operator <p>Subtotal (Cilium per cluster): ~0.2 CPU cores (+ per node), ~0.62 GB RAM</p>"},{"location":"prd/infrastructure-requirements/#per-tenant-cluster-total","title":"Per-Tenant Cluster Total","text":""},{"location":"prd/infrastructure-requirements/#configuration-1-minimal-shared-etcd-2-minimal-workers","title":"Configuration 1: Minimal (Shared etcd, 2 minimal workers)","text":"Component CPU Cores RAM (GB) Storage (GB) Control Plane (2 replicas) 2.4 3.5 - Workers (2x minimal) 2 2 40 CloudSigma Integration 1.2 0.6 - Cilium CNI 0.4 1.1 - TOTAL 6 7.2 40"},{"location":"prd/infrastructure-requirements/#configuration-2-standard-shared-etcd-3-standard-workers","title":"Configuration 2: Standard (Shared etcd, 3 standard workers)","text":"Component CPU Cores RAM (GB) Storage (GB) Control Plane (2 replicas) 2.4 3.5 - Workers (3x standard) 6 12 120 CloudSigma Integration 1.7 1.35 - Cilium CNI 0.5 1.62 - TOTAL 10.6 18.47 120"},{"location":"prd/infrastructure-requirements/#configuration-3-production-dedicated-etcd-3-standard-workers","title":"Configuration 3: Production (Dedicated etcd, 3 standard workers)","text":"Component CPU Cores RAM (GB) Storage (GB) Control Plane (2 replicas) 2.4 3.5 - Dedicated etcd (3 replicas) 1.5 1.5 30 Workers (3x standard) 6 12 120 CloudSigma Integration 1.7 1.35 - Cilium CNI 0.5 1.62 - TOTAL 12.1 19.97 150"},{"location":"prd/infrastructure-requirements/#example-deployment-scenarios","title":"Example Deployment Scenarios","text":""},{"location":"prd/infrastructure-requirements/#scenario-1-small-platform-5-tenant-clusters","title":"Scenario 1: Small Platform (5 Tenant Clusters)","text":"Infrastructure CPU Cores RAM (GB) Storage (GB) Management Cluster Base 18 20 45 5x Tenant Clusters (Standard) 53 92.35 600 OS/System Overhead (3 nodes) 6 12 60 TOTAL 77 124.35 705 <p>Recommended Infrastructure: - 3x Master/Worker nodes: 32 cores, 48 GB RAM, 300 GB SSD each</p>"},{"location":"prd/infrastructure-requirements/#scenario-2-medium-platform-20-tenant-clusters","title":"Scenario 2: Medium Platform (20 Tenant Clusters)","text":"Infrastructure CPU Cores RAM (GB) Storage (GB) Management Cluster Base 18 20 45 20x Tenant Clusters (Standard) 212 369.4 2400 OS/System Overhead (6 nodes) 12 24 120 TOTAL 242 413.4 2565 <p>Recommended Infrastructure: - 3x Master nodes: 32 cores, 64 GB RAM, 500 GB SSD each - 6x Worker nodes: 48 cores, 96 GB RAM, 1 TB SSD each</p>"},{"location":"prd/infrastructure-requirements/#scenario-3-large-platform-50-tenant-clusters","title":"Scenario 3: Large Platform (50 Tenant Clusters)","text":"Infrastructure CPU Cores RAM (GB) Storage (GB) Management Cluster Base 18 20 45 50x Tenant Clusters (Standard) 530 923.5 6000 OS/System Overhead (12 nodes) 24 48 240 TOTAL 572 991.5 6285 <p>Recommended Infrastructure: - 3x Master nodes: 64 cores, 128 GB RAM, 1 TB SSD each - 12x Worker nodes: 64 cores, 128 GB RAM, 2 TB SSD each</p>"},{"location":"prd/infrastructure-requirements/#storage-requirements-breakdown","title":"Storage Requirements Breakdown","text":""},{"location":"prd/infrastructure-requirements/#management-cluster-persistent-storage","title":"Management Cluster Persistent Storage","text":"Volume Type Size per Instance Instances Total Purpose Kamaji etcd 10 GB 3 30 GB Shared etcd datastore Prometheus 20 GB 1 20 GB Metrics storage (configurable: 365d retention) Loki Minio 10 GB 1 10 GB Log storage (7d retention) Keycloak PostgreSQL 5 GB 1 5 GB User database TOTAL - - 65 GB -"},{"location":"prd/infrastructure-requirements/#per-tenant-cluster-storage","title":"Per-Tenant Cluster Storage","text":"Volume Type Size per Instance Instances Total Purpose Dedicated etcd (optional) 10 GB 3 30 GB Per-cluster etcd Worker OS Disk 20-80 GB N Variable OS and container images Tenant PVCs Variable Variable Variable Application storage via CSI"},{"location":"prd/infrastructure-requirements/#network-requirements","title":"Network Requirements","text":""},{"location":"prd/infrastructure-requirements/#bandwidth","title":"Bandwidth","text":"<ul> <li>Management Cluster Internal: 10 Gbps recommended (node-to-node)</li> <li>External Access: 1 Gbps minimum for API/UI</li> <li>Storage Network (if separate): 10 Gbps recommended</li> </ul>"},{"location":"prd/infrastructure-requirements/#ip-address-requirements","title":"IP Address Requirements","text":""},{"location":"prd/infrastructure-requirements/#management-cluster-kube-ovn","title":"Management Cluster (Kube-OVN)","text":"<ul> <li>Pod CIDR: /16 recommended (65,536 IPs)</li> <li>Service CIDR: /16 recommended (65,536 IPs)</li> <li>Per Project VPC: /16 (configurable)</li> </ul>"},{"location":"prd/infrastructure-requirements/#per-tenant-cluster","title":"Per-Tenant Cluster","text":"<ul> <li>Pod CIDR: /16 (65,536 IPs per cluster)</li> <li>Service CIDR: /16 (65,536 IPs per cluster)</li> </ul>"},{"location":"prd/infrastructure-requirements/#external-ips","title":"External IPs","text":"<ul> <li>Management cluster: 1-5 public IPs (UI, API, monitoring)</li> <li>Per tenant cluster: Variable (depends on LoadBalancer services)</li> </ul>"},{"location":"prd/infrastructure-requirements/#notes-and-recommendations","title":"Notes and Recommendations","text":""},{"location":"prd/infrastructure-requirements/#scaling-considerations","title":"Scaling Considerations","text":"<ol> <li>Horizontal Scaling:</li> <li>Add worker nodes to management cluster as tenant cluster count grows</li> <li>Management cluster workers can be scaled independently</li> <li> <p>Each worker node can host ~10-20 tenant control plane pods</p> </li> <li> <p>Vertical Scaling:</p> </li> <li>Increase worker node resources for larger tenant worker VMs</li> <li> <p>Monitoring stack may need scaling with high pod/metric count</p> </li> <li> <p>Storage Scaling:</p> </li> <li>Prometheus retention and storage grow with cluster count</li> <li>Consider external object storage for Loki at scale</li> <li>Plan for ~50 GB additional storage per 10 tenant clusters</li> </ol>"},{"location":"prd/infrastructure-requirements/#resource-overhead","title":"Resource Overhead","text":"<ul> <li>Kubernetes System: ~10-15% CPU/RAM overhead</li> <li>VM Runtime (KubeVirt): ~10-20% overhead per VM</li> <li>Network Overhead: ~5-10% CPU for OVN/CNI</li> </ul>"},{"location":"prd/infrastructure-requirements/#high-availability","title":"High Availability","text":"<ul> <li>Management Cluster: 3+ master nodes, 3+ worker nodes</li> <li>etcd: Always use 3 or 5 replicas (odd number)</li> <li>Control Planes: 2+ replicas per tenant cluster</li> <li>Monitoring: Consider external storage for production</li> </ul>"},{"location":"prd/infrastructure-requirements/#cost-optimization","title":"Cost Optimization","text":"<ol> <li>Use shared etcd for non-critical tenant clusters</li> <li>Right-size worker VMs based on actual workload</li> <li>Enable cluster autoscaling for variable workloads</li> <li>Use lower retention for Prometheus/Loki in dev environments</li> </ol>"},{"location":"prd/infrastructure-requirements/#actual-production-cluster-analysis","title":"Actual Production Cluster Analysis","text":""},{"location":"prd/infrastructure-requirements/#current-deployment-stagekube-dccom","title":"Current Deployment (stage.kube-dc.com)","text":"<p>Management Cluster Hardware: - Node Count: 2 nodes (kube-dc-master-1, kube-dc-worker-1) - Per Node: 8 CPU cores, 64 GB RAM, Debian 12 - Total Capacity: 16 cores, 128 GB RAM</p> <p>Resource Utilization (Live): - kube-dc-master-1: 40% CPU (3.2 cores), 49% RAM (31 GB) - kube-dc-worker-1: 33% CPU (2.7 cores), 64% RAM (41 GB) - Total Used: ~6 cores (37%), ~72 GB RAM (56%)</p> <p>Tenant Clusters Hosted: 7 active KdcClusters</p> Namespace Cluster Name Control Plane Replicas Worker Replicas Datastore Type cloudsigma-example-3415fbd3 banja 1 2 banja-etcd (dedicated) cloudsigma-example-3415fbd3 xxx 1 1 banja-etcd (shared) cloudsigma-tan-dovan-90e02d2d c1 1 3 c1-etcd (dedicated) shalb-demo demo-cluster 1 1 demo-cluster-etcd (dedicated) shalb-demo k3s-cluster 2 1 k3s-cluster-etcd (dedicated) shalb-demo my-cluster 2 2 my-cluster-etcd (dedicated) shalb-envoy three-cluster 2 1 three-cluster-etcd (dedicated)"},{"location":"prd/infrastructure-requirements/#tenant-cluster-resource-consumption-analysis","title":"Tenant Cluster Resource Consumption Analysis","text":""},{"location":"prd/infrastructure-requirements/#example-banja-and-xxx-clusters-cloudsigma-example-3415fbd3","title":"Example: \"banja\" and \"xxx\" Clusters (cloudsigma-example-3415fbd3)","text":"<p>Control Plane Pods (Management Cluster):</p> Component Pod Count CPU Request Memory Request Actual Location banja-cp 1 None None kube-dc-worker-1 banja-etcd 1 None None kube-dc-worker-1 xxx-cp 1 None None kube-dc-worker-1 csccm-banja (CCM) 1 10m 64Mi kube-dc-worker-1 csccm-xxx (CCM) 1 10m 64Mi kube-dc-worker-1 <p>Worker VMs (Customer CloudSigma Account): - Banja: 2 workers (2 cores, 4GB each) = 4 cores, 8GB total - xxx: 1 worker (2 cores, 4GB) = 2 cores, 4GB total</p> <p>Key Observations:</p> <ol> <li>No Resource Limits: Most tenant control plane pods have no CPU/memory requests, relying on cluster overcommit</li> <li>Shared etcd: xxx cluster uses banja's etcd datastore (cost optimization)</li> <li>Lightweight Control Planes: Each tenant CP consumes ~0.5-1 GB RAM in practice</li> <li>Management Overhead: CloudSigma CCM pods: 10m CPU, 64Mi RAM per cluster</li> <li>Worker VMs on Customer Infrastructure: Worker nodes NOT visible in management cluster metrics</li> </ol>"},{"location":"prd/infrastructure-requirements/#platform-components-resource-usage","title":"Platform Components Resource Usage","text":"<p>Core Platform (kube-dc namespace):</p> Component CPU Request Memory Request Notes kube-dc-manager None None Core controller kube-dc-backend None None API server kube-dc-frontend None None React UI kube-dc-k8-manager 10m 64Mi Tenant cluster controller <p>Monitoring Stack (monitoring namespace):</p> Component CPU Request Memory Request Storage Prometheus None 1Gi 20Gi Grafana None None - Alertmanager None 128Mi - Loki Backend None None - Loki Write None 256Mi - Loki Read None 256Mi - Loki Minio 100m 128Mi 10Gi Node Exporter (per node) None 32Mi - <p>Shared Infrastructure (kamaji-system namespace):</p> Component CPU Request Memory Request Storage Kamaji Controller 100m 20Mi - Kamaji etcd (3 replicas) None None 30Gi (3x10Gi) CAPI Kamaji Controller 10m 64Mi -"},{"location":"prd/infrastructure-requirements/#actual-vs-theoretical-requirements","title":"Actual vs Theoretical Requirements","text":"<p>Current Cluster Efficiency: - 7 tenant clusters running on 16 cores, 128 GB RAM - Average per cluster: ~0.9 cores, ~10 GB RAM (management overhead only) - Platform base: ~4 cores, ~20 GB RAM - Remaining capacity: ~6 cores, ~36 GB RAM for additional tenants</p> <p>Scaling Projection: - Current 2-node cluster can support ~10-15 tenant clusters before CPU/RAM constraints - With 3-node architecture (24 cores, 192 GB): ~20-30 tenant clusters - Adding 1 node per 10 tenant clusters is recommended for stability</p> <p>Resource Optimization Observed: - Resource requests not set on most components \u2192 cluster overcommit strategy - Shared etcd reduces storage requirements (xxx uses banja's etcd) - Control plane memory footprint lower than theoretical (0.5-1GB vs 1-2GB estimated)</p>"},{"location":"prd/infrastructure-requirements/#storage-usage-persistent-volumes","title":"Storage Usage (Persistent Volumes)","text":"<p>Management Cluster Storage: - Kamaji shared etcd: 30 GB (3x 10GB PVCs) - Prometheus: 20 GB - Loki/Minio: 10 GB - Keycloak PostgreSQL: ~5 GB - Per tenant etcd (dedicated): 10-30 GB (1-3 replicas)</p> <p>Total Storage in Use: ~500-600 GB across all tenant etcd instances + monitoring</p>"},{"location":"prd/infrastructure-requirements/#cloudsigma-platform-capacity-planning","title":"CloudSigma Platform Capacity Planning","text":""},{"location":"prd/infrastructure-requirements/#proposed-hardware-configuration","title":"Proposed Hardware Configuration","text":"<p>Management Cluster Infrastructure:</p> VM Role Nb VMs CPU Cores CPU (GHz) RAM (GB) Disk (GB) Backup (GB) Purpose Master-1 1 8 16 32 200 300 K8s control plane + tenant CPs Master-2 1 8 16 32 200 300 K8s control plane + tenant CPs Master-3 1 8 16 32 200 300 K8s control plane + tenant CPs Worker-1 1 16 32 64 250 300 Tenant CPs + monitoring Worker-2 1 16 32 64 250 300 Tenant CPs + monitoring Management VM 1 4 16 32 200 300 Optional dedicated management TOTAL 6 60 128 256 1300 1800 - <p>Configuration Notes: - All 5 nodes (3 masters + 2 workers) can host tenant control planes - Management VM can be used for backups, monitoring, or additional capacity - Total usable for tenant CPs: 52 cores, 224 GB RAM (after K8s overhead)</p>"},{"location":"prd/infrastructure-requirements/#per-tenant-cluster-resource-consumption-cloudsigma","title":"Per-Tenant Cluster Resource Consumption (CloudSigma)","text":""},{"location":"prd/infrastructure-requirements/#components-per-tenant-cluster","title":"Components per Tenant Cluster:","text":"<p>1. Tenant Control Plane Pod (on Management Cluster) - kube-apiserver: ~200-300Mi RAM, 50-100m CPU - kube-controller-manager: ~150-200Mi RAM, 25-50m CPU - kube-scheduler: ~50-100Mi RAM, 10-25m CPU - Total per TCP: ~500Mi RAM, ~100m CPU</p> <p>2. CloudSigma Cloud Controller Manager (per cluster) - csccm pod: 64Mi RAM, 10m CPU (observed) - Total: 64Mi RAM, 10m CPU</p> <p>3. etcd Datastore (50% 1-node / 50% 3-node)</p> <p>1-node etcd (50% of clusters): - etcd pod: 512Mi RAM, 100m CPU, 10Gi storage - Total: 512Mi RAM, 100m CPU, 10Gi</p> <p>3-node etcd (50% of clusters): - etcd pods (3x): 1536Mi RAM (512Mi\u00d73), 300m CPU (100m\u00d73), 30Gi storage (10Gi\u00d73) - Total: 1536Mi RAM, 300m CPU, 30Gi</p>"},{"location":"prd/infrastructure-requirements/#average-per-cluster-mixed-etcd-topology","title":"Average per Cluster (Mixed etcd Topology)","text":"Component CPU (cores) RAM (GB) Storage (GB) Notes Control Plane Pod 0.1 0.5 - 3-in-1 pod CloudSigma CCM 0.01 0.06 - Per cluster etcd (1-node) 0.1 0.5 10 50% of clusters etcd (3-node) 0.3 1.5 30 50% of clusters Average 0.21 1.06 20 Weighted avg Conservative 0.3 1.5 20 With overhead"},{"location":"prd/infrastructure-requirements/#capacity-calculation","title":"Capacity Calculation","text":""},{"location":"prd/infrastructure-requirements/#total-available-resources-after-k8s-overhead-15","title":"Total Available Resources (after K8s overhead ~15%)","text":"Resource Total K8s Overhead (15%) Available Reserved for Platform (20%) Usable for Tenants CPU Cores 60 9 51 10 41 cores RAM (GB) 256 38 218 44 174 GB Storage (GB) 1300 - 1300 100 1200 GB"},{"location":"prd/infrastructure-requirements/#capacity-by-constraint","title":"Capacity by Constraint","text":"<p>CPU Constraint: - Usable CPU: 41 cores - Per cluster: 0.3 cores - Capacity: ~136 clusters</p> <p>Memory Constraint: - Usable RAM: 174 GB - Per cluster: 1.5 GB - Capacity: ~116 clusters</p> <p>Storage Constraint: - Usable Storage: 1200 GB - Per cluster: 20 GB (average) - Capacity: ~60 clusters</p> <p>Bottleneck: Storage (most restrictive)</p>"},{"location":"prd/infrastructure-requirements/#recommended-capacity-50-60-tenant-clusters","title":"Recommended Capacity: 50-60 Tenant Clusters","text":""},{"location":"prd/infrastructure-requirements/#breakdown-by-etcd-topology-5050-split","title":"Breakdown by etcd Topology (50/50 split)","text":"Cluster Type Count etcd Nodes etcd Storage TCP + CCM Resources 1-node etcd 25-30 25-30 250-300 GB 25-30 \u00d7 (0.11 cores, 0.56 GB) 3-node etcd 25-30 75-90 750-900 GB 25-30 \u00d7 (0.11 cores, 0.56 GB) TOTAL 50-60 100-120 1000-1200 GB 5.5-6.6 cores, 28-34 GB"},{"location":"prd/infrastructure-requirements/#resource-distribution-across-nodes","title":"Resource Distribution Across Nodes","text":"<p>Assuming 60 tenant clusters evenly distributed:</p> Node Role TCP Pods etcd Pods CPU Used RAM Used Storage Used Master-1 K8s CP + TCP host 12 20 ~6 cores ~20 GB ~200 GB Master-2 K8s CP + TCP host 12 20 ~6 cores ~20 GB ~200 GB Master-3 K8s CP + TCP host 12 20 ~6 cores ~20 GB ~200 GB Worker-1 TCP + Monitoring 12 20 ~7 cores ~25 GB ~250 GB Worker-2 TCP + Monitoring 12 20 ~7 cores ~25 GB ~250 GB TOTAL - 60 100 32 cores 110 GB 1100 GB"},{"location":"prd/infrastructure-requirements/#scaling-strategies","title":"Scaling Strategies","text":""},{"location":"prd/infrastructure-requirements/#to-increase-capacity-beyond-60-clusters","title":"To Increase Capacity Beyond 60 Clusters:","text":"<p>Option 1: Add Storage - Expand disk on Worker-1 and Worker-2 to 500 GB each - New Capacity: ~100 clusters (limited by CPU/RAM)</p> <p>Option 2: Add Worker Nodes - Add 2 more workers: 32 cores, 128 GB RAM, 500 GB disk each - New Capacity: ~150 clusters</p> <p>Option 3: Use Shared etcd (Kamaji default) - 3-node shared etcd for all clusters instead of dedicated - Saves: ~950 GB storage, ~20 cores, ~80 GB RAM - New Capacity: 200+ clusters (limited by control plane density)</p> <p>Option 4: External etcd Storage - Move etcd storage to separate storage cluster or cloud object storage - Management cluster only hosts control plane pods - New Capacity: 300+ clusters (Kamaji scaling limit per management cluster)</p>"},{"location":"prd/infrastructure-requirements/#kamaji-scaling-best-practices","title":"Kamaji Scaling Best Practices","text":"<p>From Kamaji Official Documentation:</p> <ol> <li>Control Plane Density: 50-100 tenant control planes per management node recommended</li> <li>etcd Sizing: </li> <li>Shared etcd: 3-node cluster can handle 100+ tenant clusters</li> <li>Dedicated etcd: 1 or 3 nodes per cluster based on SLA requirements</li> <li>Resource Overcommit: Kamaji leverages Kubernetes QoS, safe to run without strict resource limits</li> <li>High Availability: Distribute TCP pods across nodes using pod anti-affinity</li> </ol>"},{"location":"prd/infrastructure-requirements/#production-recommendations","title":"Production Recommendations","text":"<p>Conservative (50 clusters): - Current hardware configuration as-is - 25 clusters with 1-node etcd (dev/test) - 25 clusters with 3-node etcd (production) - Leaves 20% headroom for growth</p> <p>Standard (60 clusters): - Current hardware configuration - 30 clusters with 1-node etcd - 30 clusters with 3-node etcd - Uses ~85% of available storage</p> <p>Aggressive (100+ clusters): - Add storage expansion or additional worker nodes - Use shared etcd for majority of clusters - Reserve dedicated etcd for critical production clusters only</p>"},{"location":"prd/infrastructure-requirements/#customer-infrastructure-not-counted-in-management-cluster","title":"Customer Infrastructure (Not Counted in Management Cluster)","text":"<p>Per Tenant Cluster Workers (CloudSigma): - Worker VMs: Run on customer's CloudSigma account - CSI Driver storage: Customer's CloudSigma disks - Networking: Customer's CloudSigma IPs/VLANs</p> <p>Example Customer Workload: - 3 workers \u00d7 (4 cores, 8 GB) = 12 cores, 24 GB on customer side - 100 GB storage per worker via CSI = 300 GB on customer CloudSigma</p> <p>Management cluster only hosts control plane - customer workloads NOT included in above calculations.</p> <p>Last Updated: January 2025 Document Version: 2.1 - Added CloudSigma capacity planning with Kamaji scaling guidelines</p>"},{"location":"prd/organization_standard_groups/","title":"PRD: Organization Standard Groups and Role Distribution","text":""},{"location":"prd/organization_standard_groups/#problem-statement","title":"Problem Statement","text":"<p>When approving join requests, the UI offers group options (<code>developer</code>, <code>project-manager</code>, <code>user</code>) that don't exist in the organization's Keycloak realm. Currently, only <code>org-admin</code> group is created during organization setup.</p> <p>Current State: - Organization controller creates only <code>org-admin</code> group in Keycloak realm - RoleBinding maps <code>&lt;org&gt;:org-admin</code> to Kubernetes RBAC in org namespace - No standard user-level groups exist for assigning regular users - Join request approval fails silently when trying to add users to non-existent groups</p>"},{"location":"prd/organization_standard_groups/#design-approach-hybrid-model","title":"Design Approach: Hybrid Model","text":"<p>This PRD implements a hybrid approach combining automatic standard groups with fine-grained OrganizationGroup CRD control:</p> <ol> <li>Standard Groups (<code>org-admin</code>, <code>user</code>) - Created automatically during organization setup, provide org-wide basic access</li> <li>Elevated Access (<code>developer</code>, <code>project-manager</code>) - Granted via OrganizationGroup CRD for per-project granular control</li> </ol>"},{"location":"prd/organization_standard_groups/#requirements","title":"Requirements","text":""},{"location":"prd/organization_standard_groups/#1-standard-keycloak-groups-organization-realm","title":"1. Standard Keycloak Groups (Organization Realm)","text":"<p>Create during organization creation:</p> Group Name Purpose Created By <code>org-admin</code> Full organization management Organization controller (exists) <code>user</code> Read-only access to all projects Organization controller (new) <p>Note: <code>developer</code> and <code>project-manager</code> groups are created on-demand via OrganizationGroup CRD for per-project access control.</p>"},{"location":"prd/organization_standard_groups/#2-kubernetes-roles","title":"2. Kubernetes Roles","text":""},{"location":"prd/organization_standard_groups/#organization-namespace-roles","title":"Organization Namespace Roles","text":"Role Name Permissions Created By <code>{org}-admin</code> Full access to org resources Organization controller (exists) <code>{org}-user</code> Read-only org access Organization controller (new)"},{"location":"prd/organization_standard_groups/#project-namespace-roles-templates","title":"Project Namespace Roles (Templates)","text":"<p>Role templates stored in <code>kube-dc</code> namespace, copied to each project namespace:</p> Role Name Permissions Created By <code>admin</code> Full project access Project controller (exists) <code>developer</code> VMs, containers, pods, services: full CRUD Project controller (new) <code>project-manager</code> VMs, containers, pods, services: get, list, watch Project controller (new) <code>user</code> VMs, containers, pods, services: get, list Project controller (new)"},{"location":"prd/organization_standard_groups/#3-rolebindings","title":"3. RoleBindings","text":""},{"location":"prd/organization_standard_groups/#organization-namespace","title":"Organization Namespace","text":"RoleBinding Subject Role <code>org-admin</code> <code>{org}:org-admin</code> <code>{org}-admin</code> (exists) <code>user</code> <code>{org}:user</code> <code>{org}-user</code> (new)"},{"location":"prd/organization_standard_groups/#project-namespace","title":"Project Namespace","text":"RoleBinding Subject Role Created By <code>org-admin</code> <code>{org}:org-admin</code> <code>admin</code> Project controller (exists) <code>user</code> <code>{org}:user</code> <code>user</code> Project controller (new) <p>Note: <code>developer</code> and <code>project-manager</code> RoleBindings are created by OrganizationGroup controller when admin assigns users to specific projects.</p>"},{"location":"prd/organization_standard_groups/#implementation-details","title":"Implementation Details","text":""},{"location":"prd/organization_standard_groups/#files-modified","title":"Files Modified","text":"<ol> <li><code>internal/organization/helpers.go</code> \u2705 DONE</li> <li>Added <code>DefaultKeycloakUserGroup</code> and <code>DefaultKeycloakUserRole</code> constants</li> <li> <p>Added <code>generateUserRoleName()</code> helper function</p> </li> <li> <p><code>internal/organization/client_keycloak.go</code> \u2705 DONE</p> </li> <li> <p>Added <code>user</code> group creation in <code>Create()</code> method</p> </li> <li> <p><code>internal/organization/res_kube_role.go</code> \u2705 DONE</p> </li> <li> <p>Added <code>NewRealmUserRole()</code> function for <code>{org}-user</code> role</p> </li> <li> <p><code>internal/organization/res_kube_role_binding.go</code> \u2705 DONE</p> </li> <li> <p>Added <code>NewRealmUserRoleBinding()</code> function</p> </li> <li> <p><code>internal/organization/organization.go</code> \u2705 DONE</p> </li> <li> <p>Added calls to sync user role and rolebinding in <code>Sync()</code></p> </li> <li> <p><code>internal/project/helpers.go</code> \u2705 DONE</p> </li> <li> <p>Added role template constants and loader functions</p> </li> <li> <p><code>internal/project/res_role.go</code> \u2705 DONE</p> </li> <li> <p>Added <code>NewProjectDeveloperRole()</code>, <code>NewProjectManagerRole()</code>, <code>NewProjectUserRole()</code></p> </li> <li> <p><code>internal/project/res_role_binding.go</code> \u2705 DONE</p> </li> <li> <p>Added <code>NewProjectUserRoleBinding()</code> for automatic <code>user</code> group binding</p> </li> <li> <p><code>internal/project/project.go</code> \u2705 DONE</p> </li> <li> <p>Added Sync and Delete calls for new roles and role bindings</p> </li> <li> <p><code>api/kube-dc.com/v1/types.go</code> \u2705 DONE</p> <ul> <li>Added role template name constants</li> </ul> </li> <li> <p><code>charts/kube-dc/templates/default-project-admin-role.yaml</code> \u2705 DONE</p> <ul> <li>Contains all 4 role templates: <code>admin</code>, <code>developer</code>, <code>project-manager</code>, <code>user</code></li> </ul> </li> </ol>"},{"location":"prd/organization_standard_groups/#controller-flow","title":"Controller Flow","text":"<pre><code>Organization Created\n    \u251c\u2500\u2500 Create Keycloak Realm\n    \u2502   \u2514\u2500\u2500 Create Groups: org-admin, user\n    \u251c\u2500\u2500 Create Org Namespace\n    \u2502   \u251c\u2500\u2500 Create Roles: {org}-admin, {org}-user\n    \u2502   \u2514\u2500\u2500 Create RoleBindings: org-admin \u2192 {org}-admin, user \u2192 {org}-user\n    \u2514\u2500\u2500 Done\n\nProject Created\n    \u251c\u2500\u2500 Create Project Namespace\n    \u2502   \u251c\u2500\u2500 Create Roles from templates: admin, developer, project-manager, user\n    \u2502   \u2514\u2500\u2500 Create RoleBindings: \n    \u2502       \u251c\u2500\u2500 {org}:org-admin \u2192 admin (exists)\n    \u2502       \u2514\u2500\u2500 {org}:user \u2192 user (new)\n    \u2514\u2500\u2500 Done\n\nOrganizationGroup Created (for elevated access)\n    \u251c\u2500\u2500 Create Keycloak Group (e.g., \"my-developers\")\n    \u251c\u2500\u2500 For each project in spec.permissions:\n    \u2502   \u2514\u2500\u2500 Create RoleBinding: {org}:my-developers \u2192 developer\n    \u2514\u2500\u2500 Done\n</code></pre>"},{"location":"prd/organization_standard_groups/#role-permissions-matrix","title":"Role Permissions Matrix","text":""},{"location":"prd/organization_standard_groups/#organization-namespace_1","title":"Organization Namespace","text":"Resource org-admin user organizations get, list, patch, update, watch get projects full CRUD get, list organizationgroups full CRUD -"},{"location":"prd/organization_standard_groups/#project-namespace_1","title":"Project Namespace","text":"Resource admin developer project-manager user virtualmachines full CRUD full CRUD get, list, watch get, list virtualmachineinstances full CRUD full CRUD get, list, watch get, list pods full CRUD full CRUD get, list, watch get, list pods/log get get get get services full CRUD full CRUD get, list, watch get, list deployments full CRUD full CRUD get, list, watch get, list secrets full CRUD full CRUD get, list - configmaps full CRUD full CRUD get, list get, list"},{"location":"prd/organization_standard_groups/#user-approval-flow","title":"User Approval Flow","text":"<pre><code>User requests to join organization\n    \u2193\nOrg admin sees join request in UI\n    \u2193\nAdmin selects group: \"user\" (default) or \"org-admin\"\n    \u2193\nBackend adds user to Keycloak group\n    \u2193\nUser gets automatic read-only access to all projects\n    \u2193\n(Optional) Admin creates OrganizationGroup for elevated per-project access\n</code></pre>"},{"location":"prd/organization_standard_groups/#success-criteria","title":"Success Criteria","text":"<ol> <li>New organizations have <code>org-admin</code> and <code>user</code> groups in Keycloak</li> <li>Join request approval adds users to <code>user</code> group by default</li> <li>Users in <code>user</code> group have read-only access to all projects</li> <li>Project creation includes <code>developer</code>, <code>project-manager</code>, <code>user</code> role templates</li> <li>OrganizationGroup CRD can grant elevated access per-project</li> </ol>"},{"location":"prd/organization_standard_groups/#out-of-scope","title":"Out of Scope","text":"<ul> <li>Migration of existing organizations (recreate after approval)</li> <li>Custom group creation via UI (future feature)</li> <li>Per-project group overrides outside OrganizationGroup CRD</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/","title":"PRD: OVN Database Connection Stability Improvements","text":""},{"location":"prd/ovn_database_stability_improvements/#status","title":"Status","text":"<ul> <li>Status: Proposed</li> <li>Created: 2026-01-12</li> <li>Priority: High</li> <li>Impact: Platform Stability, Service Availability</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#executive-summary","title":"Executive Summary","text":"<p>The kube-dc-manager controller experiences severe OVN database connection instability, resulting in 2.6+ million disconnections over 158 days of uptime. This causes: - 20+ minute service reconciliation deadlocks - LoadBalancer services stuck in <code>&lt;pending&gt;</code> state - Mass reconnection storms during network hiccups - Unpredictable service external IP assignment delays</p> <p>This PRD outlines comprehensive improvements to OVN database client connectivity, probe intervals, and reconnection strategies to achieve production-grade stability.</p>"},{"location":"prd/ovn_database_stability_improvements/#problem-statement","title":"Problem Statement","text":""},{"location":"prd/ovn_database_stability_improvements/#current-issues","title":"Current Issues","text":"<p>1. Extreme Connection Churn <pre><code>OVN Database Metrics (158 days uptime):\n- Disconnections: 2,682,477 (avg 16,964/day)\n- Active Connections: 13 established, 12 TIME_WAIT\n- Pattern: Constant disconnect/reconnect cycle\n</code></pre></p> <p>2. Service Reconciliation Deadlocks - Services remain <code>&lt;pending&gt;</code> for 20+ minutes during connection issues - Example: <code>jump-cp</code> and <code>jump-etcd-etcd-lb</code> stuck from 14:35 to 14:56 (21 minutes) - 32 services complete simultaneously when connection recovers (queued backlog)</p> <p>3. Controller Behavior - Before fix: Parallel deadlock (5 concurrent reconciliations block on libovsdb internal mutexes) - After SafeOvnClient fix: Serial bottleneck (one stuck operation blocks all others via operation mutex) - After timeout fix: Operations timeout after 30s, but still experience delays during reconnection</p>"},{"location":"prd/ovn_database_stability_improvements/#impact-on-production","title":"Impact on Production","text":"<ul> <li>Service Availability: LoadBalancer services cannot get external IPs during connection issues</li> <li>Unpredictability: No SLA for service provisioning time (0-30+ minutes)</li> <li>Cascading Failures: Connection loss triggers mass reconnection storm</li> <li>Resource Waste: Controller CPU spikes during reconnection attempts</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#root-cause-analysis","title":"Root Cause Analysis","text":""},{"location":"prd/ovn_database_stability_improvements/#1-aggressive-server-side-probe-intervals-critical","title":"1. Aggressive Server-Side Probe Intervals \u26a0\ufe0f CRITICAL","text":"<p>Current Configuration: <pre><code>OVN_LEADER_PROBE_INTERVAL: 5 seconds\nOVN_NORTHD_PROBE_INTERVAL: 5000ms (5 seconds)\nPROBE_INTERVAL: 180000ms (3 minutes)\n</code></pre></p> <p>Problem: - Industry standard: 30-60 seconds for production environments - Any GC pause, network jitter, or temporary CPU spike \u2192 disconnection - Too aggressive for distributed systems with network latency</p> <p>Reference: Mirantis/OpenStack production deployments use 60-second inactivity probes</p>"},{"location":"prd/ovn_database_stability_improvements/#2-no-client-side-inactivity-monitoring-critical","title":"2. No Client-Side Inactivity Monitoring \u26a0\ufe0f CRITICAL","text":"<p>Current State: <pre><code>// kube-dc-manager uses kube-ovn v1.14.4\novsClient, err := ovs.NewOvnNbClient(\n    kubedccomv1.ConfigGlobal.MasterConfig.OvnDbIps,\n    ovnNbTimeout,           // 2 seconds\n    ovsDbConTimeout,        // 2 seconds  \n    ovsDbInactivityTimeout, // 2 seconds\n    maxRetry,               // 2 attempts\n)\n</code></pre></p> <p>Problems: - No proactive Echo requests to keep connections alive - No awareness of stale connections until server kills them - No graceful reconnection strategy (instant retry, thundering herd)</p> <p>What's Missing: <pre><code>// libovsdb client options NOT used:\nclient.WithInactivityCheck(30*time.Second, nil, nil)  // \u274c Not implemented\nclient.WithReconnect(60*time.Second, backoff)         // \u274c Not implemented\n</code></pre></p>"},{"location":"prd/ovn_database_stability_improvements/#3-kube-ovn-newovnnbclient-limitations","title":"3. kube-ovn NewOvnNbClient Limitations","text":"<p>Current Implementation (<code>kube-ovn v1.14.4/pkg/ovs/ovn.go</code>): <pre><code>func NewOvnNbClient(ovnNbAddr string, ovnNbTimeout, ovsDbConTimeout, \n                    ovsDbInactivityTimeout, maxRetry int) (*OVNNbClient, error) {\n    // ...\n    nbClient, err = ovsclient.NewOvsDbClient(\n        ovsclient.NBDB,\n        ovnNbAddr,\n        dbModel,\n        monitors,\n        ovsDbConTimeout,        // Used for initial connection timeout\n        ovsDbInactivityTimeout, // Passed to underlying client\n    )\n    // ...\n    // NO WithReconnect() option\n    // NO WithInactivityCheck() option\n    // Simple retry loop with 2-second sleep (no backoff)\n}\n</code></pre></p> <p>Limitations: - Does not expose libovsdb's <code>WithReconnect()</code> option - Does not expose libovsdb's <code>WithInactivityCheck()</code> option - No exponential backoff on reconnection - Fixed 2-second sleep between retries (can cause thundering herd)</p>"},{"location":"prd/ovn_database_stability_improvements/#4-controller-mutex-architecture","title":"4. Controller Mutex Architecture","text":"<p>Evolution:</p> <p>V1 - Original (Parallel Deadlock): <pre><code>// Multiple reconciliations share singleton client\n// libovsdb internal mutexes cause contention \u2192 DEADLOCK\n</code></pre></p> <p>V2 - SafeOvnClient (Serial Bottleneck): <pre><code>// Operation mutex serializes ALL OVN calls\n// One stuck operation blocks everything \u2192 20min hang\n</code></pre></p> <p>V3 - Timeout Wrapper (Current): <pre><code>// 30-second timeout on mutex acquisition\n// Stuck operations timeout and reset client\n// BUT: Reconnection still takes time, services still delayed\n</code></pre></p> <p>Still Missing: - Proactive connection health monitoring - Graceful degradation during reconnection - Connection pool per operation type (optional optimization)</p>"},{"location":"prd/ovn_database_stability_improvements/#proposed-solutions","title":"Proposed Solutions","text":""},{"location":"prd/ovn_database_stability_improvements/#phase-1-immediate-configuration-changes-zero-code","title":"Phase 1: Immediate Configuration Changes (Zero Code) \ud83d\ude80","text":"<p>1.1 Increase OVN Database Probe Intervals</p> <p>Change: <pre><code># Edit: kubectl edit deployment -n kube-system ovn-central\nenv:\n- name: OVN_LEADER_PROBE_INTERVAL\n  value: \"60\"  # Was: 5 (12x increase)\n\n- name: OVN_NORTHD_PROBE_INTERVAL\n  value: \"60000\"  # Was: 5000 (12x increase)\n\n- name: PROBE_INTERVAL\n  value: \"300000\"  # Was: 180000 (1.67x increase to 5 minutes)\n</code></pre></p> <p>Expected Impact: - \u2705 Reduce disconnections by 80-90% (from 17K/day to &lt;2K/day) - \u2705 Prevent transient network issues from causing mass reconnections - \u2705 Reduce OVN database CPU during connection churn - \u2705 More tolerance for GC pauses and temporary load spikes</p> <p>Risk: Very low - aligns with industry best practices</p> <p>Rollback: Simple <code>kubectl rollout undo</code> if issues occur</p> <p>1.2 Configure OVN Database Connection Inactivity Probe</p> <p>Change: <pre><code>kubectl exec -n kube-system ovn-central-* -- \\\n  ovn-nbctl set-connection ptcp:6641 -- \\\n  set connection . inactivity_probe=60000\n</code></pre></p> <p>Expected Impact: - \u2705 Server-side 60-second inactivity timeout (matches PROBE_INTERVAL) - \u2705 Consistent behavior across all connection types - \u2705 Prevents premature connection kills</p> <p>Risk: Low - standard OVN configuration</p>"},{"location":"prd/ovn_database_stability_improvements/#phase-2-client-side-improvements-code-changes","title":"Phase 2: Client-Side Improvements (Code Changes) \ud83d\udd27","text":"<p>2.1 Extend kube-ovn Client with libovsdb Options</p> <p>Option A: Wrapper Around NewOvnNbClient (Recommended)</p> <p>Create enhanced client initialization in <code>internal/service_lb/ovn_client.go</code>:</p> <pre><code>import (\n    \"github.com/cenkalti/backoff/v4\"\n    \"github.com/ovn-org/libovsdb/client\"\n)\n\nfunc createEnhancedOvnClient(addr string, timeout int) (*ovs.OVNNbClient, error) {\n    // 1. Create base client using kube-ovn\n    baseClient, err := ovs.NewOvnNbClient(\n        addr,\n        timeout,\n        ovsDbConTimeout,\n        ovsDbInactivityTimeout,\n        maxRetry,\n    )\n    if err != nil {\n        return nil, err\n    }\n\n    // 2. Access underlying libovsdb client\n    // Note: May require reflection or type assertion depending on kube-ovn internals\n    underlyingClient := baseClient.Client // Access internal client field\n\n    // 3. Configure reconnection strategy\n    reconnectBackoff := backoff.NewExponentialBackOff()\n    reconnectBackoff.InitialInterval = 1 * time.Second\n    reconnectBackoff.MaxInterval = 30 * time.Second\n    reconnectBackoff.MaxElapsedTime = 2 * time.Minute\n    reconnectBackoff.Multiplier = 2.0\n\n    // Apply options to underlying client\n    underlyingClient.SetOption(client.WithReconnect(60*time.Second, reconnectBackoff))\n    underlyingClient.SetOption(client.WithInactivityCheck(\n        30*time.Second,  // Send Echo every 30s\n        nil,             // Default success handler\n        func(err error) {\n            klog.Warningf(\"OVN client inactivity check failed: %v\", err)\n        },\n    ))\n\n    return baseClient, nil\n}\n</code></pre> <p>Option B: Fork kube-ovn NewOvnNbClient (Alternative)</p> <p>Copy and modify <code>NewOvnNbClient</code> to include reconnection options:</p> <pre><code>func NewEnhancedOvnNbClient(ovnNbAddr string, ovnNbTimeout, ovsDbConTimeout, \n                            ovsDbInactivityTimeout, maxRetry int) (*OVNNbClient, error) {\n    dbModel, err := ovnnb.FullDatabaseModel()\n    if err != nil {\n        return nil, err\n    }\n\n    // ... setup indexes and monitors (same as kube-ovn) ...\n\n    // Configure reconnection strategy\n    reconnectBackoff := backoff.NewExponentialBackOff()\n    reconnectBackoff.InitialInterval = 1 * time.Second\n    reconnectBackoff.MaxInterval = 30 * time.Second\n    reconnectBackoff.MaxElapsedTime = 2 * time.Minute\n\n    // Create client with enhanced options\n    nbClient, err = ovsclient.NewOvsDbClient(\n        ovsclient.NBDB,\n        ovnNbAddr,\n        dbModel,\n        monitors,\n        ovsDbConTimeout,\n        ovsDbInactivityTimeout,\n        // NEW: Add reconnection options\n        client.WithReconnect(60*time.Second, reconnectBackoff),\n        client.WithInactivityCheck(30*time.Second, nil, nil),\n    )\n\n    // ... rest of implementation ...\n}\n</code></pre> <p>Recommended Approach: Option A (wrapper) for minimal kube-ovn dependency changes</p> <p>2.2 Update GetOvnClient Implementation</p> <p>File: <code>internal/service_lb/ovn_client.go</code></p> <p>Change: <pre><code>func GetOvnClient(ctx context.Context, cli client.Client) (*SafeOvnClient, error) {\n    ovnClientMu.RLock()\n    if globalOvnClient != nil {\n        ovnClientMu.RUnlock()\n        return &amp;SafeOvnClient{\n            OVNNbClient: globalOvnClient,\n            opMu:        &amp;ovnOpMu,\n        }, nil\n    }\n    ovnClientMu.RUnlock()\n\n    ovnClientMu.Lock()\n    defer ovnClientMu.Unlock()\n\n    if globalOvnClient != nil {\n        return &amp;SafeOvnClient{\n            OVNNbClient: globalOvnClient,\n            opMu:        &amp;ovnOpMu,\n        }, nil\n    }\n\n    if err := kubedccomv1.ConfigGlobal.ReadConfig(ctx, cli); err != nil {\n        return nil, err\n    }\n\n    // NEW: Use enhanced client creation\n    ovsClient, err := createEnhancedOvnClient(\n        kubedccomv1.ConfigGlobal.MasterConfig.OvnDbIps,\n        ovnNbTimeout,\n    )\n    if err != nil {\n        return nil, err\n    }\n\n    globalOvnClient = ovsClient\n    return &amp;SafeOvnClient{\n        OVNNbClient: globalOvnClient,\n        opMu:        &amp;ovnOpMu,\n    }, nil\n}\n</code></pre></p> <p>Benefits: - \u2705 Proactive connection health monitoring (Echo requests every 30s) - \u2705 Automatic reconnection with exponential backoff - \u2705 Graceful handling of temporary network issues - \u2705 Reduced thundering herd during mass reconnections</p>"},{"location":"prd/ovn_database_stability_improvements/#phase-3-monitoring-observability","title":"Phase 3: Monitoring &amp; Observability \ud83d\udcca","text":"<p>3.1 Add Prometheus Metrics</p> <pre><code>import (\n    \"github.com/prometheus/client_golang/prometheus\"\n)\n\nvar (\n    ovnConnectionsTotal = prometheus.NewCounterVec(\n        prometheus.CounterOpts{\n            Name: \"kube_dc_ovn_connections_total\",\n            Help: \"Total OVN database connections by state\",\n        },\n        []string{\"state\"}, // connected, disconnected, reconnecting\n    )\n\n    ovnOperationDuration = prometheus.NewHistogramVec(\n        prometheus.HistogramOpts{\n            Name: \"kube_dc_ovn_operation_duration_seconds\",\n            Help: \"OVN operation duration in seconds\",\n            Buckets: []float64{.001, .005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10, 30},\n        },\n        []string{\"operation\"}, // GetLogicalRouter, ListLoadBalancers, etc.\n    )\n\n    ovnMutexWaitDuration = prometheus.NewHistogram(\n        prometheus.HistogramOpts{\n            Name: \"kube_dc_ovn_mutex_wait_duration_seconds\",\n            Help: \"Time spent waiting for OVN operation mutex\",\n            Buckets: []float64{.001, .01, .1, 1, 5, 10, 30},\n        },\n    )\n)\n\nfunc init() {\n    prometheus.MustRegister(ovnConnectionsTotal)\n    prometheus.MustRegister(ovnOperationDuration)\n    prometheus.MustRegister(ovnMutexWaitDuration)\n}\n</code></pre> <p>Use in tryLockWithTimeout: <pre><code>func (c *SafeOvnClient) tryLockWithTimeout() error {\n    start := time.Now()\n    lockCh := make(chan struct{})\n    go func() {\n        c.opMu.Lock()\n        close(lockCh)\n    }()\n\n    select {\n    case &lt;-lockCh:\n        ovnMutexWaitDuration.Observe(time.Since(start).Seconds())\n        return nil\n    case &lt;-time.After(ovnOpMutexTimeout):\n        ovnMutexWaitDuration.Observe(ovnOpMutexTimeout.Seconds())\n        ovnConnectionsTotal.WithLabelValues(\"timeout\").Inc()\n        ResetOvnClient()\n        return fmt.Errorf(\"OVN operation mutex timeout after %v\", ovnOpMutexTimeout)\n    }\n}\n</code></pre></p> <p>Grafana Dashboard Metrics: - OVN connection state over time - Operation duration percentiles (p50, p95, p99) - Mutex wait time distribution - Reconnection events per hour - Service reconciliation success rate</p> <p>3.2 Enhanced Logging</p> <pre><code>// Add structured logging for connection events\nklog.InfoS(\"OVN client connecting\", \n    \"address\", ovnNbAddr,\n    \"timeout\", ovnNbTimeout,\n    \"retry\", attempt)\n\nklog.InfoS(\"OVN client reconnecting\",\n    \"reason\", \"inactivity_timeout\",\n    \"elapsed\", timeSinceLastActivity)\n\nklog.WarningS(\"OVN operation slow\",\n    \"operation\", \"GetLogicalRouter\",\n    \"duration\", duration,\n    \"threshold\", 5*time.Second)\n</code></pre>"},{"location":"prd/ovn_database_stability_improvements/#implementation-plan","title":"Implementation Plan","text":""},{"location":"prd/ovn_database_stability_improvements/#timeline","title":"Timeline","text":"Phase Tasks Duration Priority Phase 1 Configuration changes (probe intervals) 1 day P0 - Critical Phase 2 Client-side improvements (code) 3-5 days P1 - High Phase 3 Monitoring &amp; metrics 2-3 days P2 - Medium <p>Total Estimated Effort: 6-9 days</p>"},{"location":"prd/ovn_database_stability_improvements/#phase-1-configuration-changes-day-1","title":"Phase 1: Configuration Changes (Day 1)","text":"<p>Tasks: 1. \u2705 Document current OVN configuration 2. \u2705 Backup ovn-central deployment YAML 3. \u2705 Apply probe interval changes 4. \u2705 Monitor disconnection rate for 24 hours 5. \u2705 Validate no service disruption</p> <p>Success Criteria: - Disconnection rate drops by &gt;80% - No increase in service reconciliation failures - No DEADLOCK alerts in controller logs</p>"},{"location":"prd/ovn_database_stability_improvements/#phase-2-client-improvements-days-2-6","title":"Phase 2: Client Improvements (Days 2-6)","text":"<p>Tasks: 1. Research kube-ovn client internals for extensibility 2. Implement <code>createEnhancedOvnClient()</code> wrapper 3. Add exponential backoff configuration 4. Add inactivity check with Echo requests 5. Update <code>GetOvnClient()</code> to use enhanced client 6. Unit tests for reconnection scenarios 7. Integration tests with simulated network failures 8. Deploy to staging environment 9. Monitor for 48 hours before production</p> <p>Success Criteria: - Client reconnects within 5 seconds of disconnection - No thundering herd during mass reconnections - Service reconciliation continues during brief network issues - Mutex timeout events drop to zero</p>"},{"location":"prd/ovn_database_stability_improvements/#phase-3-observability-days-7-9","title":"Phase 3: Observability (Days 7-9)","text":"<p>Tasks: 1. Add Prometheus metrics collection 2. Create Grafana dashboard 3. Set up alerts for abnormal connection patterns 4. Document troubleshooting runbook 5. Train team on new metrics</p> <p>Success Criteria: - Real-time visibility into OVN connection health - Alerts trigger before user-visible impact - &lt; 5 minute MTTR for connection issues</p>"},{"location":"prd/ovn_database_stability_improvements/#success-metrics","title":"Success Metrics","text":""},{"location":"prd/ovn_database_stability_improvements/#immediate-phase-1-configuration","title":"Immediate (Phase 1 - Configuration)","text":"Metric Before Target Daily Disconnections 16,964 &lt; 2,000 Service Provisioning P95 30+ minutes &lt; 5 minutes DEADLOCK Alerts/Day 2-5 0 Controller CPU (avg) Unknown Baseline + Monitor"},{"location":"prd/ovn_database_stability_improvements/#long-term-phase-23-code-monitoring","title":"Long-term (Phase 2+3 - Code + Monitoring)","text":"Metric Before Target Service Provisioning P95 30+ minutes &lt; 30 seconds Service Provisioning P99 Unknown &lt; 2 minutes Reconnection Time P95 Unknown &lt; 10 seconds MTTR for Connection Issues Unknown &lt; 5 minutes Connection Uptime SLA Unknown 99.9%"},{"location":"prd/ovn_database_stability_improvements/#risks-mitigation","title":"Risks &amp; Mitigation","text":""},{"location":"prd/ovn_database_stability_improvements/#risk-1-increased-probe-intervals-delay-failure-detection","title":"Risk 1: Increased Probe Intervals Delay Failure Detection","text":"<p>Risk: Longer probe intervals mean slower detection of actual failures</p> <p>Mitigation: - Client-side inactivity checks (30s) provide faster detection than server probes (60s) - Echo requests every 30s ensure liveness monitoring - Acceptable tradeoff for production stability</p>"},{"location":"prd/ovn_database_stability_improvements/#risk-2-kube-ovn-internal-changes-required","title":"Risk 2: kube-ovn Internal Changes Required","text":"<p>Risk: kube-ovn v1.14.4 may not expose necessary client APIs</p> <p>Mitigation: - Use reflection/type assertion to access internal client - Fork kube-ovn client code if necessary (Option B) - Contribute improvements upstream to kube-ovn project</p>"},{"location":"prd/ovn_database_stability_improvements/#risk-3-regression-during-rollout","title":"Risk 3: Regression During Rollout","text":"<p>Risk: Changes could introduce new stability issues</p> <p>Mitigation: - Staged rollout: Config \u2192 Staging \u2192 Production - Comprehensive monitoring during each phase - Quick rollback plan (kubectl rollout undo) - Feature flag for enhanced client (gradual enablement)</p>"},{"location":"prd/ovn_database_stability_improvements/#testing-strategy","title":"Testing Strategy","text":""},{"location":"prd/ovn_database_stability_improvements/#unit-tests","title":"Unit Tests","text":"<pre><code>func TestSafeOvnClient_ReconnectionBackoff(t *testing.T) {\n    // Test exponential backoff behavior\n}\n\nfunc TestSafeOvnClient_InactivityCheck(t *testing.T) {\n    // Test Echo request behavior\n}\n\nfunc TestSafeOvnClient_MutexTimeout(t *testing.T) {\n    // Test 30-second timeout enforcement\n}\n</code></pre>"},{"location":"prd/ovn_database_stability_improvements/#integration-tests","title":"Integration Tests","text":"<pre><code>func TestLoadBalancerService_DuringNetworkPartition(t *testing.T) {\n    // Simulate network partition\n    // Verify service eventually gets external IP\n    // Verify no deadlock\n}\n\nfunc TestLoadBalancerService_DuringOVNRestart(t *testing.T) {\n    // Restart OVN database\n    // Verify client reconnects\n    // Verify services continue reconciling\n}\n</code></pre>"},{"location":"prd/ovn_database_stability_improvements/#chaos-testing","title":"Chaos Testing","text":"<ul> <li>Randomly kill OVN database connections</li> <li>Inject network latency (100-500ms)</li> <li>Simulate OVN database CPU saturation</li> <li>Test with 100+ simultaneous service creations</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#documentation-requirements","title":"Documentation Requirements","text":"<ol> <li>Architecture Docs: Update OVN client connectivity diagram</li> <li>Operations Runbook: Troubleshooting guide for connection issues</li> <li>Metrics Guide: Prometheus metrics and Grafana dashboards</li> <li>Configuration Reference: All tunable parameters and defaults</li> <li>Migration Guide: Rollout procedure and rollback steps</li> </ol>"},{"location":"prd/ovn_database_stability_improvements/#dependencies","title":"Dependencies","text":""},{"location":"prd/ovn_database_stability_improvements/#external-dependencies","title":"External Dependencies","text":"<ul> <li>kube-ovn: v1.14.4 (current), potential upgrade to v1.15+ for better client APIs</li> <li>libovsdb: Indirect dependency via kube-ovn</li> <li>backoff library: <code>github.com/cenkalti/backoff/v4</code> (already in kube-ovn)</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#internal-dependencies","title":"Internal Dependencies","text":"<ul> <li>OVN database deployment configuration</li> <li>kube-dc-manager controller deployment</li> <li>Prometheus metrics infrastructure (if Phase 3)</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#future-enhancements","title":"Future Enhancements","text":""},{"location":"prd/ovn_database_stability_improvements/#post-implementation-improvements","title":"Post-Implementation Improvements","text":"<ol> <li>Connection Pooling: Separate pools for read vs write operations</li> <li>Circuit Breaker: Temporarily disable OVN operations during extended outages</li> <li>Degraded Mode: Continue serving existing services even when OVN unreachable</li> <li>Multi-Database HA: Support OVN database clustering (not just single-node)</li> <li>Local Caching: Cache read-heavy operations (logical routers, switches)</li> </ol>"},{"location":"prd/ovn_database_stability_improvements/#kube-ovn-upstream-contributions","title":"kube-ovn Upstream Contributions","text":"<ol> <li>PR to expose <code>WithReconnect()</code> and <code>WithInactivityCheck()</code> options</li> <li>PR to use exponential backoff in <code>NewOvnNbClient()</code></li> <li>Share production learnings and best practices</li> </ol>"},{"location":"prd/ovn_database_stability_improvements/#references","title":"References","text":""},{"location":"prd/ovn_database_stability_improvements/#documentation","title":"Documentation","text":"<ul> <li>libovsdb Client Options</li> <li>Mirantis OVS Timeouts Guide</li> <li>kube-ovn v1.14.4 Source</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#related-issues","title":"Related Issues","text":"<ul> <li>Original deadlock issue: Services stuck <code>&lt;pending&gt;</code> for 20+ minutes</li> <li>SafeOvnClient fix: Added operation mutex (commit <code>760fffa</code>)</li> <li>Timeout wrapper fix: Added 30s timeout on mutex (commit <code>f57c5c9</code>)</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#investigation-findings","title":"Investigation Findings","text":"<ul> <li>OVN Database: 2,682,477 disconnections over 158 days</li> <li>Probe Intervals: 5s (too aggressive, should be 60s)</li> <li>Client Options: No inactivity checking or reconnection strategy</li> <li>Pattern: Mass reconnection during network hiccups causes cascade</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#approval-sign-off","title":"Approval &amp; Sign-off","text":""},{"location":"prd/ovn_database_stability_improvements/#stakeholders","title":"Stakeholders","text":"<ul> <li>Engineering Lead: Review technical approach</li> <li>Platform Team: Review infrastructure changes</li> <li>SRE: Review monitoring and operations impact</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#approval-criteria","title":"Approval Criteria","text":"<ul> <li>\u2705 Technical design reviewed</li> <li>\u2705 Risk assessment completed</li> <li>\u2705 Rollback plan documented</li> <li>\u2705 Success metrics defined</li> <li>\u2705 Testing strategy approved</li> </ul>"},{"location":"prd/ovn_database_stability_improvements/#appendix","title":"Appendix","text":""},{"location":"prd/ovn_database_stability_improvements/#a-current-configuration-snapshot","title":"A. Current Configuration Snapshot","text":"<pre><code># OVN Central Environment\nkubectl get deployment -n kube-system ovn-central -o yaml | grep -A 3 \"env:\"\n\nenv:\n- name: ENABLE_SSL\n  value: \"false\"\n- name: NODE_IPS\n  value: 192.168.1.3\n- name: OVN_LEADER_PROBE_INTERVAL\n  value: \"5\"\n- name: OVN_NORTHD_PROBE_INTERVAL\n  value: \"5000\"\n- name: PROBE_INTERVAL\n  value: \"180000\"\n</code></pre>"},{"location":"prd/ovn_database_stability_improvements/#b-disconnection-analysis","title":"B. Disconnection Analysis","text":"<pre><code># OVN Cluster Status (2026-01-12)\nkubectl exec -n kube-system ovn-central-* -- \\\n  ovs-appctl -t /var/run/ovn/ovnnb_db.ctl cluster/status OVN_Northbound\n\nDisconnections: 2682477\nUptime: 158 days\nRate: ~16,964 disconnections/day\n</code></pre>"},{"location":"prd/ovn_database_stability_improvements/#c-service-reconciliation-timeline","title":"C. Service Reconciliation Timeline","text":"<pre><code>14:35:12 - Service jump-etcd-etcd-lb: reconciliation started\n14:35:12 - Creating LoadBalancer resource manager\n14:35:12 - [STUCK - OVN connection issue]\n...\n14:56:15 - Service jump-etcd-etcd-lb: reconciliation completed (21 minutes)\n14:56:15 - 32 services complete simultaneously (backlog flush)\n</code></pre> <p>Document Version: 1.0 Last Updated: 2026-01-12 Author: kube-dc Platform Team Review Date: TBD</p>"},{"location":"prd/service_lb_sync_issue/","title":"Service LoadBalancer OVN Sync Issue","text":""},{"location":"prd/service_lb_sync_issue/#summary","title":"Summary","text":"<p>When kube-ovn-controller restarts (due to OVN database timeouts or other failures), the LoadBalancer VIP entries managed by <code>kube-dc-manager</code> are lost from the OVN Northbound database. This causes external services (like tenant cluster API servers) to become unreachable until <code>kube-dc-manager</code> is manually restarted.</p>"},{"location":"prd/service_lb_sync_issue/#issue-details","title":"Issue Details","text":""},{"location":"prd/service_lb_sync_issue/#observed-behavior","title":"Observed Behavior","text":"<p>Date: 2025-12-01</p> <p>Symptoms: - Tenant cluster control planes unreachable: <code>dial tcp 168.119.17.55:6443: connect: no route to host</code> - All EIP resources show <code>READY: true</code> - OVN EIP resources show <code>READY: true</code> - VMs are running correctly</p> <p>Timeline: 1. <code>kube-ovn-controller</code> experienced OVN database connection timeouts:    <pre><code>E1201 10:34:42.771547 controller.go:1021] OVN database echo timeout (4/5) after 60s\nE1201 10:35:57.772950 controller.go:1021] OVN database echo timeout (5/5) after 60s\nE1201 10:35:57.773181 klog.go:10] \"OVN database connection timeout after 5 attempts\"\n</code></pre> 2. <code>kube-ovn-controller</code> pod restarted at 10:35:58 3. After restart, OVN NB database was missing LoadBalancer entries for:    - <code>shalb-envoy-user-a-cp-tcp</code> (168.119.17.55:6443)    - <code>shalb-envoy-user-b-cp-tcp</code> (168.119.17.53:6443)    - <code>shalb-envoy-user-c-cp-tcp</code> (168.119.17.56:6443)    - <code>shalb-envoy-envoy-delta-controller-envoy-tcp</code> (168.119.17.54:443/10000/9901)</p>"},{"location":"prd/service_lb_sync_issue/#root-cause-analysis","title":"Root Cause Analysis","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     writes to      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  kube-dc-manager    \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 \u2502   OVN NB Database   \u2502\n\u2502  (service_lb.go)    \u2502                    \u2502   (LoadBalancers)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                    \u2191\n                                                    \u2502 reconciles\n                                                    \u2502\n                                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                           \u2502 kube-ovn-controller \u2502\n                                           \u2502                     \u2502\n                                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The Problem:</p> <ol> <li><code>kube-dc-manager</code> writes LoadBalancer VIPs directly to OVN NB database via <code>ovs.NbClient</code></li> <li><code>kube-ovn-controller</code> manages its own OVN resources but does NOT manage <code>kube-dc-manager</code>'s LBs</li> <li>When <code>kube-ovn-controller</code> restarts, it reconciles resources it knows about</li> <li><code>kube-dc-manager</code>'s LBs are NOT reconciled because:</li> <li>They are not tracked by any Kubernetes resource that <code>kube-ovn-controller</code> watches</li> <li><code>kube-dc-manager</code> only reconciles on Endpoints changes, not on OVN state changes</li> </ol>"},{"location":"prd/service_lb_sync_issue/#affected-code","title":"Affected Code","text":"<p><code>internal/service_lb/service_lb.go</code>:</p> <pre><code>func (r *LBResource) Sync(ctx context.Context) error {\n    // Builds VIP maps\n    vipListTcp := map[string]string{}\n    // ...\n\n    // Updates OVN LB directly\n    err = r.updateLbs(r.tcpLbName(), ovnnb.LoadBalancerProtocolTCP, vipListTcp)\n\n    // Attaches to router and switch\n    err = r.ovsCli.LogicalRouterUpdateLoadBalancers(r.projectRouter.Name, ...)\n    err = r.ovsCli.LogicalSwitchUpdateLoadBalancers(project.SubnetName(r.project), ...)\n}\n</code></pre> <p>The sync is triggered by: - Endpoint creation/update - Service creation/update</p> <p>NOT triggered by: - OVN database reconnection - kube-ovn-controller restart - OVN NB database state changes</p>"},{"location":"prd/service_lb_sync_issue/#solutions-considered","title":"Solutions Considered","text":"Option Description Pros Cons Status Periodic Reconciliation Full resync every N minutes Simple Downtime up to N min, wasteful \u274c Rejected OVN Connection Monitor Track connection state Immediate Requires OVS client mods \u274c Rejected K8s Annotation State Store LB state in annotations Declarative Complex implementation \u274c Rejected OVSDB Event Watch Subscribe to LB deletions Real-time Complex, stability concerns \u274c Rejected LB Watcher + Restart Detection Verify LBs periodically + detect restarts Minimal impact, targeted Slight delay \u2705 Implemented"},{"location":"prd/service_lb_sync_issue/#implemented-solution","title":"Implemented Solution","text":"<p>LB Watcher with Periodic Verification + kube-ovn-controller Restart Detection</p>"},{"location":"prd/service_lb_sync_issue/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            LBWatcher                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502  Periodic Verification      \u2502    \u2502  Restart Detection          \u2502    \u2502\n\u2502  \u2502  (every 2 min)              \u2502    \u2502  (poll every 30s)           \u2502    \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524    \u2502\n\u2502  \u2502 1. List LoadBalancer svcs   \u2502    \u2502 1. Check pod restart count  \u2502    \u2502\n\u2502  \u2502 2. Check OVN LB exists      \u2502    \u2502 2. If changed: wait 30s     \u2502    \u2502\n\u2502  \u2502 3. If missing: trigger      \u2502    \u2502 3. Verify all LBs           \u2502    \u2502\n\u2502  \u2502    reconciliation           \u2502    \u2502                             \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                 \u2502                                \u2502                      \u2502\n\u2502                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2502                                  \u25bc                                      \u2502\n\u2502                    Update annotation on Service                         \u2502\n\u2502                    kube-dc.com/lb-resync-timestamp                      \u2502\n\u2502                                  \u2502                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Service Controller         \u2502\n                    \u2502  (existing reconcile loop)  \u2502\n                    \u2502  - Detects annotation change\u2502\n                    \u2502  - Recreates OVN LB         \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"prd/service_lb_sync_issue/#files-modifiedcreated","title":"Files Modified/Created","text":"<ol> <li><code>internal/service_lb/lb_watcher.go</code> (New)</li> <li><code>LBWatcher</code> struct implementing <code>manager.Runnable</code></li> <li>Periodic verification every 2 minutes</li> <li>kube-ovn-controller pod restart detection (every 30s)</li> <li> <p>Triggers reconciliation via annotation update</p> </li> <li> <p><code>internal/controller/core/service_controller.go</code> (Modified)</p> </li> <li>Added <code>lbWatcher</code> field to <code>ServiceReconciler</code></li> <li>Added RBAC for pods: <code>+kubebuilder:rbac:groups=core,resources=pods,verbs=get;list;watch</code></li> <li>Added predicate for <code>kube-dc.com/lb-resync-timestamp</code> annotation</li> <li>Integrated <code>LBWatcher</code> startup via <code>mgr.Add()</code></li> </ol>"},{"location":"prd/service_lb_sync_issue/#performance-impact","title":"Performance Impact","text":"Metric Value Notes Periodic check interval 2 min Configurable via <code>LBVerificationInterval</code> Pod restart poll 30s Single API call OVN LB check ~10ms per svc Only for provisioned LB services Reconciliation trigger On-demand Only when LB actually missing"},{"location":"prd/service_lb_sync_issue/#test-results-2025-12-02","title":"Test Results (2025-12-02)","text":"<p>Test: Manual LB Deletion Recovery</p> <pre><code># Deleted OVN LB manually\n$ ovn-nbctl lb-del shalb-dev-etcd-lb-tcp\n\n# LB Watcher detected and recovered (within 2 min):\n12:46:14 [WARN] LB watcher: OVN LB missing for service shalb-dev/etcd-lb, triggering reconciliation\n12:46:14 [INFO] Update service-lb resync annotation changed, run reconciliation\n12:46:15 [INFO] Kind: ServiceLb, Message: Create Lb shalb-dev-etcd-lb-tcp\n12:46:15 [INFO] Kind: ServiceLb, Message: Add Vip Lb shalb-dev-etcd-lb-tcp, Vip 168.119.17.51:2379\n12:46:15 [INFO] LB watcher: triggered reconciliation for 1 services with missing LBs\n</code></pre> <p>Result: \u2705 LB automatically recreated within 2 minutes</p>"},{"location":"prd/service_lb_sync_issue/#verification-steps","title":"Verification Steps","text":"<p>After implementing fix, verify with:</p> <pre><code># 1. Check OVN LBs exist\nkubectl exec -n kube-system deployment/ovn-central -- \\\n  ovn-nbctl --no-leader-only lb-list | grep \"168.119\"\n\n# 2. Simulate failure - restart kube-ovn-controller\nkubectl rollout restart deployment/kube-ovn-controller -n kube-system\n\n# 3. Wait 2 minutes and verify LBs still exist\nsleep 120\nkubectl exec -n kube-system deployment/ovn-central -- \\\n  ovn-nbctl --no-leader-only lb-list | grep \"168.119\"\n\n# 4. Test connectivity\ncurl -k https://168.119.17.55:6443/version\n</code></pre>"},{"location":"prd/service_lb_sync_issue/#related-files","title":"Related Files","text":"<ul> <li><code>internal/service_lb/lb_watcher.go</code> - NEW LB Watcher implementation</li> <li><code>internal/service_lb/service_lb.go</code> - ServiceLB OVN sync logic</li> <li><code>internal/controller/core/service_controller.go</code> - Service controller (modified)</li> </ul>"},{"location":"prd/service_lb_sync_issue/#version","title":"Version","text":"<ul> <li>Implemented in: v0.1.34-dev4</li> <li>Date: 2025-12-02</li> </ul>"},{"location":"prd/svc_lb_architecture/","title":"Service LoadBalancer Architecture in Kube-DC","text":"<p>Status: \u2705 Documented &amp; Misconceptions Resolved Last Updated: 2025-12-02  </p>"},{"location":"prd/svc_lb_architecture/#summary","title":"Summary","text":"<p>Service LoadBalancers in kube-dc work without requiring VPC policy routes or NAT rules. The load balancer VIPs are directly accessible through the OVN router's external interface.</p>"},{"location":"prd/svc_lb_architecture/#how-it-works","title":"How It Works","text":""},{"location":"prd/svc_lb_architecture/#1-network-topology","title":"1. Network Topology","text":"<pre><code>External Network (168.119.17.48/28)\n         \u2193\nOVN Router Port: shalb-dev-ext-public\n  MAC: ae:d6:b9:e1:76:78\n  Network: 168.119.17.51/28\n         \u2193\nOVN Load Balancer VIPs (168.119.17.51-.63)\n         \u2193\nBackend Pods/VMs in Project VPC\n</code></pre>"},{"location":"prd/svc_lb_architecture/#2-eip-allocation-for-service-loadbalancers","title":"2. EIP Allocation for Service LoadBalancers","text":"<p>When a Service of type <code>LoadBalancer</code> is created:</p> <ol> <li>kube-dc Service Controller (<code>internal/controller/core/service_controller.go</code>):</li> <li>Detects the LoadBalancer service</li> <li> <p>Creates an <code>EIp</code> resource</p> </li> <li> <p>kube-dc EIP Controller (<code>internal/eip/ovn_eip_res.go</code>):</p> </li> <li>Creates an <code>OvnEip</code> resource</li> <li>Allocates an IP from the external subnet (e.g., <code>ext-public</code>)</li> <li> <p>Type: <code>lrp</code> (Logical Router Port)</p> </li> <li> <p>Kube-OVN (upstream controller):</p> </li> <li>Does NOT create NAT rules for <code>lrp</code> type EIPs when used with load balancers</li> <li>The IP becomes part of the router's external interface subnet</li> </ol>"},{"location":"prd/svc_lb_architecture/#3-load-balancer-vip-configuration","title":"3. Load Balancer VIP Configuration","text":"<p>kube-dc Service LB Controller (<code>internal/service_lb/service_lb.go</code>):</p> <pre><code>// Creates OVN load balancer\nvipKey := fmt.Sprintf(\"%s:%d\", r.ipAddress, port.Port)  // e.g., \"168.119.17.55:80\"\nbackends := \"10.1.0.40:31416,10.1.0.41:31416\"  // Pod/VM IPs:ports\n\n// Attaches to BOTH router and logical switch\novsCli.LogicalRouterUpdateLoadBalancers(r.projectRouter.Name, ...)  // shalb-dev\novsCli.LogicalSwitchUpdateLoadBalancers(project.SubnetName(r.project), ...)  // shalb-dev-default\n</code></pre>"},{"location":"prd/svc_lb_architecture/#4-traffic-flow","title":"4. Traffic Flow","text":""},{"location":"prd/svc_lb_architecture/#external-client-service","title":"External Client \u2192 Service","text":"<pre><code>1. Client sends packet to 168.119.17.55:80\n2. ARP resolution: Who has 168.119.17.55?\n3. OVN router responds: ae:d6:b9:e1:76:78 (my MAC)\n4. Packet arrives at router's external port\n5. OVN load balancer intercepts (VIP match)\n6. Packet DNAT'd to backend: 10.1.0.40:31416\n7. Response SNAT'd back through VIP\n8. Client receives response from 168.119.17.55:80\n</code></pre>"},{"location":"prd/svc_lb_architecture/#internal-pod-service-clusterip","title":"Internal Pod \u2192 Service (ClusterIP)","text":"<p>Normal kube-proxy/Cilium routing within the cluster.</p>"},{"location":"prd/svc_lb_architecture/#key-differences-from-fip","title":"Key Differences from FIP","text":"Feature Service LoadBalancer (lrp EIP) Floating IP (FIP) OvnEip Type <code>lrp</code> <code>lrp</code> NAT Rules None (uses LB VIP) <code>dnat_and_snat</code> Policy Routes Not needed Required for outbound Annotation <code>ovn.kubernetes.io/vpc_nat</code> NOT needed <code>ovn.kubernetes.io/vpc_nat: {vpc}-{fip-name}</code> required Use Case Inbound load balancing Bidirectional NAT to VM/Pod Status.nat <code>\"\"</code> (empty) <code>fip</code>"},{"location":"prd/svc_lb_architecture/#verification-commands","title":"Verification Commands","text":""},{"location":"prd/svc_lb_architecture/#check-service-loadbalancer","title":"Check Service LoadBalancer","text":"<pre><code># 1. Verify Service has external IP\nkubectl get svc -n {namespace} {service-name}\n\n# 2. Check EIP resource\nkubectl get eip -n {namespace} | grep slb-\n\n# 3. Verify OvnEip (no vpc_nat needed)\nEIP_NAME=$(kubectl get eip -n {namespace} {eip-name} -o jsonpath='{.status.ovnEIpRef}')\nkubectl get ovn-eip $EIP_NAME -o yaml\n\n# 4. Check OVN load balancer\nkubectl exec -n kube-system ovn-central-xxx -- ovn-nbctl lb-list | grep {namespace}\n\n# 5. Verify router attachment\nkubectl exec -n kube-system ovn-central-xxx -- ovn-nbctl lr-lb-list {namespace}\n\n# 6. Check ARP resolution (from gateway/bastion)\narp -n | grep {external-ip}\n# Should show router MAC: ae:d6:b9:e1:76:78 (for shalb-dev)\n\n# 7. Test connectivity\ncurl http://{external-ip}:{port}\n</code></pre>"},{"location":"prd/svc_lb_architecture/#check-vpc-router-configuration","title":"Check VPC Router Configuration","text":"<pre><code># Show router ports and subnet\nkubectl exec -n kube-system ovn-central-xxx -- ovn-nbctl show {vpc-name}\n\n# Example output:\nrouter 9cae37d3-65ae-46e9-ad95-a0ebf58108d9 (shalb-dev)\n    port shalb-dev-ext-public\n        mac: \"ae:d6:b9:e1:76:78\"\n        networks: [\"168.119.17.51/28\"]  # \u2190 All EIPs in this range\n        gateway chassis: [...]\n</code></pre>"},{"location":"prd/svc_lb_architecture/#common-misconceptions-resolved","title":"Common Misconceptions (Resolved)","text":"<p>Note: As of 2025-12-02, the codebase has been cleaned up to remove sources of these misconceptions.</p>"},{"location":"prd/svc_lb_architecture/#misconception-1-policy-routes-required","title":"\u274c Misconception 1: Policy Routes Required","text":"<p>FALSE: Service LoadBalancers do NOT require VPC policy routes.</p> <p>Policy routes (like <code>ip4.src==168.119.17.X reroute 168.119.17.49</code>) are only needed for: - Outbound traffic from VMs/Pods with dedicated EIPs - FIP resources that need bidirectional NAT</p> <p>Service LoadBalancers use the router's external interface directly.</p> <p>Status: \u2705 No incorrect references found in codebase.</p>"},{"location":"prd/svc_lb_architecture/#misconception-2-vpc_nat-annotation-required","title":"\u274c Misconception 2: vpc_nat Annotation Required","text":"<p>FALSE: The <code>ovn.kubernetes.io/vpc_nat</code> annotation is NOT required for Service LoadBalancer OvnEips.</p> <p>This annotation is only needed for: - FIP resources (creates DNAT/SNAT rules) - Resources that need VPC-level NAT management</p> <p>Service LoadBalancers work through the OVN load balancer VIP mechanism.</p> <p>Status: \u2705 kube-dc controllers verified - no <code>vpc_nat</code> usage for Service LBs.</p>"},{"location":"prd/svc_lb_architecture/#misconception-3-kyverno-policy-is-mandatory","title":"\u274c Misconception 3: Kyverno Policy is Mandatory","text":"<p>FALSE: The Kyverno policies for Service LoadBalancers were NOT required.</p> <p>Status: \u2705 REMOVED on 2025-12-02: - Deleted <code>installer/kube-dc/templates/kube-dc/kyverno/mutate-tenant-svc-lb.yaml</code> - Deleted <code>installer/kube-dc/templates/kube-dc/kyverno/mutate-svc-lb-dep.yaml</code> - Removed unnecessary OVN annotations from <code>examples/capi-cluster/addons.yaml</code></p> <p>These policies set annotations (<code>ovn.kubernetes.io/vpc</code>, etc.) that were NOT read by kube-dc controllers.</p>"},{"location":"prd/svc_lb_architecture/#troubleshooting","title":"Troubleshooting","text":""},{"location":"prd/svc_lb_architecture/#service-not-accessible-externally","title":"Service Not Accessible Externally","text":"<ol> <li> <p>Check if EIP is allocated: <pre><code>kubectl get svc -n {namespace} {service-name}\n# STATUS should show EXTERNAL-IP\n</code></pre></p> </li> <li> <p>Verify OVN load balancer exists: <pre><code>kubectl exec -n kube-system ovn-central-xxx -- ovn-nbctl lb-list | grep {svc-name}\n</code></pre></p> </li> <li> <p>Check backend endpoints: <pre><code>kubectl get endpoints -n {namespace} {service-name}\n# Should list pod/VM IPs\n</code></pre></p> </li> <li> <p>Verify router attachment: <pre><code>kubectl exec -n kube-system ovn-central-xxx -- ovn-nbctl lr-lb-list {vpc-name}\n# Should list the load balancer\n</code></pre></p> </li> <li> <p>Test from within cluster first: <pre><code>kubectl run test --image=curlimages/curl --rm -i -n {namespace} \\\n  -- curl http://{external-ip}:{port}\n</code></pre></p> </li> <li> <p>Check ARP resolution (from external host): <pre><code># On gateway/bastion\narp -n | grep {external-ip}\n# Should show router MAC\n</code></pre></p> </li> </ol>"},{"location":"prd/svc_lb_architecture/#service-works-internally-but-not-externally","title":"Service Works Internally but Not Externally","text":"<p>Possible causes:</p> <ol> <li>Firewall rules on external gateway/firewall</li> <li>Network routing - external network may not route to EIP subnet</li> <li>Testing from wrong location - if testing from bastion/gateway that has the subnet assigned locally, connections will be routed locally</li> </ol> <p>Solution: - Test from a truly external client (your laptop, different server) - Check firewall rules on the physical network infrastructure - Verify routing table on the internet gateway</p>"},{"location":"prd/svc_lb_architecture/#slow-initial-connection","title":"Slow Initial Connection","text":"<p>If first connection fails but subsequent ones work: - ARP cache warming - first packet triggers ARP resolution - Wait 5-10 seconds and try again - Check ARP cache: <code>arp -n | grep {external-ip}</code></p>"},{"location":"prd/svc_lb_architecture/#code-references","title":"Code References","text":""},{"location":"prd/svc_lb_architecture/#service-lb-controller","title":"Service LB Controller","text":"<ul> <li>Main controller: <code>/home/voa/projects/kube-dc/internal/controller/core/service_controller.go</code></li> <li>Load balancer logic: <code>/home/voa/projects/kube-dc/internal/service_lb/service_lb.go</code></li> <li>EIP management: <code>/home/voa/projects/kube-dc/internal/service_lb/eip_res.go</code></li> </ul>"},{"location":"prd/svc_lb_architecture/#eip-controller","title":"EIP Controller","text":"<ul> <li>OvnEip creation: <code>/home/voa/projects/kube-dc/internal/eip/ovn_eip_res.go</code></li> <li>Lines 134-150: OvnEip resource generation (NO vpc_nat annotation needed)</li> </ul>"},{"location":"prd/svc_lb_architecture/#related-documentation","title":"Related Documentation","text":"<ul> <li>Service LB Tutorial: <code>/home/voa/projects/kube-dc/docs/tutorial-ip-and-lb.md</code></li> <li>Networking Architecture: <code>/home/voa/projects/kube-dc/docs/architecture-networking.md</code></li> <li>FIP Resources: <code>/home/voa/projects/kube-dc/internal/fip/res_fip.go</code></li> </ul>"}]}